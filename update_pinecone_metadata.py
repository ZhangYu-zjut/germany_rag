"""
æ™ºèƒ½æ‰¹é‡æ›´æ–°Pinecone metadata
åªæ›´æ–°4ä¸ªæ–°å¢å­—æ®µï¼šmonth, day, id, source_reference
ä¸é‡æ–°è®¡ç®—embeddingsï¼Œä¿æŒå‘é‡ä¸å˜
"""

import json
import os
import time
from typing import Dict, List
from pinecone import Pinecone
from dotenv import load_dotenv
from loguru import logger

# é…ç½®logger
logger.remove()
logger.add(
    lambda msg: print(msg, end=''),
    format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level:8}</level> | <level>{message}</level>",
    level="INFO"
)

load_dotenv()


class MetadataUpdater:
    """Pinecone Metadataæ‰¹é‡æ›´æ–°å™¨"""

    def __init__(self):
        """åˆå§‹åŒ–Pineconeè¿æ¥"""
        api_key = os.getenv('PINECONE_VECTOR_DATABASE_API_KEY')
        self.pc = Pinecone(api_key=api_key)
        self.index = self.pc.Index('german-bge')

        # åŠ è½½åŸå§‹JSONæ•°æ®
        self.data_cache = {}  # {year: {text_id: metadata}}

        logger.info("âœ… Pineconeè¿æ¥åˆå§‹åŒ–æˆåŠŸ")

    def load_year_data(self, year: int) -> Dict:
        """
        åŠ è½½æŸä¸€å¹´çš„åŸå§‹JSONæ•°æ®

        Returns:
            {text_id: metadata} çš„æ˜ å°„
        """
        if year in self.data_cache:
            return self.data_cache[year]

        json_file = f'data/pp_json_49-21/pp_{year}.json'

        if not os.path.exists(json_file):
            logger.warning(f"âš ï¸ {year}å¹´æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {json_file}")
            return {}

        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # æ„å»º text_id -> metadata æ˜ å°„
            text_id_map = {}
            if 'transcript' in data:
                for item in data['transcript']:
                    if item.get('type') == 'text_block':
                        text_id = item.get('text_id')
                        metadata = item.get('metadata', {})
                        if text_id and metadata:
                            text_id_map[text_id] = metadata

            self.data_cache[year] = text_id_map
            logger.info(f"ğŸ“š åŠ è½½{year}å¹´æ•°æ®: {len(text_id_map)}æ¡è®°å½•")

            return text_id_map

        except Exception as e:
            logger.error(f"âŒ åŠ è½½{year}å¹´æ•°æ®å¤±è´¥: {str(e)}")
            return {}

    def extract_info_from_vector_id(self, vector_id: str) -> tuple:
        """
        ä»å‘é‡IDä¸­æå–yearå’Œoriginal_text_id

        å‘é‡IDæ ¼å¼: "2017_1762423575_2477_chunk_0"
        æå–: year=2017

        éœ€è¦ä»metadataä¸­çš„original_text_idè·å–çœŸå®çš„text_id
        """
        parts = vector_id.split('_')
        if len(parts) >= 1:
            try:
                year = int(parts[0])
                return year, None
            except:
                pass

        return None, None

    def format_source_reference(self, metadata: Dict) -> str:
        """
        æ ¼å¼åŒ–source_reference: "id | speaker | year-month-day"
        """
        doc_id = metadata.get('id', 'unknown')
        speaker = metadata.get('speaker', 'Unknown')
        year = metadata.get('year', '0000')
        month = metadata.get('month', '01')
        day = metadata.get('day', '01')

        return f"{doc_id} | {speaker} | {year}-{month}-{day}"

    def update_vector_metadata(
        self,
        vector_id: str,
        original_text_id: str,
        year: int
    ) -> bool:
        """
        æ›´æ–°å•ä¸ªå‘é‡çš„metadata

        Args:
            vector_id: Pineconeå‘é‡ID
            original_text_id: åŸå§‹æ–‡æœ¬ID (ä»å½“å‰metadataä¸­è·å–)
            year: å¹´ä»½

        Returns:
            æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        # åŠ è½½è¯¥å¹´ä»½çš„åŸå§‹æ•°æ®
        year_data = self.load_year_data(year)

        if not year_data:
            logger.warning(f"âš ï¸ {year}å¹´æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡å‘é‡ {vector_id}")
            return False

        # æŸ¥æ‰¾å¯¹åº”çš„åŸå§‹metadata
        if original_text_id not in year_data:
            logger.debug(f"  æœªæ‰¾åˆ°åŸå§‹metadata: {original_text_id}")
            return False

        original_meta = year_data[original_text_id]

        # æ„å»ºæ–°çš„metadataå­—æ®µï¼ˆåªæ›´æ–°4ä¸ªæ–°å­—æ®µï¼‰
        new_fields = {
            'month': original_meta.get('month', '01'),
            'day': original_meta.get('day', '01'),
            'id': original_meta.get('id', original_text_id),
            'source_reference': self.format_source_reference(original_meta)
        }

        # ä½¿ç”¨Pineconeçš„updateæ–¹æ³•æ›´æ–°metadata
        try:
            self.index.update(
                id=vector_id,
                set_metadata=new_fields
            )
            return True

        except Exception as e:
            logger.error(f"âŒ æ›´æ–°å¤±è´¥ {vector_id}: {str(e)}")
            return False

    def update_year_metadata(self, year: int, batch_size: int = 100) -> Dict:
        """
        æ›´æ–°æŸä¸€å¹´æ‰€æœ‰å‘é‡çš„metadata

        Args:
            year: å¹´ä»½
            batch_size: æ‰¹å¤„ç†å¤§å°

        Returns:
            ç»Ÿè®¡ä¿¡æ¯
        """
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ”§ å¼€å§‹æ›´æ–°{year}å¹´metadata")
        logger.info(f"{'='*60}")

        start_time = time.time()

        # é¢„åŠ è½½è¯¥å¹´ä»½çš„åŸå§‹æ•°æ®
        year_data = self.load_year_data(year)
        if not year_data:
            logger.warning(f"âš ï¸ {year}å¹´æ— æ•°æ®ï¼Œè·³è¿‡")
            return {"year": year, "updated": 0, "failed": 0, "total": 0}

        # æŸ¥è¯¢è¯¥å¹´ä»½çš„æ‰€æœ‰å‘é‡
        logger.info(f"ğŸ“Š æŸ¥è¯¢{year}å¹´çš„æ‰€æœ‰å‘é‡...")

        # ä½¿ç”¨filteræŸ¥è¯¢è·å–è¯¥å¹´ä»½æ‰€æœ‰å‘é‡
        try:
            # Pineconeä¸æ”¯æŒç›´æ¥è·å–æ‰€æœ‰IDï¼Œæˆ‘ä»¬ä½¿ç”¨query + filterçš„æ–¹å¼
            dummy_vector = [0.0] * 1024
            results = self.index.query(
                vector=dummy_vector,
                top_k=10000,  # Pineconeé™åˆ¶
                filter={'year': {'$eq': str(year)}},
                include_metadata=True
            )

            vectors = results.matches
            total_vectors = len(vectors)

            logger.info(f"âœ… æ‰¾åˆ°{total_vectors}ä¸ªå‘é‡")

        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢{year}å¹´å‘é‡å¤±è´¥: {str(e)}")
            return {"year": year, "updated": 0, "failed": 0, "total": 0}

        if total_vectors == 0:
            logger.warning(f"âš ï¸ {year}å¹´æ— å‘é‡æ•°æ®")
            return {"year": year, "updated": 0, "failed": 0, "total": 0}

        # æ‰¹é‡æ›´æ–°
        updated_count = 0
        failed_count = 0

        for i, match in enumerate(vectors):
            vector_id = match.id
            metadata = match.metadata

            # ä»metadataä¸­è·å–original_text_id
            original_text_id = metadata.get('original_text_id')

            if not original_text_id:
                logger.debug(f"  å‘é‡ {vector_id} ç¼ºå°‘original_text_idï¼Œè·³è¿‡")
                failed_count += 1
                continue

            # æ›´æ–°metadata
            success = self.update_vector_metadata(vector_id, original_text_id, year)

            if success:
                updated_count += 1
            else:
                failed_count += 1

            # æ˜¾ç¤ºè¿›åº¦
            if (i + 1) % 100 == 0:
                progress = (i + 1) / total_vectors * 100
                logger.info(f"  è¿›åº¦: {i+1}/{total_vectors} ({progress:.1f}%) - æˆåŠŸ: {updated_count}, å¤±è´¥: {failed_count}")

        elapsed_time = time.time() - start_time

        logger.info(f"\nâœ… {year}å¹´metadataæ›´æ–°å®Œæˆ")
        logger.info(f"   æ€»å‘é‡æ•°: {total_vectors}")
        logger.info(f"   æˆåŠŸæ›´æ–°: {updated_count}")
        logger.info(f"   å¤±è´¥: {failed_count}")
        logger.info(f"   è€—æ—¶: {elapsed_time:.1f}ç§’")

        return {
            "year": year,
            "total": total_vectors,
            "updated": updated_count,
            "failed": failed_count,
            "time": elapsed_time
        }

    def verify_update(self, year: int, sample_size: int = 5):
        """
        éªŒè¯æ›´æ–°ç»“æœ

        Args:
            year: å¹´ä»½
            sample_size: æŠ½æ ·æ•°é‡
        """
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ” éªŒè¯{year}å¹´metadataæ›´æ–°ç»“æœ")
        logger.info(f"{'='*60}")

        # æŸ¥è¯¢å‡ ä¸ªæ ·æœ¬
        dummy_vector = [0.0] * 1024
        results = self.index.query(
            vector=dummy_vector,
            top_k=sample_size,
            filter={'year': {'$eq': str(year)}},
            include_metadata=True
        )

        logger.info(f"\næŠ½æ ·æ£€æŸ¥ {len(results.matches)} ä¸ªå‘é‡:\n")

        for i, match in enumerate(results.matches, 1):
            meta = match.metadata

            month = meta.get('month')
            day = meta.get('day')
            doc_id = meta.get('id')
            source_ref = meta.get('source_reference')

            logger.info(f"æ ·æœ¬ {i}:")
            logger.info(f"  ID: {match.id[:30]}...")
            logger.info(f"  month: {month} (type: {type(month).__name__})")
            logger.info(f"  day: {day} (type: {type(day).__name__})")
            logger.info(f"  id: {doc_id}")
            logger.info(f"  source_reference: {source_ref[:60] if source_ref else 'None'}...")

            # æ£€æŸ¥æ˜¯å¦æˆåŠŸæ›´æ–°
            if month and day and doc_id and source_ref:
                logger.info(f"  âœ… æ›´æ–°æˆåŠŸ\n")
            else:
                logger.warning(f"  âš ï¸ æ›´æ–°ä¸å®Œæ•´\n")


def main():
    """ä¸»å‡½æ•°"""
    logger.info("="*60)
    logger.info("Pinecone Metadataæ‰¹é‡æ›´æ–°å·¥å…·")
    logger.info("="*60)
    logger.info("\nåŠŸèƒ½: æ›´æ–°4ä¸ªæ–°å­—æ®µ (month, day, id, source_reference)")
    logger.info("ä¼˜åŠ¿: ä¸é‡æ–°è®¡ç®—embeddingsï¼Œä¿æŒå‘é‡ä¸å˜\n")

    updater = MetadataUpdater()

    # è¦æ›´æ–°çš„å¹´ä»½
    years_to_update = [2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024]

    total_start = time.time()
    all_stats = []

    for year in years_to_update:
        stats = updater.update_year_metadata(year)
        all_stats.append(stats)

        # éªŒè¯å‰3å¹´çš„æ›´æ–°ç»“æœ
        if year <= 2017:
            updater.verify_update(year)

    total_time = time.time() - total_start

    # æ€»ç»“
    logger.info(f"\n{'='*60}")
    logger.info(f"ğŸ“Š æ‰€æœ‰å¹´ä»½æ›´æ–°å®Œæˆ")
    logger.info(f"{'='*60}\n")

    total_updated = sum(s['updated'] for s in all_stats)
    total_failed = sum(s['failed'] for s in all_stats)
    total_vectors = sum(s['total'] for s in all_stats)

    logger.info(f"æ€»å‘é‡æ•°: {total_vectors}")
    logger.info(f"æˆåŠŸæ›´æ–°: {total_updated}")
    logger.info(f"å¤±è´¥: {total_failed}")
    logger.info(f"æˆåŠŸç‡: {total_updated/total_vectors*100:.2f}%")
    logger.info(f"æ€»è€—æ—¶: {total_time:.1f}ç§’ ({total_time/60:.1f}åˆ†é’Ÿ)")
    logger.info(f"\nå¹´ä»½è¯¦æƒ…:")

    for stats in all_stats:
        logger.info(f"  {stats['year']}: {stats['updated']}/{stats['total']} æˆåŠŸ")


if __name__ == "__main__":
    main()
