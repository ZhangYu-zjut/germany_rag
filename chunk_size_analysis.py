#!/usr/bin/env python3
"""
åˆ†æåˆ†å—å¤§å°å¯¹è¿ç§»æ•ˆç‡çš„å½±å“
å¯¹æ¯”ä¸åŒchunk_sizeçš„æ€§èƒ½å·®å¼‚
"""

import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).resolve().parent
sys.path.append(str(project_root))

def analyze_chunk_size_impact():
    """åˆ†æåˆ†å—å¤§å°å¯¹è¿ç§»æ•ˆç‡çš„å½±å“"""
    print("ğŸ“Š åˆ†å—å¤§å°å¯¹è¿ç§»æ•ˆç‡çš„å½±å“åˆ†æ")
    print("=" * 60)
    
    # å‡è®¾åœºæ™¯ï¼š2015å¹´æ•°æ®åˆ†æ
    original_data_size = 50_000_000  # 50MBåŸå§‹æ–‡æœ¬
    
    chunk_scenarios = [
        {
            "chunk_size": 1000,
            "overlap": 100,
            "description": "å½“å‰é…ç½®",
        },
        {
            "chunk_size": 2000, 
            "overlap": 200,
            "description": "ä¸­ç­‰å—å¤§å°",
        },
        {
            "chunk_size": 4000,
            "overlap": 400, 
            "description": "å¤§å—å¤§å°ï¼ˆç”¨æˆ·å»ºè®®ï¼‰",
        },
        {
            "chunk_size": 8000,
            "overlap": 800,
            "description": "æå¤§å—å¤§å°",
        }
    ]
    
    print("ğŸ” ä¸åŒåˆ†å—ç­–ç•¥å¯¹æ¯”:")
    print("å—å¤§å°  |  é¢„ä¼°å—æ•°  |  ä¼ è¾“æ¬¡æ•°  |  embeddingæ—¶é—´  |  å­˜å‚¨æ—¶é—´  |  æ€»æ—¶é—´  |  ä¼˜ç¼ºç‚¹")
    print("-" * 100)
    
    for scenario in chunk_scenarios:
        chunk_size = scenario["chunk_size"]
        overlap = scenario["overlap"]
        
        # ä¼°ç®—å—æ•°é‡ (è€ƒè™‘é‡å )
        effective_chunk_size = chunk_size - overlap
        estimated_chunks = original_data_size // effective_chunk_size
        
        # ä¼°ç®—ä¼ è¾“æ—¶é—´ (åŸºäºå®é™…æµ‹è¯•æ•°æ®)
        embedding_time_per_chunk = 1 / 503.4  # ç§’/chunk (åŸºäº128æ‰¹æ¬¡)
        storage_time_per_chunk = 1 / 40.7     # ç§’/chunk (åŸºäº50æ‰¹æ¬¡)
        
        total_embedding_time = estimated_chunks * embedding_time_per_chunk
        total_storage_time = estimated_chunks * storage_time_per_chunk
        total_time = total_embedding_time + total_storage_time
        
        # ä¼ è¾“æ¬¡æ•°ä¼°ç®— (åŸºäºæ‰¹æ¬¡)
        embedding_batches = estimated_chunks // 128 + (1 if estimated_chunks % 128 else 0)
        storage_batches = estimated_chunks // 50 + (1 if estimated_chunks % 50 else 0)
        total_api_calls = embedding_batches + storage_batches
        
        # ä¼˜ç¼ºç‚¹åˆ†æ
        if chunk_size <= 1000:
            pros_cons = "ç»†ç²’åº¦ï¼Œç²¾ç¡®æ£€ç´¢ï¼Œä½†å—æ•°å¤š"
        elif chunk_size <= 2000:
            pros_cons = "å¹³è¡¡æ€§èƒ½å’Œç²¾åº¦"
        elif chunk_size <= 4000:
            pros_cons = "å‡å°‘ä¼ è¾“ï¼Œä½†å¯èƒ½å½±å“æ£€ç´¢ç²¾åº¦"
        else:
            pros_cons = "æœ€å°‘ä¼ è¾“ï¼Œä½†æ£€ç´¢ç²¾åº¦å¤§å¹…ä¸‹é™"
        
        print(f" {chunk_size:4d}   |  {estimated_chunks:8,d}  |   {total_api_calls:6d}   |    {total_embedding_time:8.1f}s   |   {total_storage_time:7.1f}s   | {total_time:6.1f}s | {pros_cons}")
    
    print("\nğŸ’¡ åˆ†å—å¤§å°ä¼˜åŒ–åˆ†æ:")
    print("1. ğŸ“‰ å‡å°‘å—æ•°é‡ï¼š4000å­—ç¬¦ç¡®å®èƒ½å‡å°‘ä¼ è¾“æ¬¡æ•°çº¦75%")
    print("2. âš¡ æ€§èƒ½æå‡ï¼šæ€»å¤„ç†æ—¶é—´å¯å‡å°‘çº¦75%") 
    print("3. âš ï¸  æ£€ç´¢ç²¾åº¦é£é™©ï¼šå¤§å—å¯èƒ½å½±å“è¯­ä¹‰æ£€ç´¢å‡†ç¡®æ€§")
    print("4. ğŸ§  å†…å­˜å½±å“ï¼šæ›´å¤§çš„å—éœ€è¦æ›´å¤šembeddingå†…å­˜")
    
    print("\nğŸ¯ å»ºè®®:")
    print("- ğŸ“Š å½“å‰1000å­—ç¬¦ï¼šé€‚åˆç²¾ç¡®æ£€ç´¢ï¼Œä½†ä¼ è¾“é‡å¤§")
    print("- ğŸš€ 4000å­—ç¬¦ä¼˜åŒ–ï¼šæ˜¾è‘—å‡å°‘ä¼ è¾“æ—¶é—´ï¼Œæ¨èå°è¯•")
    print("- âš–ï¸  å¹³è¡¡æ–¹æ¡ˆï¼š2000-3000å­—ç¬¦å¯èƒ½æ˜¯æœ€ä½³å¹³è¡¡ç‚¹")
    
def calculate_memory_impact():
    """è®¡ç®—ä¸åŒåˆ†å—å¤§å°å¯¹å†…å­˜çš„å½±å“"""
    print("\nğŸ§  å†…å­˜å½±å“åˆ†æ:")
    print("=" * 40)
    
    chunk_sizes = [1000, 2000, 4000, 8000]
    batch_size = 128
    
    for chunk_size in chunk_sizes:
        # ä¼°ç®—å†…å­˜ä½¿ç”¨ (ç²—ç•¥è®¡ç®—)
        # æ¯ä¸ªå­—ç¬¦çº¦1-2å­—èŠ‚ï¼Œembeddingå‘é‡1024ç»´*4å­—èŠ‚
        text_memory_mb = (chunk_size * batch_size * 2) / (1024*1024)  # æ–‡æœ¬å†…å­˜
        vector_memory_mb = (1024 * 4 * batch_size) / (1024*1024)      # å‘é‡å†…å­˜
        total_memory_mb = text_memory_mb + vector_memory_mb
        
        print(f"å—å¤§å°{chunk_size:4d}: æ–‡æœ¬{text_memory_mb:5.1f}MB + å‘é‡{vector_memory_mb:5.1f}MB = æ€»è®¡{total_memory_mb:5.1f}MB")
    
    print("\nğŸ“Š å†…å­˜ç»“è®º:")
    print("- GPUæ˜¾å­˜16GBè¶³å¤Ÿå¤„ç†ä»»ä½•åˆç†çš„åˆ†å—å¤§å°") 
    print("- 4000å­—ç¬¦åˆ†å—ä¸ä¼šé€ æˆå†…å­˜é—®é¢˜")
    print("- ä¸»è¦é™åˆ¶æ˜¯ç½‘ç»œä¼ è¾“ï¼Œä¸æ˜¯å†…å­˜")

if __name__ == "__main__":
    analyze_chunk_size_impact()
    calculate_memory_impact()
