#!/usr/bin/env python3
"""
Pinecone RAGç³»ç»Ÿç«¯åˆ°ç«¯æµ‹è¯•
éªŒè¯2015å¹´æ•°æ®çš„å®Œæ•´RAGæµç¨‹ï¼šæ£€ç´¢ -> ç”Ÿæˆç­”æ¡ˆ
æµ‹è¯•ä¸åŒç±»å‹çš„é—®é¢˜ï¼šæ€»ç»“ç±»ã€å¯¹æ¯”ç±»ã€è§‚ç‚¹ç±»
"""

import os
import sys
import time
import json
from pathlib import Path
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).resolve().parent
sys.path.append(str(project_root))

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(project_root / ".env", override=True)

from src.utils.logger import setup_logger
from src.llm.embeddings import GeminiEmbeddingClient
from pinecone import Pinecone

logger = setup_logger()


class SimplePineconeRAG:
    """ç®€åŒ–çš„Pinecone RAGç³»ç»Ÿ"""

    def __init__(self):
        """åˆå§‹åŒ–RAGç³»ç»Ÿ"""
        logger.info("ğŸ”§ åˆå§‹åŒ–Pinecone RAGç³»ç»Ÿ")

        # åˆå§‹åŒ–Embeddingå®¢æˆ·ç«¯
        self.embedding_client = GeminiEmbeddingClient(
            embedding_mode="local",
            model_name="BAAI/bge-m3",
            dimensions=1024
        )
        logger.info("âœ… BGE-M3 Embeddingå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")

        # åˆå§‹åŒ–Pinecone
        api_key = os.getenv("PINECONE_VECTOR_DATABASE_API_KEY")
        self.pc = Pinecone(api_key=api_key)
        self.index = self.pc.Index("german-bge")
        logger.info("âœ… Pineconeå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")

        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯ï¼ˆä½¿ç”¨é¡¹ç›®ä¸­çš„GeminiLLMClientï¼‰
        from src.llm.client import GeminiLLMClient
        self.llm = GeminiLLMClient(temperature=0.0)
        logger.info("âœ… Gemini LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")

    def retrieve(self, question: str, top_k: int = 10, year_filter: str = None):
        """
        æ£€ç´¢ç›¸å…³æ–‡æ¡£

        Args:
            question: é—®é¢˜
            top_k: æ£€ç´¢æ•°é‡
            year_filter: å¹´ä»½è¿‡æ»¤ï¼ˆä¾‹å¦‚ "2015"ï¼‰

        Returns:
            æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        logger.info(f"ğŸ” æ£€ç´¢é—®é¢˜: {question}")
        start_time = time.time()

        # ç”Ÿæˆé—®é¢˜çš„embedding
        query_vector = self.embedding_client.embed_text(question)

        # å‡†å¤‡è¿‡æ»¤æ¡ä»¶
        filter_dict = {}
        if year_filter:
            filter_dict["year"] = {"$eq": year_filter}

        # æ‰§è¡ŒPineconeæŸ¥è¯¢
        query_params = {
            "vector": query_vector,
            "top_k": top_k,
            "include_metadata": True
        }
        if filter_dict:
            query_params["filter"] = filter_dict

        results = self.index.query(**query_params)

        retrieval_time = time.time() - start_time

        # æå–ç»“æœ
        chunks = []
        for match in results.matches:
            chunks.append({
                "id": match.id,
                "score": match.score,
                "text": match.metadata.get("text", ""),
                "speaker": match.metadata.get("speaker", ""),
                "date": match.metadata.get("date", ""),
                "group": match.metadata.get("group", ""),
                "metadata": match.metadata
            })

        logger.info(f"âœ… æ£€ç´¢å®Œæˆ: {len(chunks)}ä¸ªç»“æœï¼Œè€—æ—¶{retrieval_time:.2f}ç§’")

        return chunks, retrieval_time

    def generate_answer(self, question: str, chunks: list):
        """
        åŸºäºæ£€ç´¢ç»“æœç”Ÿæˆç­”æ¡ˆ

        Args:
            question: é—®é¢˜
            chunks: æ£€ç´¢åˆ°çš„æ–‡æ¡£å—

        Returns:
            ç”Ÿæˆçš„ç­”æ¡ˆ
        """
        logger.info(f"ğŸ§  ç”Ÿæˆç­”æ¡ˆ: {question}")
        start_time = time.time()

        # æ„å»ºä¸Šä¸‹æ–‡
        context_parts = []
        for i, chunk in enumerate(chunks[:5], 1):  # åªä½¿ç”¨top 5
            context_parts.append(
                f"[æ–‡æ¡£{i}]\n"
                f"å‘è¨€äºº: {chunk['speaker']}\n"
                f"æ—¥æœŸ: {chunk['date']}\n"
                f"å…šæ´¾: {chunk['group']}\n"
                f"ç›¸ä¼¼åº¦: {chunk['score']:.4f}\n"
                f"å†…å®¹: {chunk['text'][:500]}\n"
            )

        context = "\n\n".join(context_parts)

        # æ„å»ºprompt
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¾·å›½è®®ä¼šæ¼”è®²åˆ†æåŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹æ£€ç´¢åˆ°çš„å¾·å›½è®®ä¼šæ¼”è®²å†…å®¹ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

é—®é¢˜: {question}

æ£€ç´¢åˆ°çš„ç›¸å…³æ¼”è®²å†…å®¹:
{context}

è¯·æ ¹æ®ä¸Šè¿°å†…å®¹ï¼Œç”¨ä¸­æ–‡æä¾›ä¸€ä¸ªå…¨é¢ã€å‡†ç¡®çš„å›ç­”ã€‚è¦æ±‚ï¼š
1. å¦‚æœæ£€ç´¢å†…å®¹å……åˆ†ï¼Œç»™å‡ºè¯¦ç»†å›ç­”
2. å¦‚æœæ£€ç´¢å†…å®¹ä¸è¶³ï¼Œè¯´æ˜ç°æœ‰ææ–™çš„å±€é™æ€§
3. å¼•ç”¨å…·ä½“çš„å‘è¨€äººå’Œæ—¥æœŸ
4. ä¿æŒå®¢è§‚å’Œå‡†ç¡®

å›ç­”:"""

        # è°ƒç”¨LLMç”Ÿæˆç­”æ¡ˆ
        try:
            answer = self.llm.invoke(prompt)
            generation_time = time.time() - start_time

            logger.info(f"âœ… ç­”æ¡ˆç”Ÿæˆå®Œæˆï¼Œè€—æ—¶{generation_time:.2f}ç§’")
            return answer, generation_time

        except Exception as e:
            logger.error(f"âŒ ç­”æ¡ˆç”Ÿæˆå¤±è´¥: {str(e)}")
            return f"ç­”æ¡ˆç”Ÿæˆå¤±è´¥: {str(e)}", time.time() - start_time

    def answer_question(self, question: str, year_filter: str = None):
        """
        å®Œæ•´çš„RAGé—®ç­”æµç¨‹

        Args:
            question: é—®é¢˜
            year_filter: å¹´ä»½è¿‡æ»¤

        Returns:
            ç­”æ¡ˆå’Œæ€§èƒ½æŒ‡æ ‡
        """
        total_start = time.time()

        # æ£€ç´¢
        chunks, retrieval_time = self.retrieve(question, top_k=10, year_filter=year_filter)

        if not chunks:
            return {
                "question": question,
                "answer": "æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£",
                "retrieval_count": 0,
                "retrieval_time": retrieval_time,
                "generation_time": 0,
                "total_time": time.time() - total_start
            }

        # ç”Ÿæˆç­”æ¡ˆ
        answer, generation_time = self.generate_answer(question, chunks)

        total_time = time.time() - total_start

        return {
            "question": question,
            "answer": answer,
            "retrieval_count": len(chunks),
            "top_scores": [c["score"] for c in chunks[:3]],
            "retrieval_time": retrieval_time,
            "generation_time": generation_time,
            "total_time": total_time
        }


def test_rag_system():
    """æµ‹è¯•RAGç³»ç»Ÿ"""
    logger.info("ğŸš€ å¼€å§‹Pinecone RAGç«¯åˆ°ç«¯æµ‹è¯•")
    logger.info("=" * 80)

    # åˆå§‹åŒ–RAGç³»ç»Ÿ
    rag = SimplePineconeRAG()

    # æµ‹è¯•é—®é¢˜é›†ï¼ˆä¸åŒç±»å‹ï¼‰
    test_cases = [
        {
            "name": "æ€»ç»“ç±»é—®é¢˜",
            "question": "è¯·æ€»ç»“2015å¹´å¾·å›½è®®ä¼šå…³äºéš¾æ°‘æ”¿ç­–çš„ä¸»è¦è®¨è®ºå†…å®¹",
            "year_filter": "2015"
        },
        {
            "name": "å¯¹æ¯”ç±»é—®é¢˜",
            "question": "CDU/CSUå’ŒSPDåœ¨2015å¹´å¯¹éš¾æ°‘æ”¿ç­–çš„ç«‹åœºæœ‰ä»€ä¹ˆä¸åŒï¼Ÿ",
            "year_filter": "2015"
        },
        {
            "name": "è§‚ç‚¹ç±»é—®é¢˜",
            "question": "2015å¹´å¾·å›½è®®ä¼šè®®å‘˜å¯¹æ¬§ç›Ÿä¸€ä½“åŒ–çš„ä¸»è¦è§‚ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ",
            "year_filter": "2015"
        },
        {
            "name": "äº‹å®æŸ¥è¯¢é—®é¢˜",
            "question": "2015å¹´å¾·å›½è®®ä¼šæœ‰å“ªäº›é‡è¦æ³•æ¡ˆè¢«è®¨è®ºï¼Ÿ",
            "year_filter": "2015"
        }
    ]

    results = []

    # æµ‹è¯•æ¯ä¸ªé—®é¢˜
    for i, test_case in enumerate(test_cases, 1):
        print(f"\n{'='*80}")
        print(f"ğŸ“ æµ‹è¯• {i}/{len(test_cases)}: {test_case['name']}")
        print(f"   é—®é¢˜: {test_case['question']}")
        print('='*80)

        try:
            result = rag.answer_question(
                question=test_case["question"],
                year_filter=test_case.get("year_filter")
            )

            results.append({
                "test_name": test_case["name"],
                **result
            })

            # æ˜¾ç¤ºç»“æœ
            print(f"\nğŸ“Š æ€§èƒ½æŒ‡æ ‡:")
            print(f"   æ£€ç´¢æ—¶é—´: {result['retrieval_time']:.2f}ç§’")
            print(f"   ç”Ÿæˆæ—¶é—´: {result['generation_time']:.2f}ç§’")
            print(f"   æ€»è€—æ—¶: {result['total_time']:.2f}ç§’")
            print(f"   æ£€ç´¢æ–‡æ¡£æ•°: {result['retrieval_count']}")
            if result['top_scores']:
                print(f"   Top-3ç›¸ä¼¼åº¦: {[f'{s:.4f}' for s in result['top_scores']]}")

            print(f"\nğŸ“„ ç”Ÿæˆç­”æ¡ˆ:")
            print(result['answer'])
            print()

        except Exception as e:
            logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
            print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            continue

    # æ€»ç»“ç»Ÿè®¡
    print(f"\n{'='*80}")
    print("ğŸ“Š æµ‹è¯•æ€»ç»“ç»Ÿè®¡")
    print('='*80)

    if results:
        avg_retrieval_time = sum(r['retrieval_time'] for r in results) / len(results)
        avg_generation_time = sum(r['generation_time'] for r in results) / len(results)
        avg_total_time = sum(r['total_time'] for r in results) / len(results)
        avg_retrieval_count = sum(r['retrieval_count'] for r in results) / len(results)

        print(f"âœ… æˆåŠŸæµ‹è¯•: {len(results)}/{len(test_cases)}")
        print(f"\nâ±ï¸  å¹³å‡æ€§èƒ½:")
        print(f"   æ£€ç´¢æ—¶é—´: {avg_retrieval_time:.2f}ç§’")
        print(f"   ç”Ÿæˆæ—¶é—´: {avg_generation_time:.2f}ç§’")
        print(f"   æ€»è€—æ—¶: {avg_total_time:.2f}ç§’")
        print(f"   æ£€ç´¢æ–‡æ¡£æ•°: {avg_retrieval_count:.1f}")

        # ä¿å­˜ç»“æœåˆ°JSON
        output_file = project_root / "rag_test_results.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

    else:
        print(f"âŒ æ‰€æœ‰æµ‹è¯•å¤±è´¥")
        return 1

    print(f"\n{'='*80}")
    print("ğŸ‰ Pinecone RAGç«¯åˆ°ç«¯æµ‹è¯•å®Œæˆï¼")
    print('='*80)

    return 0


def main():
    """ä¸»å‡½æ•°"""
    try:
        return test_rag_system()
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•ç¨‹åºå¼‚å¸¸: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit(main())
