#!/usr/bin/env python3
"""
å®Œæ•´LangGraph Workflowæµ‹è¯•ï¼ˆåŒ…å«ReRankï¼‰
å¯¹æ¯”ä¸ç®€åŒ–è„šæœ¬çš„ç­”æ¡ˆè´¨é‡å·®å¼‚
"""

import os
import sys
import time
import json
from pathlib import Path
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).resolve().parent
sys.path.append(str(project_root))

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(project_root / ".env", override=True)

from src.utils.logger import setup_logger
from src.graph.workflow import QuestionAnswerWorkflow

logger = setup_logger()


def test_complete_workflow():
    """æµ‹è¯•å®Œæ•´çš„LangGraph workflow"""

    logger.info("="*80)
    logger.info("ğŸ§ª å¼€å§‹å®Œæ•´Workflowæµ‹è¯•ï¼ˆåŒ…å«ReRankï¼‰")
    logger.info("="*80)

    # åˆå§‹åŒ–workflow
    logger.info("ğŸ”§ åˆå§‹åŒ–QuestionAnswerWorkflow...")
    workflow = QuestionAnswerWorkflow()
    logger.info("âœ… Workflowåˆå§‹åŒ–å®Œæˆ")

    # æµ‹è¯•é—®é¢˜ï¼ˆä¸ç®€åŒ–è„šæœ¬ç›¸åŒï¼‰
    test_questions = [
        {
            "id": "Q1",
            "type": "æ€»ç»“ç±»",
            "question": "è¯·æ€»ç»“2015å¹´å¾·å›½è®®ä¼šå…³äºéš¾æ°‘æ”¿ç­–çš„ä¸»è¦è®¨è®ºå†…å®¹"
        },
        {
            "id": "Q2",
            "type": "å¯¹æ¯”ç±»",
            "question": "CDU/CSUå’ŒSPDåœ¨2015å¹´å¯¹éš¾æ°‘æ”¿ç­–çš„ç«‹åœºæœ‰ä»€ä¹ˆä¸åŒï¼Ÿ"
        },
        {
            "id": "Q3",
            "type": "è§‚ç‚¹ç±»",
            "question": "2015å¹´å¾·å›½è®®ä¼šè®®å‘˜å¯¹æ¬§ç›Ÿä¸€ä½“åŒ–çš„ä¸»è¦è§‚ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ"
        },
        {
            "id": "Q4",
            "type": "äº‹å®æŸ¥è¯¢",
            "question": "2015å¹´å¾·å›½è®®ä¼šæœ‰å“ªäº›é‡è¦æ³•æ¡ˆè¢«è®¨è®ºï¼Ÿ"
        }
    ]

    results = []

    for test_case in test_questions:
        logger.info(f"\n{'='*80}")
        logger.info(f"ğŸ” æµ‹è¯•é—®é¢˜ {test_case['id']}: {test_case['type']}")
        logger.info(f"   é—®é¢˜: {test_case['question']}")
        logger.info(f"{'='*80}\n")

        start_time = time.time()

        try:
            # è°ƒç”¨å®Œæ•´workflow
            result = workflow.run(test_case['question'])

            total_time = time.time() - start_time

            # æå–ç­”æ¡ˆå’Œä¸­é—´çŠ¶æ€
            answer = result.get("final_answer", "")
            intent_result = result.get("intent_result", {})
            classify_result = result.get("classify_result", {})
            extract_result = result.get("extract_result", {})
            decompose_result = result.get("decompose_result", {})
            retrieval_results = result.get("retrieval_results", [])
            rerank_results = result.get("rerank_results", [])

            # ç»Ÿè®¡æ£€ç´¢å’Œrerankä¿¡æ¯
            total_chunks_before_rerank = sum(len(r.get("chunks", [])) for r in retrieval_results)
            total_chunks_after_rerank = sum(len(r.get("reranked_chunks", [])) for r in rerank_results)

            logger.info(f"âœ… {test_case['id']} å®Œæˆ")
            logger.info(f"   æ€»è€—æ—¶: {total_time:.2f} ç§’")
            logger.info(f"   æ„å›¾åˆ†æ: {intent_result.get('intent_type', 'N/A')}")
            logger.info(f"   é—®é¢˜ç±»å‹: {classify_result.get('question_type', 'N/A')}")
            logger.info(f"   æ£€ç´¢å‰å—æ•°: {total_chunks_before_rerank}")
            logger.info(f"   ReRankåå—æ•°: {total_chunks_after_rerank}")
            logger.info(f"   ç­”æ¡ˆé•¿åº¦: {len(answer)} å­—ç¬¦")

            # æ˜¾ç¤ºå‰200å­—ç¬¦ç­”æ¡ˆé¢„è§ˆ
            preview = answer[:200] + "..." if len(answer) > 200 else answer
            logger.info(f"\nğŸ“ ç­”æ¡ˆé¢„è§ˆ:\n{preview}\n")

            # æ”¶é›†ç»“æœ
            test_result = {
                "question_id": test_case['id'],
                "question_type": test_case['type'],
                "question": test_case['question'],
                "total_time": round(total_time, 2),
                "intent_type": intent_result.get('intent_type', 'N/A'),
                "classify_type": classify_result.get('question_type', 'N/A'),
                "extract_params": extract_result,
                "sub_questions": decompose_result.get('sub_questions', []),
                "chunks_before_rerank": total_chunks_before_rerank,
                "chunks_after_rerank": total_chunks_after_rerank,
                "answer": answer,
                "full_state": result
            }

            results.append(test_result)

        except Exception as e:
            logger.error(f"âŒ {test_case['id']} å¤±è´¥: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())

            results.append({
                "question_id": test_case['id'],
                "question_type": test_case['type'],
                "question": test_case['question'],
                "status": "failed",
                "error": str(e)
            })

    # ä¿å­˜ç»“æœ
    logger.info(f"\n{'='*80}")
    logger.info("ğŸ’¾ ä¿å­˜æµ‹è¯•ç»“æœ...")
    logger.info(f"{'='*80}\n")

    # ä¿å­˜è¯¦ç»†JSON
    output_file = project_root / "complete_workflow_results.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    logger.info(f"âœ… è¯¦ç»†ç»“æœå·²ä¿å­˜: {output_file}")

    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    generate_comparison_report(results)

    return results


def generate_comparison_report(results):
    """ç”Ÿæˆä¸ç®€åŒ–è„šæœ¬çš„å¯¹æ¯”æŠ¥å‘Š"""

    logger.info("ğŸ“Š ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š...")

    report_file = project_root / "WORKFLOW_COMPARISON_REPORT.md"

    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("# å®Œæ•´Workflow vs ç®€åŒ–è„šæœ¬å¯¹æ¯”æŠ¥å‘Š\n\n")
        f.write("## æµ‹è¯•é…ç½®\n\n")
        f.write("- **æµ‹è¯•æ—¶é—´**: " + time.strftime("%Y-%m-%d %H:%M:%S") + "\n")
        f.write("- **æ•°æ®èŒƒå›´**: 2015å¹´å¾·å›½è®®ä¼šæ•°æ®\n")
        f.write("- **Workflow**: LangGraph CoA (Chain of Agents)\n")
        f.write("- **ReRank**: Cohere rerank-v3.5\n")
        f.write("- **Embedding**: BGE-M3 (local, 1024-dim)\n")
        f.write("- **Vector DB**: Pinecone (german-bge index)\n\n")

        f.write("## æµ‹è¯•ç»“æœå¯¹æ¯”\n\n")

        for result in results:
            if result.get('status') == 'failed':
                f.write(f"### {result['question_id']}: {result['question_type']}\n\n")
                f.write(f"**é—®é¢˜**: {result['question']}\n\n")
                f.write(f"**çŠ¶æ€**: âŒ å¤±è´¥\n\n")
                f.write(f"**é”™è¯¯**: {result['error']}\n\n")
                f.write("---\n\n")
                continue

            f.write(f"### {result['question_id']}: {result['question_type']}\n\n")
            f.write(f"**é—®é¢˜**: {result['question']}\n\n")

            f.write(f"#### Workflowå¤„ç†æµç¨‹\n\n")
            f.write(f"- **æ„å›¾ç±»å‹**: {result['intent_type']}\n")
            f.write(f"- **é—®é¢˜åˆ†ç±»**: {result['classify_type']}\n")
            f.write(f"- **æå–å‚æ•°**: {json.dumps(result['extract_params'], ensure_ascii=False)}\n")
            f.write(f"- **å­é—®é¢˜æ•°**: {len(result.get('sub_questions', []))}\n")
            f.write(f"- **ReRankå‰**: {result['chunks_before_rerank']} ä¸ªæ–‡æ¡£å—\n")
            f.write(f"- **ReRankå**: {result['chunks_after_rerank']} ä¸ªæ–‡æ¡£å—\n")
            f.write(f"- **æ€»è€—æ—¶**: {result['total_time']} ç§’\n\n")

            f.write(f"#### å®Œæ•´Workflowç­”æ¡ˆ\n\n")
            f.write(f"```\n{result['answer']}\n```\n\n")

            f.write("#### ç­”æ¡ˆè´¨é‡åˆ†æ\n\n")
            f.write("å¾…äººå·¥è¯„ä¼°ï¼š\n")
            f.write("- [ ] ç­”æ¡ˆå®Œæ•´æ€§\n")
            f.write("- [ ] ä¿¡æ¯å‡†ç¡®æ€§\n")
            f.write("- [ ] å¼•ç”¨è´¨é‡\n")
            f.write("- [ ] é€»è¾‘è¿è´¯æ€§\n")
            f.write("- [ ] ä¸ç®€åŒ–è„šæœ¬å¯¹æ¯”\n\n")

            f.write("---\n\n")

        f.write("## æ€»ä½“å¯¹æ¯”\n\n")
        f.write("### å®Œæ•´Workflowä¼˜åŠ¿\n\n")
        f.write("1. **å¤šé˜¶æ®µå¤„ç†**: æ„å›¾åˆ†æ â†’ åˆ†ç±» â†’ å‚æ•°æå– â†’ åˆ†è§£ â†’ æ£€ç´¢ â†’ ReRank â†’ æ€»ç»“\n")
        f.write("2. **ReRankä¼˜åŒ–**: Cohere APIé‡æ–°æ’åºæ–‡æ¡£ï¼Œæå‡ç›¸å…³æ€§\n")
        f.write("3. **å­é—®é¢˜åˆ†è§£**: å¤æ‚é—®é¢˜æ‹†åˆ†ä¸ºå¤šä¸ªå­é—®é¢˜ï¼Œæ£€ç´¢æ›´ç²¾å‡†\n")
        f.write("4. **å‚æ•°æå–**: è‡ªåŠ¨æå–å¹´ä»½ã€å…šæ´¾ã€å‘è¨€äººç­‰è¿‡æ»¤æ¡ä»¶\n\n")

        f.write("### ç®€åŒ–è„šæœ¬ç‰¹ç‚¹\n\n")
        f.write("1. **ç›´æ¥æ£€ç´¢**: é—®é¢˜ â†’ Embedding â†’ PineconeæŸ¥è¯¢ â†’ LLMç”Ÿæˆ\n")
        f.write("2. **æ— ReRank**: ç›´æ¥ä½¿ç”¨å‘é‡ç›¸ä¼¼åº¦æ’åº\n")
        f.write("3. **å›ºå®štop_k**: æ£€ç´¢å›ºå®šæ•°é‡æ–‡æ¡£ï¼ˆ10ä¸ªï¼‰\n")
        f.write("4. **ç®€å•å¿«é€Ÿ**: é€‚åˆç®€å•é—®é¢˜ï¼Œè€—æ—¶æ›´çŸ­\n\n")

        f.write("### æ€§èƒ½å¯¹æ¯”\n\n")
        f.write("| æŒ‡æ ‡ | å®Œæ•´Workflow | ç®€åŒ–è„šæœ¬ |\n")
        f.write("|------|-------------|--------|\n")

        avg_time = sum(r['total_time'] for r in results if 'total_time' in r) / len([r for r in results if 'total_time' in r])
        f.write(f"| å¹³å‡è€—æ—¶ | {avg_time:.2f}ç§’ | 28-32ç§’ |\n")

        avg_chunks_before = sum(r['chunks_before_rerank'] for r in results if 'chunks_before_rerank' in r) / len([r for r in results if 'chunks_before_rerank' in r])
        avg_chunks_after = sum(r['chunks_after_rerank'] for r in results if 'chunks_after_rerank' in r) / len([r for r in results if 'chunks_after_rerank' in r])
        f.write(f"| æ–‡æ¡£å—æ•° | ReRankå‰: {avg_chunks_before:.1f}, ReRankå: {avg_chunks_after:.1f} | 10ä¸ª |\n")

        f.write("| å¤„ç†é˜¶æ®µ | 7ä¸ªèŠ‚ç‚¹ | 2æ­¥ï¼ˆæ£€ç´¢+ç”Ÿæˆï¼‰ |\n")
        f.write("| é€‚ç”¨åœºæ™¯ | å¤æ‚é—®é¢˜ | ç®€å•é—®é¢˜ |\n\n")

        f.write("## æ£€ç´¢å®Œæ•´æ€§åˆ†æ\n\n")
        f.write("### Q1é—®é¢˜ï¼š\"è¯·æ€»ç»“2015å¹´å¾·å›½è®®ä¼šå…³äºéš¾æ°‘æ”¿ç­–çš„ä¸»è¦è®¨è®ºå†…å®¹\"\n\n")
        f.write("**ç®€åŒ–è„šæœ¬ç­”æ¡ˆæåˆ°**: \"æ£€ç´¢åˆ°çš„å†…å®¹ä»…åŒ…å«2015å¹´5æœˆå’Œ10æœˆä¸¤ä¸ªæ—¶é—´ç‚¹çš„ä¸‰ä½å‘è¨€äººçš„è§‚ç‚¹\"\n\n")
        f.write("**éœ€è¦éªŒè¯**:\n")
        f.write("1. 2015å¹´å…¶ä»–æœˆä»½æ˜¯å¦è®¨è®ºäº†éš¾æ°‘æ”¿ç­–ï¼Ÿ\n")
        f.write("2. top_k=10æ˜¯å¦é™åˆ¶äº†æ£€ç´¢èŒƒå›´ï¼Ÿ\n")
        f.write("3. å®Œæ•´workflowçš„ReRankæ˜¯å¦æ£€ç´¢åˆ°æ›´å¤šæ—¶é—´ç‚¹ï¼Ÿ\n\n")

        # åˆ†æQ1çš„æ£€ç´¢ç»“æœ
        q1_result = next((r for r in results if r['question_id'] == 'Q1'), None)
        if q1_result and 'full_state' in q1_result:
            retrieval_results = q1_result['full_state'].get('retrieval_results', [])
            if retrieval_results:
                f.write("**å®Œæ•´Workflowæ£€ç´¢åˆ°çš„æ—¶é—´ç‚¹**:\n\n")
                dates = set()
                for retrieval in retrieval_results:
                    for chunk in retrieval.get('chunks', []):
                        metadata = chunk.get('metadata', {})
                        date = metadata.get('date', 'N/A')
                        if date != 'N/A':
                            dates.add(date)

                dates_sorted = sorted(list(dates))
                f.write(f"- å…± {len(dates_sorted)} ä¸ªä¸åŒæ—¥æœŸ\n")
                for date in dates_sorted[:20]:  # æ˜¾ç¤ºå‰20ä¸ª
                    f.write(f"- {date}\n")

                if len(dates_sorted) > 20:
                    f.write(f"- ... è¿˜æœ‰ {len(dates_sorted) - 20} ä¸ªæ—¥æœŸ\n")
                f.write("\n")

        f.write("## ç»“è®º\n\n")
        f.write("**å¾…å®Œæˆ**:\n")
        f.write("1. äººå·¥è¯„ä¼°ç­”æ¡ˆè´¨é‡å·®å¼‚\n")
        f.write("2. ç¡®è®¤æ£€ç´¢å®Œæ•´æ€§é—®é¢˜\n")
        f.write("3. å†³å®šç”Ÿäº§ç¯å¢ƒä½¿ç”¨å“ªç§æ–¹æ¡ˆ\n\n")

    logger.info(f"âœ… å¯¹æ¯”æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")


if __name__ == "__main__":
    try:
        results = test_complete_workflow()

        success_count = len([r for r in results if r.get('status') != 'failed'])
        failed_count = len([r for r in results if r.get('status') == 'failed'])

        logger.info(f"\n{'='*80}")
        logger.info(f"ğŸ‰ æµ‹è¯•å®Œæˆ!")
        logger.info(f"   æˆåŠŸ: {success_count}")
        logger.info(f"   å¤±è´¥: {failed_count}")
        logger.info(f"{'='*80}\n")

        exit(0 if failed_count == 0 else 1)

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        exit(1)
