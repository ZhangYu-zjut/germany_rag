# 检索和ReRank流程详解

**生成时间**: 2025-11-11
**目的**: 回答用户关于检索和ReRank阶段的文档数量、分数等问题

---

## 一、检索阶段 (Retrieve)

### 配置参数

**文件**: `src/graph/nodes/retrieve_pinecone.py`

```python
class PineconeRetrieveNode:
    def __init__(
        self,
        top_k: int = 50,              # 标准检索时的top-k
        limit_per_year: int = 5        # 多年份策略时每年的文档数
    ):
```

### 检索策略

#### 策略A: 标准检索 (单年或简单问题)
```
检索文档数 = top_k = 50
```

**示例**:
- Q2: "2017年各党派对专业人才移民的立场"
- 检索结果: 50个文档 (年份分布={'2017': 50})

---

#### 策略B: 多年份分层检索 (multi_year_stratified)
```
检索文档数 = 年份数 × limit_per_year
            = 年份数 × 5
```

**示例1 - Q1**:
- 问题: "2015年以来CDU/CSU对难民政策的变化"
- 涉及年份: 2015-2024 (10年)
- 每个子问题检索: **10年 × 5文档/年 = 50个文档**
- 子问题数: 10个
- **总检索文档数**: 10子问题 × 50文档 = **500个文档**

**示例2 - Q5**:
- 问题: "2015-2017年联盟党与绿党在移民融合的对比"
- 涉及年份: 2015-2017 (3年)
- 每个子问题检索: **3年 × 5文档/年 = 15个文档**
- 子问题数: 9个
- **总检索文档数**: 9子问题 × 15文档 = **135个文档**

---

### 检索分数

**分数类型**: Pinecone相似度分数 (Cosine Similarity)

**分数范围**: 0.0 ~ 1.0
- 1.0 = 完全相同
- 0.0 = 完全不相关

**Log中的记录**:
```
最高相似度: 0.6424
最高相似度: 0.6376
...
```

**每个文档都有相似度分数**,但log中只记录了最高分。

---

## 二、ReRank阶段

### 配置参数

**文件**: `src/graph/nodes/rerank.py`

```python
class ReRankNode:
    def __init__(self):
        self.top_n = 10  # 每个子问题最多返回10个重排后的文档
```

### ReRank流程

#### 对每个子问题单独重排序

```
输入: 50个检索到的文档 (从Retrieve阶段)
  ↓
[Cohere ReRank API]
  ↓
输出: Top 10个最相关的文档 (从50个中筛选)
```

**Log示例** (Q1的10个子问题):
```
[ReRankNode] 对 50 个文档进行重排序
[ReRankNode] 重排序完成，从 50 个文档中选出 10 个
[ReRankNode] 第 1 个问题重排序完成，保留 10 个文档

[ReRankNode] 对 50 个文档进行重排序
[ReRankNode] 重排序完成，从 50 个文档中选出 10 个
[ReRankNode] 第 2 个问题重排序完成，保留 10 个文档

... (重复10次)
```

---

### ReRank后的文档数量

#### Q1示例 (10个子问题)

```
Retrieve阶段:
  500个文档 (10子问题 × 50文档/子问题)

ReRank阶段:
  100个文档 (10子问题 × 10文档/子问题)

精简比例: 500 → 100 (保留20%)
```

#### 通用公式

```
ReRank后文档数 = 子问题数 × top_n
                = 子问题数 × 10
```

| 问题 | 子问题数 | Retrieve文档数 | ReRank后文档数 | 精简比例 |
|------|---------|---------------|---------------|---------|
| Q1 | 10 | 500 | 100 | 20% |
| Q2 | 1 | 50 | 10 | 20% |
| Q4 | 5 | 100 | 50 | 50% |
| Q5 | 9 | 135 | 90 | 67% |

---

### ReRank分数

**分数类型**: Cohere Relevance Score

**分数范围**: 0.0 ~ 1.0
- 1.0 = 最相关
- 0.0 = 不相关

**代码中的字段**:
```python
result = {
    'index': 原始文档在50个中的索引,
    'relevance_score': 0.8521,  # Cohere给出的相关性分数
    'document': {...}            # 原始文档数据
}
```

**Log中是否记录**:
- ❌ 当前log **没有记录** relevance_score
- 只有调试模式(`logger.debug`)会记录,但生产log是INFO级别

---

## 三、完整数据流 (以Q1为例)

### Q1: "请概述2015年以来德国基民盟对难民政策的立场变化"

```
1. Extract阶段:
   提取参数: {
       "years": ["2015", "2016", ..., "2024"],  # 10年
       "parties": ["CDU/CSU"],
       "topics": ["难民", "难民政策"]
   }

2. Decompose阶段:
   生成10个子问题:
   - 子问题1: "2015年CDU/CSU在难民、难民政策上的立场和观点是什么？"
   - 子问题2: "2016年CDU/CSU在难民、难民政策上的立场和观点是什么？"
   - ...
   - 子问题10: "2024年CDU/CSU在难民、难民政策上的立场和观点是什么？"

3. Retrieve阶段 (每个子问题):
   检索策略: multi_year_stratified(years=10, per_year=5)
   每个子问题检索: 10年 × 5文档 = 50个文档

   子问题1: 50个文档 (相似度: 0.6424 ~ 0.10)
     └─ 年份分布: {'2015': 5, '2016': 5, ..., '2024': 5}

   子问题2: 50个文档 (相似度: 0.6376 ~ 0.09)
     └─ 年份分布: {'2015': 5, '2016': 5, ..., '2024': 5}

   ... (重复10次)

   总检索文档数: 10子问题 × 50文档 = 500个文档

4. ReRank阶段 (每个子问题):
   输入: 50个文档
   Cohere ReRank: 从50个中选出top 10
   输出: 10个文档 (relevance_score: 0.95 ~ 0.45)

   子问题1: 10个文档 (relevance_score排序)
   子问题2: 10个文档 (relevance_score排序)
   ... (重复10次)

   总ReRank后文档数: 10子问题 × 10文档 = 100个文档

5. Summarize阶段:
   输入: 100个重排后的文档
   LLM生成: 逐个总结10个子问题 → 合并为最终答案
   输出: 最终答案 + Quellen引用
```

---

## 四、分数信息总结

### 当前Log中记录的分数

| 阶段 | 分数类型 | 是否记录 | 记录内容 |
|------|---------|---------|---------|
| **Retrieve** | Pinecone相似度 | ✅ 部分 | 只记录最高相似度 |
| **ReRank** | Cohere relevance_score | ❌ 无 | Log未记录 |

### 如果要获取完整分数信息

需要在代码中保存:
1. Retrieve阶段: 每个文档的`score`字段
2. ReRank阶段: 每个文档的`relevance_score`字段

**建议**: 在`--full_refer`模式下保存完整分数到JSON

```json
{
  "question": "...",
  "retrieval_results": [
    {
      "sub_question": "...",
      "chunks": [
        {
          "text": "...",
          "metadata": {...},
          "similarity_score": 0.6424,      # ← Pinecone分数
          "rerank_score": 0.8521,          # ← Cohere分数 (ReRank后)
          "final_rank": 1                   # ← 最终排名
        }
      ]
    }
  ]
}
```

---

## 五、回答用户的问题

### Q1: 每个子问题最多检索多少个文档?

**A**: **50个文档**

- 标准检索: top_k=50
- 多年份检索: 年份数 × 5 (例如10年 × 5 = 50)

---

### Q2: ReRank是对所有问题的文档一起排序,还是对每个子问题单独排序?

**A**: **对每个子问题单独排序**

每个子问题:
- 输入: 50个检索到的文档
- 处理: Cohere ReRank
- 输出: Top 10个文档

不是全局排序,而是每个子问题独立重排。

---

### Q3: ReRank后每个子问题保留多少个文档?

**A**: **10个文档** (top_n=10)

从50个中筛选出10个最相关的。

---

### Q4: 是否有检索相似度分数和ReRank分数?

**A**:
- ✅ **检索相似度** (Pinecone): 有,每个文档都有,但log只记录最高值
- ✅ **ReRank分数** (Cohere): 有,但log没有记录

**要获取完整分数**: 需要实施`--full_refer`模式,保存到JSON。

---

## 六、对方案选择的影响

### 方案A (从Log+Pinecone提取) 的局限性

**任务一**: 从Log提取Quellen
- ❌ Log中**没有**完整的chunk文本
- ❌ Log中**没有**rerank_score
- ⚠️ 只能通过speaker+date重新查询Pinecone

**任务二**: 宽泛检索
- ✅ 可行,直接查询Pinecone

---

### 方案C (--full_refer参数) 的优势

**保存完整信息**:
```json
{
  "retrieval_results": [
    {
      "chunks": [
        {
          "text": "完整原文...",           # ← 任务一需要
          "metadata": {...},
          "similarity_score": 0.6424,    # ← 可选
          "rerank_score": 0.8521         # ← 可选
        }
      ]
    }
  ],
  "reranked_results": [
    {
      "chunks": [...]  # Top 10重排后的文档
    }
  ]
}
```

**好处**:
- ✅ 任务一: 直接提取reranked_results中的文本,无需重新查询
- ✅ 任务二: 可以从parameters直接查询
- ✅ 可追溯: 保留完整的相似度和rerank分数
- ✅ 可验证: 可以对比检索质量

---

## 七、推荐方案

基于以上分析,**强烈推荐方案C (--full_refer参数)**

**理由**:
1. Log中没有完整文本和分数,方案A需要大量重新查询
2. 方案C一次运行,保存所有需要的信息
3. 方案C可以生成更详细的分析报告(包含分数对比)

**实施成本**:
- 代码修改: 2-3小时
- 重新运行测试: 10-20分钟(已优化后)
- 生成MD文档: 1小时

**总计**: 约半天时间,一次性解决所有需求。
