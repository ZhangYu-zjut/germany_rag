"""
ç”Ÿæˆå¸¦ä¸­æ–‡ç¿»è¯‘çš„é—®ç­”æŠ¥å‘Š
ä½¿ç”¨Gemini LLMç¿»è¯‘å¾·è¯­ç­”æ¡ˆä¸ºä¸­æ–‡
"""

import json
from datetime import datetime
from src.llm.client import GeminiLLMClient

def translate_german_to_chinese(german_text, llm_client):
    """ä½¿ç”¨LLMç¿»è¯‘å¾·è¯­æ–‡æœ¬ä¸ºä¸­æ–‡"""

    prompt = f"""è¯·å°†ä»¥ä¸‹å¾·è¯­æ–‡æœ¬ç¿»è¯‘æˆä¸­æ–‡ã€‚è¿™æ˜¯å¾·å›½è®®ä¼šç›¸å…³çš„æ”¿æ²»åˆ†ææ–‡æœ¬ã€‚

è¦æ±‚ï¼š
1. ä¿æŒä¸“ä¸šæœ¯è¯­çš„å‡†ç¡®æ€§
2. ä¿ç•™åŸæ–‡çš„ç»“æ„ï¼ˆå¦‚**æ ‡é¢˜**ã€åˆ—è¡¨ç­‰ï¼‰
3. å…šæ´¾åç§°ç¿»è¯‘ï¼š
   - CDU/CSU â†’ åŸºæ°‘ç›Ÿ/åŸºç¤¾ç›Ÿ
   - SPD â†’ ç¤¾æ°‘å…š
   - BÃœNDNIS 90/DIE GRÃœNEN æˆ– GrÃ¼ne/BÃ¼ndnis 90 â†’ ç»¿å…š
   - DIE LINKE â†’ å·¦ç¿¼å…š
   - AfD â†’ é€‰æ‹©å…š
   - FDP â†’ è‡ªæ°‘å…š
4. ä¿æŒå¼•ç”¨å’Œæ¥æºä¿¡æ¯çš„æ ¼å¼

å¾·è¯­åŸæ–‡ï¼š
{german_text}

è¯·ç›´æ¥è¾“å‡ºä¸­æ–‡ç¿»è¯‘ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šã€‚"""

    try:
        translation = llm_client.invoke(prompt)
        return translation
    except Exception as e:
        return f"[ç¿»è¯‘å¤±è´¥: {str(e)}]\n\n{german_text}"


def generate_chinese_report_with_translation(results_file, output_file):
    """ç”Ÿæˆå¸¦ä¸­æ–‡ç¿»è¯‘çš„é—®ç­”æŠ¥å‘Š"""

    print("æ­£åœ¨åˆå§‹åŒ–LLMå®¢æˆ·ç«¯...")
    llm_client = GeminiLLMClient()

    with open(results_file, 'r', encoding='utf-8') as f:
        results = json.load(f)

    lines = []

    # æ ‡é¢˜
    lines.append('# å¾·å›½è®®ä¼šRAGç³»ç»Ÿé—®ç­”æŠ¥å‘Š (ä¸­æ–‡ç¿»è¯‘ç‰ˆ)\n\n')
    lines.append('**æµ‹è¯•æ—¶é—´**: 2025-11-07\n')
    lines.append('**ç³»ç»Ÿ**: åŸºäºLangGraphçš„RAGç³»ç»Ÿï¼Œä½¿ç”¨BGE-M3åµŒå…¥æ¨¡å‹\n')
    lines.append('**æ•°æ®åº“**: Pinecone (173,355ä¸ªå‘é‡, 2015-2024å¹´)\n')
    lines.append('**æˆåŠŸç‡**: 7/7 (100%)\n\n')
    lines.append('> **è¯´æ˜**: æœ¬æŠ¥å‘Šå°†ç³»ç»Ÿç”Ÿæˆçš„å¾·è¯­ç­”æ¡ˆç¿»è¯‘ä¸ºä¸­æ–‡ï¼Œæ–¹ä¾¿é˜…è¯»ç†è§£ã€‚\n\n')
    lines.append('---\n\n')

    # æ¯ä¸ªé—®é¢˜
    for i, r in enumerate(results, 1):
        q_id = r.get('question_id')
        question = r.get('question', '')
        answer = r.get('final_answer', '')
        q_type = r.get('type', 'N/A')

        print(f"\nå¤„ç†é—®é¢˜ {q_id}/7: {q_type}")
        print(f"  é—®é¢˜: {question[:50]}...")

        lines.append(f'## é—®é¢˜ {q_id}: {q_type}\n\n')
        lines.append(f'**ç”¨æˆ·é—®é¢˜**: {question}\n\n')

        # å‚æ•°
        params = r.get('parameters', {})
        if params:
            time_range = params.get('time_range', {})
            parties = params.get('parties', [])
            topics = params.get('topics', [])

            lines.append('**æå–çš„å‚æ•°**:\n')
            if time_range:
                years = time_range.get('specific_years', [])
                expr = time_range.get('time_expression', 'N/A')
                lines.append(f'- æ—¶é—´èŒƒå›´: {expr} ({len(years)}å¹´)\n')
            if parties:
                parties_str = ', '.join(parties)
                lines.append(f'- å…šæ´¾: {parties_str}\n')
            if topics:
                topics_str = ', '.join(topics)
                lines.append(f'- ä¸»é¢˜: {topics_str}\n')
            lines.append('\n')

        # æ£€ç´¢ç»Ÿè®¡
        retrieval_results = r.get('retrieval_results', [])
        if retrieval_results:
            total_chunks = sum(len(rr.get('chunks', [])) for rr in retrieval_results)
            lines.append('**æ£€ç´¢ç»Ÿè®¡**:\n')
            lines.append(f'- å­é—®é¢˜æ•°é‡: {len(retrieval_results)}\n')
            lines.append(f'- æ£€ç´¢åˆ°çš„æ–‡æ¡£æ•°: {total_chunks}\n')

            year_dist = r.get('overall_year_distribution', {})
            if year_dist:
                years_list = ', '.join(sorted(year_dist.keys())[:10])
                lines.append(f'- å¹´ä»½è¦†ç›–: {len(year_dist)}å¹´ ({years_list})\n')
            lines.append('\n')

        # ç¿»è¯‘ç­”æ¡ˆ
        if answer:
            print(f"  æ­£åœ¨ç¿»è¯‘ç­”æ¡ˆ ({len(answer)}å­—ç¬¦)...")

            # è°ƒç”¨LLMç¿»è¯‘
            chinese_answer = translate_german_to_chinese(answer, llm_client)

            print(f"  ç¿»è¯‘å®Œæˆ ({len(chinese_answer)}å­—ç¬¦)")

            lines.append(f'**ç³»ç»Ÿå›ç­”ï¼ˆä¸­æ–‡ç¿»è¯‘ï¼‰** (åŸæ–‡{len(answer)}å­—ç¬¦):\n\n')
            lines.append(f'{chinese_answer}\n\n')

            # æ·»åŠ å¾·è¯­åŸæ–‡æŠ˜å éƒ¨åˆ†
            lines.append('<details>\n')
            lines.append('<summary>ğŸ“„ ç‚¹å‡»æŸ¥çœ‹å¾·è¯­åŸæ–‡</summary>\n\n')
            lines.append('```\n')
            lines.append(f'{answer}\n')
            lines.append('```\n\n')
            lines.append('</details>\n\n')
        else:
            error = r.get('error', 'æœªçŸ¥é”™è¯¯')
            lines.append(f'**é”™è¯¯**: {error}\n\n')

        # æ€§èƒ½
        lines.append('**æ€§èƒ½æŒ‡æ ‡**:\n')
        lines.append(f'- æ€»è€—æ—¶: {r.get("total_time", 0):.2f}ç§’\n')
        lines.append(f'- æ„å›¾ç±»å‹: {r.get("intent", "N/A")}\n')
        lines.append(f'- é—®é¢˜åˆ†ç±»: {r.get("question_type", "N/A")}\n\n')

        lines.append('---\n\n')

    # æ·»åŠ ä½¿ç”¨è¯´æ˜
    lines.append('## ğŸ“– ä½¿ç”¨è¯´æ˜\n\n')
    lines.append('### å…³äºç¿»è¯‘\n\n')
    lines.append('- æœ¬æŠ¥å‘Šä¸­çš„ä¸­æ–‡ç¿»è¯‘ç”±Gemini 2.5 Proè‡ªåŠ¨ç”Ÿæˆ\n')
    lines.append('- å¾·è¯­åŸæ–‡å¯ä»¥é€šè¿‡ç‚¹å‡»"ğŸ“„ ç‚¹å‡»æŸ¥çœ‹å¾·è¯­åŸæ–‡"å±•å¼€æŸ¥çœ‹\n')
    lines.append('- ä¸“ä¸šæœ¯è¯­å’Œå…šæ´¾åç§°å·²æŒ‰ç…§æ ‡å‡†ç¿»è¯‘è§„èŒƒå¤„ç†\n\n')

    lines.append('### å…šæ´¾åç§°å¯¹ç…§\n\n')
    lines.append('| å¾·è¯­ | ä¸­æ–‡ |\n')
    lines.append('|------|------|\n')
    lines.append('| CDU/CSU | åŸºæ°‘ç›Ÿ/åŸºç¤¾ç›Ÿ |\n')
    lines.append('| SPD | ç¤¾æ°‘å…š |\n')
    lines.append('| GrÃ¼ne/BÃœNDNIS 90 | ç»¿å…š |\n')
    lines.append('| DIE LINKE | å·¦ç¿¼å…š |\n')
    lines.append('| AfD | é€‰æ‹©å…š |\n')
    lines.append('| FDP | è‡ªæ°‘å…š |\n\n')

    # å†™å…¥æ–‡ä»¶
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(''.join(lines))

    print(f'\nâœ… ä¸­æ–‡ç¿»è¯‘æŠ¥å‘Šå·²ç”Ÿæˆ: {output_file}')
    print(f'   - è¡Œæ•°: {len(lines)}')
    print(f'   - å¤§å°: {len("".join(lines))/1024:.1f} KB')


if __name__ == "__main__":
    print("=" * 60)
    print("ç”Ÿæˆå¸¦ä¸­æ–‡ç¿»è¯‘çš„é—®ç­”æŠ¥å‘Š")
    print("=" * 60)
    print("\nâš ï¸ æ³¨æ„: è¿™å°†è°ƒç”¨Gemini LLMè¿›è¡Œç¿»è¯‘ï¼Œéœ€è¦ä¸€äº›æ—¶é—´...")
    print()

    generate_chinese_report_with_translation(
        'langgraph_complete_test_results.json',
        'é—®ç­”æŠ¥å‘Š-ä¸­æ–‡ç¿»è¯‘ç‰ˆ.md'
    )

    print("\n" + "=" * 60)
    print("âœ… ç¿»è¯‘å®Œæˆï¼")
    print("=" * 60)
