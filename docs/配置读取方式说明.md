# é…ç½®è¯»å–æ–¹å¼è¯´æ˜

## ğŸ“‹ ä¿®æ”¹æ€»ç»“

å·²å°† [`build_index.py`](../build_index.py) ä»ä½¿ç”¨ **Settings ç±»** æ”¹ä¸º **ç›´æ¥è¯»å–ç¯å¢ƒå˜é‡**ã€‚

---

## ğŸ”„ ä¿®æ”¹å‰åå¯¹æ¯”

### ä¿®æ”¹å‰ï¼ˆä½¿ç”¨ Settings ç±»ï¼‰

```python
from src.config import settings

# ä½¿ç”¨ settings å¯¹è±¡
chunk_size = settings.chunk_size
embedding_mode = settings.embedding_mode
```

**ä¼˜ç‚¹**:
- âœ… ç±»å‹æ£€æŸ¥å’ŒéªŒè¯
- âœ… é»˜è®¤å€¼ç®¡ç†
- âœ… ç»Ÿä¸€é…ç½®å…¥å£

**ç¼ºç‚¹**:
- âŒ å¤šä¸€å±‚æŠ½è±¡
- âŒ ä¾èµ– pydantic-settings
- âŒ é…ç½®å˜æ›´éœ€è¦é‡å¯

---

### ä¿®æ”¹åï¼ˆç›´æ¥è¯»å–ç¯å¢ƒå˜é‡ï¼‰

```python
import os
from dotenv import load_dotenv

# åŠ è½½ .env æ–‡ä»¶
load_dotenv()

# ç›´æ¥è¯»å–ç¯å¢ƒå˜é‡
chunk_size = int(os.getenv("CHUNK_SIZE", "1000"))
embedding_mode = os.getenv("EMBEDDING_MODE", "openai").lower()
```

**ä¼˜ç‚¹**:
- âœ… ç®€å•ç›´æ¥
- âœ… æ— éœ€ä¸­é—´å±‚
- âœ… æ˜“äºç†è§£

**ç¼ºç‚¹**:
- âŒ éœ€è¦æ‰‹åŠ¨ç±»å‹è½¬æ¢
- âŒ éœ€è¦æ‰‹åŠ¨è®¾ç½®é»˜è®¤å€¼
- âŒ ç¼ºå°‘ç±»å‹æ£€æŸ¥

---

## ğŸ“ ä¿®æ”¹è¯¦æƒ…

### 1. å¯¼å…¥éƒ¨åˆ†

**ä¿®æ”¹å‰**:
```python
from src.config import settings
```

**ä¿®æ”¹å**:
```python
import os
from dotenv import load_dotenv

# åŠ è½½.envæ–‡ä»¶
load_dotenv()
```

---

### 2. è¯»å–åˆ†å—é…ç½®

**ä¿®æ”¹å‰**:
```python
splitter = ParliamentTextSplitter(
    chunk_size=settings.chunk_size,
    chunk_overlap=settings.chunk_overlap
)
```

**ä¿®æ”¹å**:
```python
# ä»ç¯å¢ƒå˜é‡è¯»å–åˆ†å—é…ç½®
chunk_size = int(os.getenv("CHUNK_SIZE", "1000"))
chunk_overlap = int(os.getenv("CHUNK_OVERLAP", "200"))

splitter = ParliamentTextSplitter(
    chunk_size=chunk_size,
    chunk_overlap=chunk_overlap
)
```

---

### 3. è¯»å– Embedding æ¨¡å¼

**ä¿®æ”¹å‰**:
```python
if settings.embedding_mode == "local":
    embedding_client = LocalEmbeddingClient(settings.local_embedding_model)
elif settings.embedding_mode == "openai":
    embedding_client = GeminiEmbeddingClient(use_official_api=True)
```

**ä¿®æ”¹å**:
```python
# ä»ç¯å¢ƒå˜é‡è¯»å–Embeddingæ¨¡å¼
embedding_mode = os.getenv("EMBEDDING_MODE", "openai").lower()
logger.info(f"ğŸ” æ£€æµ‹åˆ°Embeddingæ¨¡å¼: {embedding_mode}")

if embedding_mode == "local":
    local_model = os.getenv("LOCAL_EMBEDDING_MODEL", "paraphrase-multilingual-MiniLM-L12-v2")
    embedding_client = LocalEmbeddingClient(local_model)
elif embedding_mode == "openai":
    embedding_client = GeminiEmbeddingClient(use_official_api=True)
```

---

### 4. è¾“å‡ºæ‘˜è¦ä¿¡æ¯

**ä¿®æ”¹å‰**:
```python
logger.info(f"  å‘é‡ç»´åº¦: {settings.embedding_dimension}")
logger.info(f"  å­˜å‚¨ä½ç½®: Milvus ({settings.milvus_mode}æ¨¡å¼)")
logger.info(f"  Collection: {settings.milvus_collection_name}")
```

**ä¿®æ”¹å**:
```python
# è·å–å‘é‡ç»´åº¦
vector_dim = len(embedded_chunks[0]['vector'])
milvus_mode = os.getenv("MILVUS_MODE", "lite")
collection_name = os.getenv("MILVUS_COLLECTION_NAME", "german_parliament_speeches")

logger.info(f"  å‘é‡ç»´åº¦: {vector_dim}")
logger.info(f"  å­˜å‚¨ä½ç½®: Milvus ({milvus_mode}æ¨¡å¼)")
logger.info(f"  Collection: {collection_name}")
```

---

## âœ… ç¯å¢ƒå˜é‡æ˜ å°„è¡¨

| ç¯å¢ƒå˜é‡ | é»˜è®¤å€¼ | è¯´æ˜ |
|---------|--------|------|
| `EMBEDDING_MODE` | `openai` | Embeddingæ¨¡å¼: local/openai/vertex |
| `LOCAL_EMBEDDING_MODEL` | `paraphrase-multilingual-MiniLM-L12-v2` | æœ¬åœ°Embeddingæ¨¡å‹ |
| `CHUNK_SIZE` | `1000` | æ–‡æœ¬åˆ†å—å¤§å° |
| `CHUNK_OVERLAP` | `200` | æ–‡æœ¬åˆ†å—é‡å  |
| `MILVUS_MODE` | `lite` | Milvusæ¨¡å¼ |
| `MILVUS_COLLECTION_NAME` | `german_parliament_speeches` | Collectionåç§° |

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### æ–¹æ³•1: åœ¨ `.env` æ–‡ä»¶ä¸­é…ç½®ï¼ˆæ¨èï¼‰

ç¼–è¾‘é¡¹ç›®æ ¹ç›®å½•çš„ `.env` æ–‡ä»¶:

```bash
# Embeddingé…ç½®
EMBEDDING_MODE=openai
LOCAL_EMBEDDING_MODEL=paraphrase-multilingual-MiniLM-L12-v2

# åˆ†å—é…ç½®
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Milvusé…ç½®
MILVUS_MODE=lite
MILVUS_COLLECTION_NAME=german_parliament_speeches
```

ç„¶åç›´æ¥è¿è¡Œ:
```powershell
python build_index.py
```

---

### æ–¹æ³•2: åœ¨å‘½ä»¤è¡Œä¸­è®¾ç½®ç¯å¢ƒå˜é‡

**PowerShell**:
```powershell
$env:EMBEDDING_MODE="openai"
$env:CHUNK_SIZE="1000"
python build_index.py
```

**CMD**:
```cmd
set EMBEDDING_MODE=openai
set CHUNK_SIZE=1000
python build_index.py
```

**Linux/Mac**:
```bash
export EMBEDDING_MODE=openai
export CHUNK_SIZE=1000
python build_index.py
```

---

## ğŸ” éªŒè¯é…ç½®

è¿è¡Œä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹å½“å‰é…ç½®:

```powershell
python -c "import os; from dotenv import load_dotenv; load_dotenv(); print('EMBEDDING_MODE:', os.getenv('EMBEDDING_MODE')); print('CHUNK_SIZE:', os.getenv('CHUNK_SIZE'))"
```

---

## ğŸ“Œ æ³¨æ„äº‹é¡¹

1. **`.env` æ–‡ä»¶ä¼˜å…ˆçº§æœ€é«˜**: `load_dotenv()` ä¼šè‡ªåŠ¨åŠ è½½ `.env` æ–‡ä»¶
2. **ç¯å¢ƒå˜é‡è¦†ç›–**: ç³»ç»Ÿç¯å¢ƒå˜é‡ä¼šè¦†ç›– `.env` æ–‡ä»¶ä¸­çš„é…ç½®
3. **ç±»å‹è½¬æ¢**: ç¯å¢ƒå˜é‡éƒ½æ˜¯å­—ç¬¦ä¸²ï¼Œéœ€è¦æ‰‹åŠ¨è½¬æ¢ï¼ˆå¦‚ `int()`, `.lower()`ï¼‰
4. **é»˜è®¤å€¼**: ä½¿ç”¨ `os.getenv("KEY", "default")` æä¾›é»˜è®¤å€¼

---

## ğŸ†š å…¶ä»–æ¨¡å—ä»ä½¿ç”¨ Settings

**æ³¨æ„**: å…¶ä»–æ¨¡å—ï¼ˆå¦‚ `src/llm/embeddings.py`, `src/vectordb/client.py` ç­‰ï¼‰ä»ç„¶ä½¿ç”¨ `Settings` ç±»ï¼Œå› ä¸º:

1. å®ƒä»¬éœ€è¦ç±»å‹éªŒè¯å’Œé»˜è®¤å€¼ç®¡ç†
2. å®ƒä»¬è¢«å¤šå¤„è°ƒç”¨ï¼Œç»Ÿä¸€é…ç½®æ›´æ–¹ä¾¿
3. å®ƒä»¬éœ€è¦è®¡ç®—å±æ€§ï¼ˆå¦‚ `embedding_dimension`ï¼‰

**åªæœ‰ `build_index.py` æ”¹ä¸ºç›´æ¥è¯»å–ç¯å¢ƒå˜é‡**ï¼Œæ›´ç¬¦åˆè„šæœ¬çš„ä½¿ç”¨ä¹ æƒ¯ã€‚

---

## ğŸ¯ æœ€ä½³å®è·µ

å»ºè®®é…ç½®æ–¹å¼:

```bash
# .env æ–‡ä»¶
EMBEDDING_MODE=openai
OPENAI_EMBEDDING_API_KEY=sk-proj-xxxxx
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
```

è¿è¡Œè„šæœ¬:
```powershell
python build_index.py
```

è¿™æ ·é…ç½®æ¸…æ™°ã€æ˜“äºä¿®æ”¹ï¼
