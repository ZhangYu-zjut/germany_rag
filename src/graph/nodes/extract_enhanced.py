"""
å¢å¼ºç‰ˆå‚æ•°æå–èŠ‚ç‚¹
æ”¯æŒæ—¶é—´è¯­ä¹‰ç†è§£("2015å¹´ä»¥æ¥"ã€"è¿‘å¹´æ¥"ç­‰)
"""

import json
import re
from typing import Dict, Optional
from datetime import datetime
from ...llm.client import GeminiLLMClient
from ...llm.prompts import PromptTemplates
from ...utils.logger import logger
from ..state import GraphState, update_state


class EnhancedExtractNode:
    """
    å¢å¼ºç‰ˆå‚æ•°æå–èŠ‚ç‚¹

    æ–°å¢åŠŸèƒ½:
    1. æ—¶é—´è¯­ä¹‰ç†è§£: "2015å¹´ä»¥æ¥" -> ['2015', '2016', ..., '2024']
    2. ç›¸å¯¹æ—¶é—´ç†è§£: "è¿‘å¹´æ¥" -> è¿‘3-5å¹´
    3. æ›´æ™ºèƒ½çš„å¹´ä»½èŒƒå›´å±•å¼€
    4. è¾“å‡ºè¯¦ç»†çš„æå–æ€è€ƒè¿‡ç¨‹
    """

    def __init__(self, llm_client: GeminiLLMClient = None):
        """
        åˆå§‹åŒ–å‚æ•°æå–èŠ‚ç‚¹

        Args:
            llm_client: LLMå®¢æˆ·ç«¯,å¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨åˆ›å»º
        """
        self.llm = llm_client or GeminiLLMClient()
        self.prompts = PromptTemplates()
        self.current_year = datetime.now().year

    def __call__(self, state: GraphState) -> GraphState:
        """
        æ‰§è¡Œå‚æ•°æå–

        Args:
            state: å½“å‰çŠ¶æ€

        Returns:
            æ›´æ–°åçš„çŠ¶æ€
        """
        question = state["question"]
        logger.info(f"[EnhancedExtractNode] å¼€å§‹æå–å‚æ•°: {question}")

        thinking_process = []
        thinking_process.append("=== å‚æ•°æå–è¿‡ç¨‹ ===")
        thinking_process.append(f"åŸå§‹é—®é¢˜: {question}")

        try:
            # 1. LLMæå–åŸºç¡€å‚æ•°
            prompt = self._build_enhanced_prompt(question)
            response = self.llm.invoke(prompt)

            logger.debug(f"[EnhancedExtractNode] LLMå“åº”: {response[:200]}...")
            thinking_process.append(f"LLMæå–ç»“æœ: {response[:200]}...")

            # 2. è§£æå“åº”
            parameters = self._parse_response(response)
            thinking_process.append(f"è§£æåå‚æ•°: {json.dumps(parameters, ensure_ascii=False)}")

            # 3. å¢å¼ºæ—¶é—´è¯­ä¹‰ç†è§£
            parameters = self._enhance_time_semantics(question, parameters, thinking_process)
            thinking_process.append(f"å¢å¼ºåå‚æ•°: {json.dumps(parameters, ensure_ascii=False)}")

            logger.info(
                f"[EnhancedExtractNode] æå–å‚æ•°å®Œæˆ: "
                f"{json.dumps(parameters, ensure_ascii=False, indent=2)}"
            )

            # 4. åˆ¤æ–­æ˜¯å¦éœ€è¦æ‹†è§£
            is_decomposed = self._need_decomposition(state, parameters)
            thinking_process.append(f"éœ€è¦æ‹†è§£: {is_decomposed}")

            # è¾“å‡ºæ€è€ƒè¿‡ç¨‹
            logger.info(f"\n[æå–æ€è€ƒè¿‡ç¨‹]\n" + "\n".join(thinking_process))

            # æ›´æ–°çŠ¶æ€
            return update_state(
                state,
                parameters=parameters,
                is_decomposed=is_decomposed,
                extraction_thinking="\n".join(thinking_process),
                current_node="extract",
                next_node="decompose" if is_decomposed else "retrieve"
            )

        except Exception as e:
            logger.error(f"[EnhancedExtractNode] å‚æ•°æå–å¤±è´¥: {str(e)}")
            thinking_process.append(f"æå–å¤±è´¥: {str(e)}")

            # è¿”å›ç©ºå‚æ•°,ç»§ç»­æµç¨‹
            return update_state(
                state,
                parameters={},
                is_decomposed=False,
                extraction_thinking="\n".join(thinking_process),
                current_node="extract",
                next_node="retrieve"
            )

    def _build_enhanced_prompt(self, question: str) -> str:
        """
        æ„å»ºå¢å¼ºç‰ˆæå–Prompt

        Args:
            question: é—®é¢˜

        Returns:
            Promptæ–‡æœ¬
        """
        enhanced_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ—¶é—´å’Œå‚æ•°æå–ä¸“å®¶ã€‚è¯·ä»é—®é¢˜ä¸­æå–å…³é”®å‚æ•°ã€‚

ã€é‡è¦ã€‘ç‰¹åˆ«æ³¨æ„æ—¶é—´è¯­ä¹‰ç†è§£ï¼š
- "2015å¹´ä»¥æ¥" = ä»2015å¹´åˆ°å½“å‰å¹´ä»½({self.current_year})
- "è¿‘å¹´æ¥" = è¿‘3-5å¹´
- "æœ€è¿‘å‡ å¹´" = è¿‘3å¹´
- "XXXä¹‹å" = ä»XXXå¹´åˆ°å½“å‰
- "XXXä»¥å‰" = ä»è¾ƒæ—©å¹´ä»½åˆ°XXXå¹´
- "2015-2017å¹´" = 2015ã€2016ã€2017å¹´ï¼ˆè¿ç»­èŒƒå›´ï¼‰
- "2019å¹´ä¸2017å¹´ç›¸æ¯”" = ä»…2019å¹´ã€2017å¹´ï¼ˆç¦»æ•£å¯¹æ¯”ï¼Œä¸è¦å¡«å……ä¸­é—´å¹´ä»½ï¼ï¼‰

ã€å…³é”®ã€‘å¯¹äº"XXå¹´ä¸YYå¹´ç›¸æ¯”"è¿™ç§ç¦»æ•£å¯¹æ¯”ï¼š
- åªè¾“å‡º specific_years: ["2017", "2019"]
- ä¸è¦å¡«å……ä¸­é—´å¹´ä»½ï¼ˆå¦‚2018ï¼‰
ç”¨æˆ·é—®é¢˜: {question}

ã€æå–è§„åˆ™ã€‘

1. **æ—¶é—´èŒƒå›´** (æœ€é‡è¦!)
   - è¯†åˆ«å¹´ä»½: "2019å¹´" â†’ start_year="2019", end_year="2019", specific_years=["2019"]
   - è¯†åˆ«è¿ç»­èŒƒå›´: "2015-2018å¹´" â†’ start_year="2015", end_year="2018", specific_years=["2015","2016","2017","2018"]
   - âš ï¸ **ç¦»æ•£å¯¹æ¯”**: "2019å¹´ä¸2017å¹´ç›¸æ¯”" â†’ start_year="2017", end_year="2019", specific_years=["2017","2019"] (ä¸è¦å¡«å……2018!)
   - è¯†åˆ«è¯­ä¹‰: "2015å¹´ä»¥æ¥" â†’ start_year="2015", end_year="{self.current_year}"
   - è¯†åˆ«ç›¸å¯¹: "è¿‘å¹´æ¥" â†’ start_year="{self.current_year - 3}", end_year="{self.current_year}"
   - **å…³é”®**: ç¦»æ•£å¯¹æ¯”(å¦‚"XXå¹´ä¸YYå¹´ç›¸æ¯”")åªæå–æ˜ç¡®æåˆ°çš„å¹´ä»½,ä¸è¦è‡ªåŠ¨å¡«å……ä¸­é—´å¹´ä»½!

2. **å…šæ´¾**ï¼ˆè¯·ä½¿ç”¨Pineconeå­˜å‚¨çš„æ ‡å‡†åç§°ï¼‰
   - CDU/CSU
   - SPD
   - FDP
   - GrÃ¼ne/BÃ¼ndnis 90ï¼ˆä¸è¦ç”¨BÃœNDNIS 90/DIE GRÃœNENï¼‰
   - DIE LINKE
   - AfD
   - "ä¸åŒå…šæ´¾"/"å„å…šæ´¾" â†’ ["ALL_PARTIES"]

3. **è®®å‘˜**
   - ä¿æŒåŸæ ¼å¼

4. **ä¸»é¢˜**
   - æ ¸å¿ƒè®®é¢˜å…³é”®è¯

ã€è¾“å‡ºæ ¼å¼ã€‘

```json
{{
    "time_range": {{
        "start_year": "YYYY",
        "end_year": "YYYY",
        "specific_years": ["YYYY", "YYYY", ...],  // å±•å¼€çš„å¹´ä»½åˆ—è¡¨
        "time_expression": "åŸå§‹æ—¶é—´è¡¨è¿°"
    }},
    "parties": ["å…šæ´¾1"] æˆ– ["ALL_PARTIES"] æˆ– null,
    "speakers": ["è®®å‘˜1"] æˆ– null,
    "topics": ["ä¸»é¢˜1", "ä¸»é¢˜2"],
    "keywords": ["å…³é”®è¯1"]
}}
```

ã€ç¤ºä¾‹ã€‘

é—®é¢˜1: "è¯·æ¦‚è¿°2015å¹´ä»¥æ¥å¾·å›½åŸºæ°‘ç›Ÿå¯¹éš¾æ°‘æ”¿ç­–çš„ç«‹åœºå‘ç”Ÿäº†å“ªäº›ä¸»è¦å˜åŒ–ã€‚"

```json
{{
    "time_range": {{
        "start_year": "2015",
        "end_year": "{self.current_year}",
        "specific_years": ["2015", "2016", "2017", "2018", "2019", "2020", "2021", "2022", "2023", "2024"],
        "time_expression": "2015å¹´ä»¥æ¥"
    }},
    "parties": ["CDU/CSU"],
    "speakers": null,
    "topics": ["éš¾æ°‘", "éš¾æ°‘æ”¿ç­–"],
    "keywords": ["å˜åŒ–", "ç«‹åœº"]
}}
```

é—®é¢˜2: "2017å¹´ï¼Œå¾·å›½è”é‚¦è®®ä¼šä¸­å„å…šæ´¾å¯¹ä¸“ä¸šäººæ‰ç§»æ°‘åˆ¶åº¦æ”¹é©åˆ†åˆ«æŒä»€ä¹ˆç«‹åœºï¼Ÿ"

```json
{{
    "time_range": {{
        "start_year": "2017",
        "end_year": "2017",
        "specific_years": ["2017"],
        "time_expression": "2017å¹´"
    }},
    "parties": ["ALL_PARTIES"],
    "speakers": null,
    "topics": ["ä¸“ä¸šäººæ‰ç§»æ°‘", "ç§»æ°‘åˆ¶åº¦æ”¹é©"],
    "keywords": ["ç«‹åœº", "æ”¹é©"]
}}
```

é—®é¢˜3 (âš ï¸ é‡è¦ç¤ºä¾‹ - ç¦»æ•£å¯¹æ¯”): "2019å¹´ä¸2017å¹´ç›¸æ¯”ï¼Œè”é‚¦è®®ä¼šå…³äºéš¾æ°‘é£è¿”çš„è®¨è®ºæœ‰ä½•å˜åŒ–ï¼Ÿ"

```json
{{
    "time_range": {{
        "start_year": "2017",
        "end_year": "2019",
        "specific_years": ["2017", "2019"],
        "time_expression": "2019å¹´ä¸2017å¹´ç›¸æ¯”"
    }},
    "parties": ["ALL_PARTIES"],
    "speakers": null,
    "topics": ["éš¾æ°‘é£è¿”", "éš¾æ°‘"],
    "keywords": ["å˜åŒ–", "è®¨è®º"]
}}
```

ç°åœ¨è¯·æå–ç”¨æˆ·é—®é¢˜çš„å‚æ•°ã€‚åªè¾“å‡ºJSONä»£ç å—ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šã€‚
"""
        return enhanced_prompt

    def _parse_response(self, response: str) -> Dict:
        """
        è§£æLLMå“åº”,æå–å‚æ•°

        Args:
            response: LLMå“åº”æ–‡æœ¬

        Returns:
            å‚æ•°å­—å…¸
        """
        # å°è¯•æå–JSON
        try:
            # æŸ¥æ‰¾JSONä»£ç å—
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªå®Œæ•´çš„JSONå¯¹è±¡
                json_match = re.search(r'\{.*\}', response, re.DOTALL)
                if json_match:
                    json_str = json_match.group(0)
                else:
                    json_str = response

            # è§£æJSON
            parameters = json.loads(json_str)

            # æ¸…ç†ç©ºå€¼
            parameters = self._clean_parameters(parameters)

            return parameters

        except json.JSONDecodeError as e:
            logger.warning(f"[EnhancedExtractNode] JSONè§£æå¤±è´¥: {str(e)}, ä½¿ç”¨è§„åˆ™æå–")
            return self._rule_based_extraction(response)

    def _enhance_time_semantics(
        self,
        question: str,
        parameters: Dict,
        thinking_process: list
    ) -> Dict:
        """
        å¢å¼ºæ—¶é—´è¯­ä¹‰ç†è§£

        å¤„ç†:
        1. "2015å¹´ä»¥æ¥" -> å±•å¼€ä¸º['2015', ..., '2024']
        2. "è¿‘å¹´æ¥" -> è¿‘3-5å¹´
        3. ç¡®ä¿specific_yearsæ€»æ˜¯å¡«å……

        Args:
            question: åŸå§‹é—®é¢˜
            parameters: å·²æå–çš„å‚æ•°
            thinking_process: æ€è€ƒè¿‡ç¨‹åˆ—è¡¨

        Returns:
            å¢å¼ºåçš„å‚æ•°
        """
        thinking_process.append("\n--- æ—¶é—´è¯­ä¹‰å¢å¼º ---")

        time_range = parameters.get("time_range", {})
        if not time_range:
            return parameters

        start_year = time_range.get("start_year")
        end_year = time_range.get("end_year")
        specific_years = time_range.get("specific_years", [])

        # ç‰¹æ®Šè¯­ä¹‰è¯†åˆ«
        semantic_patterns = [
            (r'(\d{4})\s*å¹´ä»¥æ¥', 'since_year'),
            (r'è¿‘å¹´æ¥', 'recent_years'),
            (r'æœ€è¿‘å‡ å¹´', 'last_few_years'),
            (r'(\d{4})\s*å¹´ä¹‹å', 'after_year'),
        ]

        for pattern, sem_type in semantic_patterns:
            match = re.search(pattern, question)
            if match:
                thinking_process.append(f"è¯†åˆ«è¯­ä¹‰: {sem_type}")

                if sem_type == 'since_year':
                    year = match.group(1)
                    start_year = year
                    end_year = str(self.current_year - 1)  # ä½¿ç”¨2024ä½œä¸ºæˆªæ­¢
                    thinking_process.append(f"'{year}å¹´ä»¥æ¥' -> {start_year}~{end_year}")

                elif sem_type == 'recent_years':
                    start_year = str(self.current_year - 3)
                    end_year = str(self.current_year - 1)
                    thinking_process.append(f"'è¿‘å¹´æ¥' -> {start_year}~{end_year}")

                elif sem_type == 'last_few_years':
                    start_year = str(self.current_year - 2)
                    end_year = str(self.current_year - 1)
                    thinking_process.append(f"'æœ€è¿‘å‡ å¹´' -> {start_year}~{end_year}")

                elif sem_type == 'after_year':
                    year = match.group(1)
                    start_year = str(int(year) + 1)
                    end_year = str(self.current_year - 1)
                    thinking_process.append(f"'{year}å¹´ä¹‹å' -> {start_year}~{end_year}")

                break

        # ğŸ”’ ä¿æŠ¤æªæ–½1: æ£€æµ‹ç¦»æ•£å¯¹æ¯”æ¨¡å¼ï¼ˆ"XXå¹´ä¸YYå¹´ç›¸æ¯”"ï¼‰
        is_discrete_comparison = False
        if "ä¸" in question and "ç›¸æ¯”" in question:
            if specific_years and len(specific_years) >= 2:
                # LLMå·²ç»æ­£ç¡®è¯†åˆ«äº†ç¦»æ•£å¹´ä»½ï¼Œä¿æŒä¸å˜
                thinking_process.append(f"æ£€æµ‹åˆ°ç¦»æ•£å¯¹æ¯”æ¨¡å¼ï¼Œä¿ç•™LLMæå–çš„å¹´ä»½: {specific_years}")
                is_discrete_comparison = True

        # å±•å¼€å¹´ä»½èŒƒå›´
        if start_year and end_year and not is_discrete_comparison:
            try:
                start = int(start_year)
                end = int(end_year)

                # ğŸ”’ ä¿æŠ¤æªæ–½2: å¦‚æœLLMå·²æä¾›specific_yearsä¸”ä¸èŒƒå›´ä¸åŒ¹é…ï¼Œä¿¡ä»»LLM
                if specific_years:
                    expected_count = end - start + 1
                    if len(specific_years) != expected_count:
                        # LLMæä¾›çš„å¹´ä»½æ•°é‡ä¸èŒƒå›´ä¸åŒ¹é…ï¼Œå¯èƒ½æ˜¯ç¦»æ•£å¯¹æ¯”
                        thinking_process.append(
                            f"LLMæå–çš„å¹´ä»½({len(specific_years)}ä¸ª)ä¸èŒƒå›´({expected_count}ä¸ª)ä¸åŒ¹é…ï¼Œ"
                            f"ä¿ç•™LLMç»“æœ: {specific_years}"
                        )
                        # ä¸å±•å¼€ï¼Œä¿ç•™LLMæå–çš„ç»“æœ
                    else:
                        # æ•°é‡åŒ¹é…ï¼Œç»§ç»­å±•å¼€éªŒè¯
                        year_list = [str(y) for y in range(start, end + 1)]
                        specific_years = year_list
                        thinking_process.append(f"å±•å¼€å¹´ä»½: {len(year_list)}å¹´ ({year_list[0]}~{year_list[-1]})")
                else:
                    # LLMæœªæä¾›specific_yearsï¼Œè‡ªåŠ¨å±•å¼€
                    year_list = [str(y) for y in range(start, end + 1)]

                    # é™åˆ¶èŒƒå›´ï¼ˆé¿å…è¿‡é•¿ï¼‰
                    if len(year_list) > 30:
                        thinking_process.append(f"è­¦å‘Š: å¹´ä»½è·¨åº¦è¿‡å¤§({len(year_list)}å¹´), é™åˆ¶åˆ°30å¹´")
                        year_list = year_list[:30]

                    specific_years = year_list
                    thinking_process.append(f"å±•å¼€å¹´ä»½: {len(year_list)}å¹´ ({year_list[0]}~{year_list[-1]})")

            except Exception as e:
                logger.warning(f"[EnhancedExtractNode] å¹´ä»½å±•å¼€å¤±è´¥: {str(e)}")
                thinking_process.append(f"å¹´ä»½å±•å¼€å¤±è´¥: {str(e)}")

        # æ›´æ–°å‚æ•°
        parameters["time_range"] = {
            "start_year": start_year,
            "end_year": end_year,
            "specific_years": specific_years,
            "time_expression": time_range.get("time_expression")
        }

        return parameters

    def _clean_parameters(self, params: Dict) -> Dict:
        """æ¸…ç†å‚æ•°,ç§»é™¤ç©ºå€¼"""
        cleaned = {}

        for key, value in params.items():
            if isinstance(value, dict):
                cleaned_sub = {k: v for k, v in value.items() if v and v != "null"}
                if cleaned_sub:
                    cleaned[key] = cleaned_sub
            elif isinstance(value, list):
                cleaned_list = [v for v in value if v and v != "null"]
                if cleaned_list:
                    cleaned[key] = cleaned_list
            elif value and value != "null":
                cleaned[key] = value

        return cleaned

    def _rule_based_extraction(self, text: str) -> Dict:
        """åŸºäºè§„åˆ™çš„å‚æ•°æå–(å¤‡ç”¨æ–¹æ¡ˆ)"""
        params = {
            "time_range": {},
            "parties": [],
            "speakers": [],
            "topics": [],
            "keywords": []
        }

        # æå–å¹´ä»½
        years = re.findall(r'\b(19\d{2}|20\d{2})\b', text)
        if years:
            params["time_range"]["specific_years"] = list(set(years))
            if len(years) >= 2:
                params["time_range"]["start_year"] = min(years)
                params["time_range"]["end_year"] = max(years)

        # æå–å¸¸è§å…šæ´¾
        parties = ["CDU/CSU", "SPD", "FDP", "GRÃœNE", "DIE LINKE", "AfD"]
        for party in parties:
            if party in text:
                params["parties"].append(party)

        return params

    def _need_decomposition(self, state: GraphState, parameters: Dict) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦é—®é¢˜æ‹†è§£"""
        # å¦‚æœæ˜¯ç®€å•é—®é¢˜,ä¸éœ€è¦æ‹†è§£
        if state.get("intent") == "simple":
            return False

        # å¤æ‚é—®é¢˜çš„æ‹†è§£æ¡ä»¶
        question_type = state.get("question_type", "")

        # å˜åŒ–ç±»ã€å¯¹æ¯”ç±»ã€æ€»ç»“ç±»é€šå¸¸éœ€è¦æ‹†è§£
        if question_type in ["å˜åŒ–ç±»", "å¯¹æ¯”ç±»", "æ€»ç»“ç±»"]:
            return True

        # å¦‚æœæ¶‰åŠå¤šä¸ªç»´åº¦,éœ€è¦æ‹†è§£
        time_range = parameters.get("time_range", {})
        parties = parameters.get("parties", [])

        # å¤šå¹´ä»½ + å¤šå…šæ´¾ = éœ€è¦æ‹†è§£
        years = time_range.get("specific_years", [])
        if len(years) > 2 and len(parties) > 1:
            return True

        return False


if __name__ == "__main__":
    # æµ‹è¯•å¢å¼ºç‰ˆæå–èŠ‚ç‚¹
    from ..state import create_initial_state, update_state

    print("=== å¢å¼ºç‰ˆå‚æ•°æå–æµ‹è¯• ===")

    # æµ‹è¯•"2015å¹´ä»¥æ¥"
    question = "è¯·æ¦‚è¿°2015å¹´ä»¥æ¥å¾·å›½åŸºæ°‘ç›Ÿå¯¹éš¾æ°‘æ”¿ç­–çš„ç«‹åœºå‘ç”Ÿäº†å“ªäº›ä¸»è¦å˜åŒ–ã€‚"
    state = create_initial_state(question)
    state = update_state(state, intent="complex", question_type="å˜åŒ–ç±»")

    print(f"é—®é¢˜: {question}")
    print("\nå¦‚éœ€å®Œæ•´æµ‹è¯•,è¯·ç¡®ä¿LLMå®¢æˆ·ç«¯é…ç½®æ­£ç¡®")
    print("\né¢„æœŸæå–ç»“æœ:")
    print("- start_year: 2015")
    print("- end_year: 2024")
    print("- specific_years: ['2015', '2016', ..., '2024']")
    print("- parties: ['CDU/CSU']")
