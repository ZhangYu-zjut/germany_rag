"""
Pineconeæ•°æ®æ£€ç´¢èŠ‚ç‚¹
ä»Pineconeå‘é‡æ•°æ®åº“æ£€ç´¢ç›¸å…³ææ–™
æ”¯æŒå¤šå¹´ä»½åˆ†å±‚æ£€ç´¢ç­–ç•¥
"""

from typing import List, Dict, Optional
from ...vectordb.pinecone_retriever import PineconeRetriever, create_pinecone_retriever
from ...llm.embeddings import GeminiEmbeddingClient
from ...utils.logger import logger
from ...utils.performance_monitor import get_performance_monitor
from ..state import GraphState, update_state


class PineconeRetrieveNode:
    """
    Pineconeæ•°æ®æ£€ç´¢èŠ‚ç‚¹

    åŠŸèƒ½:
    1. ä¸ºæ¯ä¸ªé—®é¢˜(æˆ–å­é—®é¢˜)æ£€ç´¢ç›¸å…³ææ–™
    2. æ”¯æŒæ··åˆæ£€ç´¢(å‘é‡+å…ƒæ•°æ®è¿‡æ»¤)
    3. æ”¯æŒå¤šå¹´ä»½åˆ†å±‚æ£€ç´¢(ç¡®ä¿æ¯å¹´éƒ½æœ‰ä»£è¡¨æ€§æ–‡æ¡£)
    4. è¾“å‡ºè¯¦ç»†çš„æ£€ç´¢è¿‡ç¨‹ä¿¡æ¯(å¹´ä»½åˆ†å¸ƒã€ç›¸ä¼¼åº¦ç­‰)

    ä¼˜åŒ–:
    - é»˜è®¤top_k=50,æ”¯æŒ10+å¹´æ—¶é—´è·¨åº¦
    - æ™ºèƒ½è¯†åˆ«é•¿æ—¶é—´è·¨åº¦æŸ¥è¯¢,è‡ªåŠ¨ä½¿ç”¨åˆ†å±‚æ£€ç´¢
    - è¾“å‡ºå†…éƒ¨æ€è€ƒè¿‡ç¨‹,ä¾¿äºè°ƒè¯•
    """

    def __init__(
        self,
        retriever: PineconeRetriever = None,
        embedding_client: GeminiEmbeddingClient = None,
        top_k: int = 50,  # æå‡åˆ°50,æ”¯æŒé•¿æ—¶é—´è·¨åº¦
        index_name: str = "german-bge",
        enable_multi_year_strategy: bool = True,  # å¯ç”¨å¤šå¹´ä»½ç­–ç•¥
        limit_per_year: int = 5  # å¤šå¹´ä»½ç­–ç•¥æ—¶æ¯å¹´çš„æ–‡æ¡£æ•°
    ):
        """
        åˆå§‹åŒ–Pineconeæ£€ç´¢èŠ‚ç‚¹

        Args:
            retriever: Pineconeæ£€ç´¢å™¨,å¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨åˆ›å»º
            embedding_client: Embeddingå®¢æˆ·ç«¯
            top_k: é»˜è®¤è¿”å›çš„top-kç»“æœ
            index_name: Pineconeç´¢å¼•åç§°
            enable_multi_year_strategy: æ˜¯å¦å¯ç”¨å¤šå¹´ä»½åˆ†å±‚æ£€ç´¢ç­–ç•¥
            limit_per_year: å¤šå¹´ä»½ç­–ç•¥æ—¶æ¯å¹´è¿”å›çš„æ–‡æ¡£æ•°
        """
        self.index_name = index_name
        self.top_k = top_k
        self.enable_multi_year_strategy = enable_multi_year_strategy
        self.limit_per_year = limit_per_year

        # åˆ›å»ºæˆ–ä½¿ç”¨æä¾›çš„retriever
        if retriever is None:
            try:
                logger.info(f"[PineconeRetrieveNode] åˆå§‹åŒ–Pineconeæ£€ç´¢å™¨...")
                self.retriever = create_pinecone_retriever(
                    index_name=index_name,
                    default_limit=top_k
                )

                # è·å–ç»Ÿè®¡ä¿¡æ¯
                stats = self.retriever.get_stats()
                logger.info(
                    f"[PineconeRetrieveNode] Pineconeè¿æ¥æˆåŠŸ: "
                    f"å‘é‡æ•°={stats['total_vectors']:,}, ç»´åº¦={stats['dimension']}"
                )

            except Exception as e:
                logger.error(f"[PineconeRetrieveNode] åˆ›å»ºæ£€ç´¢å™¨å¤±è´¥: {str(e)}")
                raise RuntimeError(f"æ— æ³•åˆå§‹åŒ–Pineconeæ£€ç´¢å™¨: {str(e)}")
        else:
            self.retriever = retriever

        self.embedding_client = embedding_client or GeminiEmbeddingClient()

        logger.info(
            f"[PineconeRetrieveNode] åˆå§‹åŒ–å®Œæˆ: "
            f"top_k={top_k}, å¤šå¹´ä»½ç­–ç•¥={enable_multi_year_strategy}, "
            f"æ¯å¹´æ–‡æ¡£æ•°={limit_per_year}"
        )

    def __call__(self, state: GraphState) -> GraphState:
        """
        æ‰§è¡Œæ•°æ®æ£€ç´¢

        Args:
            state: å½“å‰çŠ¶æ€

        Returns:
            æ›´æ–°åçš„çŠ¶æ€
        """
        # æ€§èƒ½ç›‘æ§å¼€å§‹
        import time
        start_time = time.time()
        monitor = get_performance_monitor()

        # è·å–é—®é¢˜åˆ—è¡¨
        sub_questions = state.get("sub_questions")
        if sub_questions:
            questions = sub_questions
            logger.info(f"[PineconeRetrieveNode] æ£€ç´¢ {len(questions)} ä¸ªå­é—®é¢˜")
        else:
            questions = [state["question"]]
            logger.info(f"[PineconeRetrieveNode] æ£€ç´¢åŸå§‹é—®é¢˜")

        parameters = state.get("parameters", {})

        # è¾“å‡ºå†…éƒ¨æ€è€ƒè¿‡ç¨‹
        thinking_process = []
        thinking_process.append("=== æ£€ç´¢ç­–ç•¥åˆ†æ ===")
        thinking_process.append(f"é—®é¢˜æ•°é‡: {len(questions)}")
        thinking_process.append(f"æå–å‚æ•°: {parameters}")

        try:
            # ä¸ºæ¯ä¸ªé—®é¢˜æ£€ç´¢
            retrieval_results = []
            no_material_found = True  # æ˜¯å¦æ‰¾åˆ°ææ–™
            overall_year_distribution = {}

            for i, question_item in enumerate(questions, 1):
                # æ”¯æŒå­—å…¸å’Œå­—ç¬¦ä¸²ä¸¤ç§æ ¼å¼
                if isinstance(question_item, dict):
                    question_text = question_item.get("question", question_item)
                    question_metadata = question_item
                else:
                    question_text = question_item
                    question_metadata = {
                        "question": question_text,
                        "target_year": None,
                        "retrieval_strategy": "multi_year"
                    }

                logger.info(f"[PineconeRetrieveNode] æ£€ç´¢é—®é¢˜ {i}/{len(questions)}: {question_text}")
                thinking_process.append(f"\n--- å­é—®é¢˜ {i} ---")
                thinking_process.append(f"é—®é¢˜: {question_text}")
                if question_metadata.get("target_year"):
                    thinking_process.append(f"ç›®æ ‡å¹´ä»½: {question_metadata['target_year']}")
                    thinking_process.append(f"æ£€ç´¢ç­–ç•¥: {question_metadata.get('retrieval_strategy', 'single_year')}")

                # æ£€ç´¢ï¼ˆä¼ å…¥å…ƒæ•°æ®ï¼‰
                chunks, year_dist, retrieval_method = self._retrieve_for_question(
                    question_text, parameters, thinking_process, question_metadata
                )

                if chunks:
                    no_material_found = False

                # è®°å½•å¹´ä»½åˆ†å¸ƒ
                for year, count in year_dist.items():
                    overall_year_distribution[year] = overall_year_distribution.get(year, 0) + count

                retrieval_results.append({
                    "question": question_text,
                    "question_metadata": question_metadata,  # ä¿å­˜å…ƒæ•°æ®
                    "chunks": chunks,
                    "answer": None,  # å¾…å¡«å……
                    "year_distribution": year_dist,
                    "retrieval_method": retrieval_method,
                    "top_similarity_score": chunks[0]['score'] if chunks else 0.0
                })

                logger.info(
                    f"[PineconeRetrieveNode] æ‰¾åˆ° {len(chunks)} ä¸ªç›¸å…³chunks, "
                    f"å¹´ä»½åˆ†å¸ƒ={year_dist}, æ–¹æ³•={retrieval_method}"
                )
                thinking_process.append(f"æ£€ç´¢åˆ°æ–‡æ¡£æ•°: {len(chunks)}")
                thinking_process.append(f"å¹´ä»½åˆ†å¸ƒ: {year_dist}")
                thinking_process.append(f"æ£€ç´¢æ–¹æ³•: {retrieval_method}")
                if chunks:
                    thinking_process.append(f"æœ€é«˜ç›¸ä¼¼åº¦: {chunks[0]['score']:.4f}")

            # æ€»ç»“æ£€ç´¢æƒ…å†µ
            thinking_process.append("\n=== æ£€ç´¢æ€»ç»“ ===")
            thinking_process.append(f"æ€»æ–‡æ¡£æ•°: {sum(len(r['chunks']) for r in retrieval_results)}")
            thinking_process.append(f"æ•´ä½“å¹´ä»½åˆ†å¸ƒ: {overall_year_distribution}")
            thinking_process.append(f"æ‰¾åˆ°ææ–™: {'æ˜¯' if not no_material_found else 'å¦'}")

            # è®°å½•æ€§èƒ½ç›‘æ§
            end_time = time.time()
            duration = end_time - start_time
            monitor.record_timing("Pineconeæ£€ç´¢", duration)

            thinking_process.append(f"æ£€ç´¢è€—æ—¶: {duration:.2f}ç§’")

            # è¾“å‡ºæ€è€ƒè¿‡ç¨‹
            logger.info(f"\n[å†…éƒ¨æ€è€ƒè¿‡ç¨‹]\n" + "\n".join(thinking_process))

            return update_state(
                state,
                retrieval_results=retrieval_results,
                no_material_found=no_material_found,
                retrieval_thinking="\n".join(thinking_process),  # ä¿å­˜åˆ°çŠ¶æ€
                overall_year_distribution=overall_year_distribution,
                current_node="retrieve",
                next_node="exception" if no_material_found else "rerank"
            )

        except Exception as e:
            logger.error(f"[PineconeRetrieveNode] æ£€ç´¢å¤±è´¥: {str(e)}")

            # è®°å½•æ€§èƒ½ç›‘æ§ï¼ˆå³ä½¿å¤±è´¥ä¹Ÿè¦è®°å½•ï¼‰
            end_time = time.time()
            duration = end_time - start_time
            monitor.record_timing("Pineconeæ£€ç´¢", duration)

            return update_state(
                state,
                error=f"æ£€ç´¢å¤±è´¥: {str(e)}",
                no_material_found=True,
                current_node="retrieve",
                next_node="exception"
            )

    def _retrieve_for_question(
        self,
        question: str,
        parameters: Dict,
        thinking_process: List[str],
        question_metadata: Dict = None
    ) -> tuple[List[Dict], Dict[str, int], str]:
        """
        ä¸ºå•ä¸ªé—®é¢˜æ£€ç´¢ææ–™ï¼ˆæ”¯æŒå•å¹´é’ˆå¯¹æ€§æ£€ç´¢ + Queryæ‰©å±•ï¼‰

        Args:
            question: é—®é¢˜
            parameters: æå–çš„å‚æ•°
            thinking_process: æ€è€ƒè¿‡ç¨‹åˆ—è¡¨(ç”¨äºè®°å½•)
            question_metadata: å­é—®é¢˜å…ƒæ•°æ®ï¼ˆåŒ…å«target_yearç­‰ï¼‰

        Returns:
            (æ£€ç´¢ç»“æœåˆ—è¡¨, å¹´ä»½åˆ†å¸ƒ, æ£€ç´¢æ–¹æ³•)
        """
        # === Phase 4: Queryæ‰©å±•ç­–ç•¥ ===
        # ç”ŸæˆæŸ¥è¯¢å˜ä½“ä»¥æé«˜å¬å›ç‡
        query_variants = self._generate_query_variants(question)
        thinking_process.append(f"ğŸ“ Queryæ‰©å±•: ç”Ÿæˆ {len(query_variants)} ä¸ªæŸ¥è¯¢å˜ä½“")
        for i, variant in enumerate(query_variants, 1):
            thinking_process.append(f"   å˜ä½“{i}: {variant[:80]}...")

        # ä¸ºæ¯ä¸ªå˜ä½“ç”Ÿæˆå‘é‡
        query_vectors = []
        for variant in query_variants:
            vector = self.embedding_client.embed_text(variant)
            query_vectors.append((variant, vector))

        # ===  æ–°å¢ï¼šå•å¹´é’ˆå¯¹æ€§æ£€ç´¢ç­–ç•¥ ===
        if question_metadata is None:
            question_metadata = {}

        target_year = question_metadata.get("target_year")
        retrieval_strategy = question_metadata.get("retrieval_strategy", "multi_year")

        # å­˜å‚¨æ‰€æœ‰å˜ä½“çš„æ£€ç´¢ç»“æœ
        all_results = []

        # ç­–ç•¥1: å•å¹´æ£€ç´¢ï¼ˆä¼˜å…ˆï¼‰
        if target_year and retrieval_strategy == "single_year":
            thinking_process.append(f"âœ… ä½¿ç”¨å•å¹´æ£€ç´¢ç­–ç•¥: target_year={target_year}")

            # æ„é€ å•å¹´è¿‡æ»¤æ¡ä»¶
            filters = self._extract_filters(parameters)
            # å¼ºåˆ¶è¦†ç›–yearä¸ºtarget_year
            filters['year'] = target_year

            thinking_process.append(f"å•å¹´è¿‡æ»¤æ¡ä»¶: {filters}")

            # å¯¹æ¯ä¸ªæŸ¥è¯¢å˜ä½“æ‰§è¡Œæ£€ç´¢
            for i, (variant_text, variant_vector) in enumerate(query_vectors, 1):
                variant_results = self.retriever.search(
                    query_vector=variant_vector,
                    limit=20,  # æ¯ä¸ªå˜ä½“å¬å›20ä¸ªï¼Œæ€»å…±æœ€å¤š60ä¸ª
                    filters=filters if filters else None
                )
                thinking_process.append(f"   å˜ä½“{i}å¬å›: {len(variant_results)}ä¸ªæ–‡æ¡£")
                all_results.extend(variant_results)

            retrieval_method = f"single_year_expanded(year={target_year}, variants={len(query_vectors)})"
            thinking_process.append(f"å•å¹´æ‰©å±•æ£€ç´¢å®Œæˆï¼Œæ€»è®¡ {len(all_results)} ä¸ªæ–‡æ¡£ï¼ˆå»é‡å‰ï¼‰")

        # ç­–ç•¥2: å¤šå¹´æ£€ç´¢ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
        else:
            # æå–è¿‡æ»¤æ¡ä»¶
            filters = self._extract_filters(parameters)
            thinking_process.append(f"è¿‡æ»¤æ¡ä»¶: {filters}")

            # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨å¤šå¹´ä»½ç­–ç•¥
            years = filters.get('year', [])
            if isinstance(years, str):
                years = [years]

            use_multi_year = (
                self.enable_multi_year_strategy and
                isinstance(years, list) and
                len(years) >= 3  # 3å¹´åŠä»¥ä¸Šä½¿ç”¨åˆ†å±‚æ£€ç´¢
            )

            if use_multi_year:
                thinking_process.append(f"æ£€æµ‹åˆ°{len(years)}å¹´è·¨åº¦ï¼Œä½¿ç”¨å¤šå¹´ä»½åˆ†å±‚æ£€ç´¢ç­–ç•¥")
                retrieval_method = f"multi_year_stratified_expanded(years={len(years)}, variants={len(query_vectors)})"

                # æå–å…¶ä»–è¿‡æ»¤æ¡ä»¶ï¼ˆå»é™¤yearï¼‰
                other_filters = {k: v for k, v in filters.items() if k != 'year'}

                # å¯¹æ¯ä¸ªæŸ¥è¯¢å˜ä½“æ‰§è¡Œå¤šå¹´ä»½æ£€ç´¢
                for i, (variant_text, variant_vector) in enumerate(query_vectors, 1):
                    variant_results = self.retriever.search_multi_year_parallel(
                        query_vector=variant_vector,
                        years=years,
                        limit_per_year=self.limit_per_year,
                        other_filters=other_filters if other_filters else None
                    )
                    thinking_process.append(f"   å˜ä½“{i}å¬å›: {len(variant_results)}ä¸ªæ–‡æ¡£")
                    all_results.extend(variant_results)
            else:
                thinking_process.append(f"ä½¿ç”¨æ ‡å‡†æ£€ç´¢ + Queryæ‰©å±•")
                retrieval_method = f"standard_expanded(variants={len(query_vectors)})"

                # å¯¹æ¯ä¸ªæŸ¥è¯¢å˜ä½“æ‰§è¡Œæ ‡å‡†æ£€ç´¢
                for i, (variant_text, variant_vector) in enumerate(query_vectors, 1):
                    variant_results = self.retriever.search(
                        query_vector=variant_vector,
                        limit=20,  # æ¯ä¸ªå˜ä½“20ä¸ª
                        filters=filters if filters else None
                    )
                    thinking_process.append(f"   å˜ä½“{i}å¬å›: {len(variant_results)}ä¸ªæ–‡æ¡£")
                    all_results.extend(variant_results)

        # å»é‡å¹¶æŒ‰ç›¸ä¼¼åº¦é‡æ–°æ’åº
        results = self._deduplicate_and_rerank(all_results, top_k=self.top_k)
        thinking_process.append(f"å»é‡å¹¶é‡æ’åºå: {len(results)}ä¸ªæ–‡æ¡£")

        # ç»Ÿè®¡å¹´ä»½åˆ†å¸ƒ
        year_distribution = {}
        for result in results:
            year = result['metadata'].get('year', 'unknown')
            year_distribution[year] = year_distribution.get(year, 0) + 1

        # æ ¼å¼åŒ–ç»“æœï¼ˆè½¬æ¢ä¸ºLangGraphç»Ÿä¸€æ ¼å¼ï¼‰
        chunks = []
        seen_texts = set()  # ç”¨äºå»é‡

        for result in results:
            metadata = result['metadata']
            text = result['text']

            # å»é‡ï¼šä½¿ç”¨æ–‡æœ¬çš„å‰100å­—ç¬¦ä½œä¸ºå”¯ä¸€æ ‡è¯†
            text_signature = text[:100] if len(text) > 100 else text

            if text_signature in seen_texts:
                logger.debug(f"[å»é‡] è·³è¿‡é‡å¤æ–‡æ¡£: {metadata.get('speaker')}, {metadata.get('date')}")
                continue

            seen_texts.add(text_signature)

            chunks.append({
                "text": text,
                "metadata": {
                    "year": metadata.get("year"),
                    "month": metadata.get("month"),
                    "day": metadata.get("day"),
                    "date": metadata.get("date"),
                    "id": metadata.get("id"),  # Document ID for citation
                    "source_reference": metadata.get("source_reference"),  # User-friendly reference
                    "speaker": metadata.get("speaker"),
                    "party": metadata.get("party"),
                    "group": metadata.get("group"),
                    "group_chinese": metadata.get("group_chinese"),
                    "session": metadata.get("session"),
                    "lp": metadata.get("lp"),
                },
                "score": result['score'],
                "id": result['id']
            })

        if len(seen_texts) < len(results):
            logger.info(f"[å»é‡] ç§»é™¤äº† {len(results) - len(seen_texts)} ä¸ªé‡å¤æ–‡æ¡£ï¼Œä¿ç•™ {len(chunks)} ä¸ª")

        return chunks, year_distribution, retrieval_method

    # å…šæ´¾åç§°æ˜ å°„ï¼ˆç»Ÿä¸€ä¸ºPineconeå­˜å‚¨æ ¼å¼ï¼‰
    PARTY_NAME_MAPPING = {
        "BÃœNDNIS 90/DIE GRÃœNEN": "GrÃ¼ne/BÃ¼ndnis 90",
        "BÃœNDNIS 90": "GrÃ¼ne/BÃ¼ndnis 90",
        "DIE GRÃœNEN": "GrÃ¼ne/BÃ¼ndnis 90",
        "GRÃœNE": "GrÃ¼ne/BÃ¼ndnis 90",
        "ç»¿å…š": "GrÃ¼ne/BÃ¼ndnis 90",
        # å…¶ä»–å…šæ´¾ä¿æŒä¸å˜
        "CDU/CSU": "CDU/CSU",
        "SPD": "SPD",
        "FDP": "FDP",
        "DIE LINKE": "DIE LINKE",
        "AfD": "AfD",
    }

    def _extract_filters(self, parameters: Dict) -> Dict:
        """
        ä»å‚æ•°ä¸­æå–Pineconeè¿‡æ»¤æ¡ä»¶

        æ”¯æŒæ—¶é—´è¯­ä¹‰ç†è§£:
        - "2015å¹´ä»¥æ¥" -> ['2015', '2016', ..., '2024']
        - "2015-2018" -> ['2015', '2016', '2017', '2018']
        - "2019å¹´" -> ['2019']

        Args:
            parameters: æå–çš„å‚æ•°

        Returns:
            Pineconeæ ¼å¼çš„è¿‡æ»¤æ¡ä»¶
        """
        filters = {}

        # æ—¶é—´è¿‡æ»¤ï¼ˆå¢å¼ºç‰ˆï¼‰
        time_range = parameters.get("time_range", {})

        # æå–å¹´ä»½å‚æ•°
        start_year = time_range.get("start_year")
        end_year = time_range.get("end_year")
        specific_years = time_range.get("specific_years", [])

        # ğŸ”§ ä¿®å¤: ä¼˜å…ˆä½¿ç”¨specific_yearsï¼ˆç¦»æ•£å¹´ä»½ï¼‰ï¼Œé¿å…ç¦»æ•£å¯¹æ¯”è¢«è¯¯åˆ¤ä¸ºè¿ç»­èŒƒå›´
        # ä¾‹å¦‚ "2019å¹´ä¸2017å¹´ç›¸æ¯”" åº”è¯¥åªæ£€ç´¢ ['2017', '2019']ï¼Œè€Œä¸æ˜¯ ['2017', '2018', '2019']
        if specific_years:
            # å…·ä½“å¹´ä»½åˆ—è¡¨ (ä¼˜å…ˆçº§æœ€é«˜ï¼Œæ”¯æŒç¦»æ•£å¯¹æ¯”)
            filters['year'] = specific_years if isinstance(specific_years, list) else [specific_years]
            logger.debug(f"[PineconeRetrieveNode] ä½¿ç”¨specific_years: {filters['year']}")
        elif start_year and end_year:
            # èŒƒå›´æŸ¥è¯¢: åªåœ¨æ²¡æœ‰specific_yearsæ—¶ä½¿ç”¨ï¼Œå±•å¼€ä¸ºè¿ç»­å¹´ä»½åˆ—è¡¨
            try:
                year_list = [str(y) for y in range(int(start_year), int(end_year) + 1)]
                filters['year'] = year_list
                logger.debug(f"[PineconeRetrieveNode] å¹´ä»½èŒƒå›´ {start_year}-{end_year} -> {year_list}")
            except:
                pass

        # å…šæ´¾è¿‡æ»¤
        parties = parameters.get("parties", [])
        if parties and parties != ["ALL_PARTIES"]:
            # è·³è¿‡ALL_PARTIESï¼ˆè¡¨ç¤ºä¸é™åˆ¶å…šæ´¾ï¼‰
            if "ALL_PARTIES" not in parties:
                # åº”ç”¨å…šæ´¾åç§°æ˜ å°„
                normalized_parties = [
                    self.PARTY_NAME_MAPPING.get(p, p) for p in parties
                ]
                filters['party'] = normalized_parties[0] if len(normalized_parties) == 1 else normalized_parties
                logger.debug(f"[PineconeRetrieveNode] å…šæ´¾æ˜ å°„: {parties} -> {normalized_parties}")

        # å‘è¨€äººè¿‡æ»¤
        speakers = parameters.get("speakers", [])
        if speakers:
            filters['speaker'] = speakers[0]

        return filters

    def _generate_query_variants(self, question: str) -> List[str]:
        """
        ç”ŸæˆæŸ¥è¯¢å˜ä½“ä»¥æé«˜å¬å›ç‡ï¼ˆPhase 4: Queryæ‰©å±•ï¼‰

        ç­–ç•¥:
        1. åŸå§‹æŸ¥è¯¢ï¼ˆä¿ç•™å®Œæ•´è¯­ä¹‰ï¼‰
        2. å…³é”®è¯æå–æŸ¥è¯¢ï¼ˆå»é™¤å†—ä½™è¯ï¼‰
        3. åŠ¨ä½œè¯å¼ºåŒ–æŸ¥è¯¢ï¼ˆé’ˆå¯¹å…·ä½“æªæ–½æ·»åŠ ç›¸å…³åŠ¨è¯ï¼‰

        Args:
            question: åŸå§‹é—®é¢˜

        Returns:
            æŸ¥è¯¢å˜ä½“åˆ—è¡¨ï¼ˆ3ä¸ªï¼‰
        """
        variants = []

        # å˜ä½“1: åŸå§‹æŸ¥è¯¢
        variants.append(question)

        # å˜ä½“2: å…³é”®è¯æå–ç‰ˆæœ¬
        keyword_query = self._extract_keywords(question)
        if keyword_query != question:  # åªæœ‰ä¸åŒæ—¶æ‰æ·»åŠ 
            variants.append(keyword_query)

        # å˜ä½“3: åŠ¨ä½œè¯å¼ºåŒ–ç‰ˆæœ¬
        action_query = self._generate_action_variant(question)
        if action_query not in variants:  # é¿å…é‡å¤
            variants.append(action_query)

        return variants

    def _extract_keywords(self, query: str) -> str:
        """
        æå–æŸ¥è¯¢ä¸­çš„å…³é”®è¯ï¼ˆæ— éœ€LLMï¼Œçº¯è§„åˆ™ï¼‰

        å»é™¤:
        - ç–‘é—®è¯: Was ist, Wie, Welche, etc.
        - åŠ©åŠ¨è¯: die Position von, im Jahr, etc.
        - ä»‹è¯: zur, zu, von, im, etc.

        ç¤ºä¾‹:
        "Was ist die Position von CDU/CSU zur Abschiebung und RÃ¼ckfÃ¼hrung im Jahr 2017?"
        â†’ "CDU/CSU Abschiebung RÃ¼ckfÃ¼hrung 2017"

        Args:
            query: åŸå§‹æŸ¥è¯¢

        Returns:
            å…³é”®è¯æŸ¥è¯¢
        """
        import re

        # ç§»é™¤å¸¸è§ç–‘é—®è¯å’ŒçŸ­è¯­
        noise_patterns = [
            r'\b(Was ist|Was sind|Wie|Welche|Welcher|Welches|Warum|Wann)\b',
            r'\b(die Position|die Positionen|die Hauptansichten|die Hauptposition)\b',
            r'\b(von|vom|zu|zur|zum|im|in der|in den|auf|fÃ¼r|Ã¼ber)\b',
            r'\b(Jahr|Zeitraum|Thema)\b',
            r'\?',  # é—®å·
        ]

        result = query
        for pattern in noise_patterns:
            result = re.sub(pattern, ' ', result, flags=re.IGNORECASE)

        # æ¸…ç†å¤šä½™ç©ºæ ¼
        result = ' '.join(result.split())

        return result.strip()

    def _generate_action_variant(self, query: str) -> str:
        """
        ç”ŸæˆåŠ¨ä½œè¯å¼ºåŒ–å˜ä½“ï¼ˆé’ˆå¯¹å…·ä½“æ”¿ç­–æªæ–½ï¼‰

        ç­–ç•¥: å¦‚æœæŸ¥è¯¢åŒ…å«æŸäº›æ”¿ç­–å…³é”®è¯ï¼Œè‡ªåŠ¨æ·»åŠ ç›¸å…³çš„åŠ¨ä½œè¯

        ç¤ºä¾‹:
        - "Abschiebung" â†’ æ·»åŠ  "durchsetzen Zwang Ausreisepflicht"
        - "Integration" â†’ æ·»åŠ  "fÃ¶rdern MaÃŸnahmen Programme"
        - "Klimaschutz" â†’ æ·»åŠ  "umsetzen Reduktion MaÃŸnahmen"

        Args:
            query: åŸå§‹æŸ¥è¯¢

        Returns:
            åŠ¨ä½œè¯å¼ºåŒ–æŸ¥è¯¢
        """
        # åŠ¨ä½œè¯æ˜ å°„è¡¨ï¼ˆé’ˆå¯¹å¾·å›½è®®ä¼šæ”¿ç­–é¢†åŸŸï¼‰
        action_keywords_map = {
            # ç§»æ°‘/é£è¿”æ”¿ç­–
            "Abschiebung": "durchsetzen Zwang Ausreisepflicht konsequent",
            "RÃ¼ckfÃ¼hrung": "durchsetzen Zwang Ausreisepflicht konsequent",
            "Migrationspolitik": "Abschiebung RÃ¼ckfÃ¼hrung Zwang Ausreisepflicht",

            # èåˆæ”¿ç­–
            "Integration": "fÃ¶rdern MaÃŸnahmen Programme Sprache Bildung",
            "Aufnahme": "fÃ¶rdern Programme UnterstÃ¼tzung",

            # æ°”å€™æ”¿ç­–
            "Klimaschutz": "umsetzen Reduktion MaÃŸnahmen Emissionen",
            "Klimapolitik": "Emissionen Reduktion MaÃŸnahmen umsetzen",

            # æ•°å­—åŒ–
            "Digitalisierung": "vorantreiben Infrastruktur Ausbau fÃ¶rdern",

            # è¾¹å¢ƒæ§åˆ¶
            "Grenzkontrollen": "verstÃ¤rken durchsetzen Sicherheit",
            "Obergrenze": "festlegen durchsetzen begrenzen",
        }

        # æå–å…³é”®è¯ç‰ˆæœ¬ä½œä¸ºåŸºç¡€
        base = self._extract_keywords(query)

        # æ£€æŸ¥æ˜¯å¦åŒ¹é…ä»»ä½•æ”¿ç­–å…³é”®è¯
        for keyword, action_words in action_keywords_map.items():
            if keyword in query:
                # æ·»åŠ åŠ¨ä½œè¯
                return f"{base} {action_words}"

        # å¦‚æœæ²¡æœ‰åŒ¹é…çš„å…³é”®è¯ï¼Œè¿”å›å…³é”®è¯ç‰ˆæœ¬
        return base

    def _deduplicate_and_rerank(self, results: List[Dict], top_k: int) -> List[Dict]:
        """
        å»é‡å¹¶æŒ‰ç›¸ä¼¼åº¦é‡æ–°æ’åº

        Args:
            results: æ£€ç´¢ç»“æœåˆ—è¡¨ï¼ˆå¯èƒ½åŒ…å«é‡å¤ï¼‰
            top_k: ä¿ç•™çš„æ–‡æ¡£æ•°

        Returns:
            å»é‡å¹¶æ’åºåçš„ç»“æœåˆ—è¡¨
        """
        # ä½¿ç”¨æ–‡æ¡£IDå»é‡ï¼ˆPineconeçš„IDæ˜¯å”¯ä¸€çš„ï¼‰
        seen_ids = set()
        unique_results = []

        for result in results:
            doc_id = result.get('id')
            if doc_id not in seen_ids:
                seen_ids.add(doc_id)
                unique_results.append(result)

        # æŒ‰ç›¸ä¼¼åº¦é™åºæ’åº
        unique_results.sort(key=lambda x: x.get('score', 0), reverse=True)

        # ä¿ç•™top_kä¸ª
        return unique_results[:top_k]


if __name__ == "__main__":
    # æµ‹è¯•Pineconeæ£€ç´¢èŠ‚ç‚¹
    from ..state import create_initial_state, update_state

    print("=== Pineconeæ£€ç´¢èŠ‚ç‚¹æµ‹è¯• ===")

    # æµ‹è¯•å¤šå¹´ä»½æ£€ç´¢
    question = "è¯·æ¦‚è¿°2015å¹´ä»¥æ¥å¾·å›½åŸºæ°‘ç›Ÿå¯¹éš¾æ°‘æ”¿ç­–çš„ç«‹åœºå‘ç”Ÿäº†å“ªäº›ä¸»è¦å˜åŒ–ã€‚"
    state = create_initial_state(question)
    state = update_state(
        state,
        intent="complex",
        question_type="å˜åŒ–ç±»",
        parameters={
            "time_range": {
                "start_year": "2015",
                "end_year": "2024",
                "specific_years": [str(y) for y in range(2015, 2025)]
            },
            "parties": ["CDU/CSU"],
            "topics": ["éš¾æ°‘"]
        }
    )

    print(f"é—®é¢˜: {question}")
    print(f"å‚æ•°: {state['parameters']}")
    print("\nå¦‚éœ€å®Œæ•´æµ‹è¯•,è¯·ç¡®ä¿:")
    print("1. PINECONE_VECTOR_DATABASE_API_KEYå·²è®¾ç½®")
    print("2. Pineconeç´¢å¼•german-bgeå­˜åœ¨ä¸”æœ‰2015-2024æ•°æ®")
    print("3. è¿è¡Œ: python -m src.graph.nodes.retrieve_pinecone")

    try:
        node = PineconeRetrieveNode()
        print(f"\nâœ… èŠ‚ç‚¹åˆ›å»ºæˆåŠŸï¼Œé…ç½®:")
        print(f"   - top_k: {node.top_k}")
        print(f"   - å¤šå¹´ä»½ç­–ç•¥: {node.enable_multi_year_strategy}")
        print(f"   - æ¯å¹´æ–‡æ¡£æ•°: {node.limit_per_year}")

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
