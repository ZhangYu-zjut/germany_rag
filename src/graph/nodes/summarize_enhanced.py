"""
å¢å¼ºç‰ˆæ€»ç»“èŠ‚ç‚¹
æ”¯æŒåˆ†å±‚æ€»ç»“å’Œæ¨¡å—åŒ–è¾“å‡º + ç»“æ„åŒ–éªŒè¯ï¼ˆé˜²æ­¢LLMè¿‡æ»¤æ¬¡è¦è®ºç‚¹ï¼‰
"""

from typing import List, Dict, Optional, Tuple
import re
from ...llm.client import GeminiLLMClient
from ...llm.prompts_summarize import SummarizePrompts
from ...llm.prompts_summarize_enhanced import EnhancedSummarizePrompts
from ...utils.logger import logger
from ..state import GraphState, update_state
from ...config import settings


class EnhancedSummarizeNode:
    """
    å¢å¼ºç‰ˆæ€»ç»“èŠ‚ç‚¹

    æ ¸å¿ƒæ”¹è¿›:
    1. æ ¹æ®é—®é¢˜ç±»å‹é€‰æ‹©å®šåˆ¶åŒ–Prompt
    2. æ¨¡å—åŒ–å¾·æ–‡è¾“å‡ºï¼ˆspeaker/statement/evidence/sourceï¼‰
    3. åˆ†å±‚æ€»ç»“ï¼ˆå•å­é—®é¢˜ â†’ å¤šå­é—®é¢˜æ•´åˆï¼‰
    4. å¾·æ–‡ç³»ç»ŸPrompt
    5. ã€æ–°å¢ã€‘ç»†èŠ‚å¼ºåˆ¶å¼•ç”¨æœºåˆ¶ï¼ˆè§£å†³Q5/Q6ç±»é—®é¢˜ï¼‰

    æ”¯æŒçš„é—®é¢˜ç±»å‹:
    - å˜åŒ–ç±»: æ—¶é—´åºåˆ—åˆ†æ + è½¬æŠ˜ç‚¹è¯†åˆ«
    - å¯¹æ¯”ç±»: å¯¹æ¯”è¡¨æ ¼ + å·®å¼‚åˆ†æ
    - æ€»ç»“ç±»: ä¸»é¢˜åˆ†ç»„ + æ ¸å¿ƒè§‚ç‚¹
    - è¶‹åŠ¿åˆ†æ: é˜¶æ®µåˆ’åˆ† + è¶‹åŠ¿è¯†åˆ«
    """

    # é¢„å®šä¹‰çš„é‡è¦åœ°åï¼ˆå¾·è¯­ï¼‰
    IMPORTANT_LOCATIONS = [
        "Syrien", "Georgien", "Afghanistan", "TÃ¼rkei", "Irak", "Iran",
        "Nordafrika", "Balkan", "Griechenland", "Italien",
        "syrisch", "georgisch", "tÃ¼rkisch", "afghanisch"
    ]

    # é¢„å®šä¹‰çš„é‡è¦æ”¿ç­–/é¡¹ç›®å…³é”®è¯ï¼ˆæ‰©å±•ç‰ˆ - è§£å†³Q5/Q6/Q7åé¦ˆé—®é¢˜ï¼‰
    IMPORTANT_POLICY_KEYWORDS = [
        # æ–‡åŒ–æ”¿ç­–
        "Kultur baut BrÃ¼cken", "Kultur macht stark",
        # ç­¾è¯ä¸å…¥å¢ƒ
        "Visum", "visumfrei", "Visumspflicht", "visumspflichtig",
        "Visaliberalisierung", "Visa-Aussetzung",
        # ç§»æ°‘æ³•å¾‹
        "Integrationsgesetz", "FachkrÃ¤fteeinwanderungsgesetz",
        "Familiennachzug", "Obergrenze", "AnKER-Zentren", "Ankerzentren",
        # é£è¿”ä¸æ‹˜ç•™
        "sichere HerkunftslÃ¤nder", "Abschiebung", "RÃ¼ckfÃ¼hrung",
        "Ausreisegewahrsam", "Abschiebungshaft", "HÃ¶chstdauer",
        # å™åˆ©äºšé‡å»º
        "Wiederaufbau", "RÃ¼ckkehrvoraussetzung", "Voraussetzung",
        # è¾¹å¢ƒæ§åˆ¶
        "Grenzkontrollen", "Dublin", "ZurÃ¼ckweisung",
    ]

    def __init__(self, llm_client: GeminiLLMClient = None):
        """
        åˆå§‹åŒ–å¢å¼ºç‰ˆæ€»ç»“èŠ‚ç‚¹

        Args:
            llm_client: LLMå®¢æˆ·ç«¯
        """
        self.llm = llm_client or GeminiLLMClient()
        self.prompts = SummarizePrompts()
        self.enhanced_prompts = EnhancedSummarizePrompts()
        self.production_mode = settings.production_mode
        # å¯ç”¨ç»“æ„åŒ–éªŒè¯ï¼ˆä¿®å¤Q6ç±»é—®é¢˜ï¼‰
        self.enable_robust_mode = True
        # ã€æ–°å¢ã€‘å¯ç”¨ç»†èŠ‚å¼ºåˆ¶å¼•ç”¨ï¼ˆè§£å†³Q5/Q6ç±»é—®é¢˜ï¼‰
        self.enable_detail_citation = True
        
    def __call__(self, state: GraphState) -> GraphState:
        """
        æ‰§è¡Œæ€»ç»“
        
        Args:
            state: å½“å‰çŠ¶æ€
            
        Returns:
            æ›´æ–°åçš„çŠ¶æ€
        """
        question = state["question"]
        question_type = state.get("question_type", "")
        # è·å–é‡æ’åºåçš„æ£€ç´¢ç»“æœï¼ˆä¼˜å…ˆï¼‰æˆ–åŸå§‹æ£€ç´¢ç»“æœï¼ˆé™çº§ï¼‰
        reranked_results = state.get("reranked_results", [])
        retrieval_results = state.get("retrieval_results", [])
        
        # ä¼˜å…ˆä½¿ç”¨é‡æ’åºç»“æœï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨åŸå§‹æ£€ç´¢ç»“æœ
        if reranked_results:
            logger.info(f"[EnhancedSummarizeNode] ä½¿ç”¨é‡æ’åºç»“æœ ({len(reranked_results)} ä¸ª)")
            processing_results = reranked_results
        else:
            logger.info(f"[EnhancedSummarizeNode] é‡æ’åºç»“æœä¸å­˜åœ¨ï¼Œä½¿ç”¨åŸå§‹æ£€ç´¢ç»“æœ ({len(retrieval_results)} ä¸ª)")
            processing_results = retrieval_results
            
        sub_questions = state.get("sub_questions")
        is_decomposed = state.get("is_decomposed", False)
        
        logger.info(f"[EnhancedSummarizeNode] å¼€å§‹æ€»ç»“")
        logger.info(f"[EnhancedSummarizeNode] é—®é¢˜ç±»å‹: {question_type}")
        logger.info(f"[EnhancedSummarizeNode] å¤„ç†ç»“æœæ•°: {len(processing_results)}")
        logger.info(f"[EnhancedSummarizeNode] æ˜¯å¦æ‹†è§£: {is_decomposed}")
        
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰ææ–™
            if not processing_results or len(processing_results) == 0:
                logger.warning("[EnhancedSummarizeNode] æ— æ£€ç´¢ç»“æœ")
                return update_state(
                    state,
                    error="æœªæ‰¾åˆ°ç›¸å…³ææ–™",
                    error_type="NO_MATERIAL",
                    no_material_found=True,
                    current_node="summarize",
                    next_node="exception"
                )
            
            # åˆ¤æ–­æ˜¯å•é—®é¢˜è¿˜æ˜¯å¤šé—®é¢˜æ€»ç»“
            if is_decomposed and len(processing_results) > 1:
                # å¤šé—®é¢˜æ€»ç»“ï¼ˆé—®é¢˜è¢«åˆ†è§£ä¸ºå­é—®é¢˜ï¼‰
                final_answer, sub_answers = self._multi_question_summarize(
                    question=question,
                    question_type=question_type,
                    retrieval_results=processing_results
                )
            else:
                # å•é—®é¢˜æ€»ç»“
                # ã€BUGä¿®å¤ã€‘å½“æœ‰å¤šä¸ªæ£€ç´¢ç»“æœæ—¶ï¼ˆå¦‚çŸ¥è¯†å›¾è°±æ‰©å±•åœºæ™¯ï¼‰ï¼Œéœ€è¦åˆå¹¶æ‰€æœ‰chunks
                if len(processing_results) > 1:
                    logger.info(f"[EnhancedSummarizeNode] ğŸ”§ åˆå¹¶ {len(processing_results)} ä¸ªæ£€ç´¢ç»“æœçš„chunks")
                    merged_result = self._merge_retrieval_results(processing_results, question)
                    logger.info(f"[EnhancedSummarizeNode] åˆå¹¶åchunksæ•°: {len(merged_result.get('chunks', []))}")
                else:
                    merged_result = processing_results[0] if processing_results else None

                final_answer, sub_answers = self._single_question_summarize(
                    question=question,
                    retrieval_result=merged_result
                )
            
            logger.info(f"[EnhancedSummarizeNode] æ€»ç»“å®Œæˆ")
            logger.info(f"[EnhancedSummarizeNode] ç­”æ¡ˆé•¿åº¦: {len(final_answer)} å­—ç¬¦")
            
            # æ›´æ–°çŠ¶æ€
            return update_state(
                state,
                final_answer=final_answer,
                sub_answers=sub_answers,
                current_node="summarize",
                next_node="end"
            )
            
        except Exception as e:
            logger.error(f"[EnhancedSummarizeNode] æ€»ç»“å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            
            return update_state(
                state,
                error=f"æ€»ç»“å¤±è´¥: {str(e)}",
                error_type="LLM_ERROR",
                current_node="summarize",
                next_node="exception"
            )
    
    def _single_question_summarize(
        self,
        question: str,
        retrieval_result: Optional[Dict]
    ) -> Tuple[str, Optional[List[Dict]]]:
        """
        å•é—®é¢˜æ€»ç»“ï¼ˆä½¿ç”¨æ¨¡å—åŒ–è¾“å‡º + ç»“æ„åŒ–éªŒè¯ï¼‰

        Args:
            question: é—®é¢˜
            retrieval_result: æ£€ç´¢ç»“æœ

        Returns:
            (final_answer, sub_answers)
        """
        logger.info(f"[EnhancedSummarizeNode] å•é—®é¢˜æ€»ç»“ï¼ˆé²æ£’æ¨¡å¼: {self.enable_robust_mode}ï¼‰")

        if not retrieval_result or not retrieval_result.get("chunks"):
            logger.warning("[EnhancedSummarizeNode] æ£€ç´¢ç»“æœä¸ºç©º")
            return "Entschuldigung, es wurden keine relevanten Materialien gefunden.", None

        chunks = retrieval_result.get("chunks", [])
        total_materials = len(chunks)
        logger.info(f"[EnhancedSummarizeNode] ææ–™æ•°é‡: {total_materials}")

        # æ ¼å¼åŒ–ä¸Šä¸‹æ–‡
        context = self._format_context(chunks)

        # ã€æœ€ä¼˜æ–¹æ¡ˆã€‘åœ¨åˆå§‹Promptä¸­å°±å¼ºåˆ¶è¦æ±‚ä¿ç•™å…³é”®æ”¿ç­–è¯ï¼ˆè€Œéäº‹åé‡è¯•ï¼‰
        detail_requirement = ""
        critical_keywords_found = []
        if self.enable_detail_citation:
            key_details = self._extract_key_details(chunks)
            if key_details:
                # ç­›é€‰å…³é”®æ”¿ç­–è¯
                critical_patterns = ["Visum", "visumspflichtig", "Kultur baut", "Wiederaufbau", "Ausreisegewahrsam", "Voraussetzung"]
                critical_keywords_found = [d for d in key_details if any(kw in d for kw in critical_patterns)]

                if critical_keywords_found:
                    logger.info(f"[EnhancedSummarizeNode] ğŸ”¥ æ£€æµ‹åˆ°{len(critical_keywords_found)}ä¸ªå…³é”®æ”¿ç­–è¯ï¼Œå°†åœ¨Promptä¸­å¼ºåˆ¶è¦æ±‚ä¿ç•™")

                    # ä»chunksä¸­æå–è¯æ®ï¼Œå¢å¼ºè¯´æœåŠ›
                    evidence_lines = []
                    for kw in critical_keywords_found:
                        for chunk in chunks:
                            text = chunk.get("text", "")
                            if kw.lower() in text.lower():
                                kw_pos = text.lower().find(kw.lower())
                                start = max(0, kw_pos - 60)
                                end = min(len(text), kw_pos + len(kw) + 60)
                                excerpt = text[start:end].strip()
                                speaker = chunk.get("metadata", {}).get("speaker", "Unknown")
                                evidence_lines.append(f'  â€¢ "{kw}" â†’ "{excerpt}..." ({speaker})')
                                break

                    evidence_text = "\n".join(evidence_lines) if evidence_lines else ""

                    detail_requirement = f"""
[âš ï¸ PFLICHT-DETAILS - Diese Begriffe MÃœSSEN wÃ¶rtlich in der Zusammenfassung erscheinen]

Die folgenden spezifischen Politikbegriffe wurden in den Materialien gefunden:
{chr(10).join([f'  â€¢ {kw}' for kw in critical_keywords_found])}

Belege aus den Materialien:
{evidence_text}

WICHTIG:
- Diese Begriffe dÃ¼rfen NICHT abstrahiert werden (z.B. "visumspflichtig" â†’ NICHT "Druck ausÃ¼ben")
- Sie MÃœSSEN wÃ¶rtlich im Abschnitt "Zusammenfassung" oder "Hauptpositionen" erscheinen
- Wenn Material 1 "Georgien visumspflichtig zu machen" fordert, muss die Zusammenfassung "visumspflichtig" enthalten

"""

        # æ ¹æ®æ¨¡å¼é€‰æ‹©Promptæ¨¡æ¿
        if self.enable_robust_mode:
            # ä½¿ç”¨ç»“æ„åŒ–éªŒè¯ç‰ˆPrompt
            prompt = self.enhanced_prompts.build_single_question_prompt_robust(
                question=question,
                context=context,
                total_materials=total_materials
            )
            logger.info("[EnhancedSummarizeNode] ä½¿ç”¨ç»“æ„åŒ–éªŒè¯ç‰ˆPrompt")
        else:
            # ä½¿ç”¨åŸå§‹æ¨¡å—åŒ–Prompt
            prompt = self.prompts.SINGLE_QUESTION_MODULAR.format(
                question=question,
                context=context
            )
            logger.info("[EnhancedSummarizeNode] ä½¿ç”¨åŸå§‹æ¨¡å—åŒ–Prompt")

        # æ·»åŠ å¾·æ–‡ç³»ç»ŸPrompt + å…³é”®è¯å¼ºåˆ¶è¦æ±‚ï¼ˆåœ¨Promptæœ€å‰é¢ï¼Œä¼˜å…ˆçº§æœ€é«˜ï¼‰
        full_prompt = f"{self.enhanced_prompts.SYSTEM_PROMPT_DE}\n\n{detail_requirement}{prompt}"

        # è°ƒç”¨LLM
        logger.debug("[EnhancedSummarizeNode] è°ƒç”¨LLM...")
        answer = self.llm.invoke(full_prompt)

        logger.debug(f"[EnhancedSummarizeNode] ç­”æ¡ˆé¢„è§ˆ: {answer[:200]}...")

        # å¦‚æœå¯ç”¨é²æ£’æ¨¡å¼ï¼Œè¿›è¡Œææ–™è¦†ç›–éªŒè¯
        if self.enable_robust_mode:
            is_complete, missing = self._verify_material_coverage(answer, total_materials)

            if not is_complete:
                logger.warning(
                    f"ğŸ”„ æ£€æµ‹åˆ°{len(missing)}ä¸ªææ–™ç¼ºå¤±: {missing}ï¼Œ"
                    f"è¦æ±‚LLMé‡æ–°ç”Ÿæˆ..."
                )

                # è¡¥å……Promptï¼šæ˜ç¡®æŒ‡å‡ºç¼ºå¤±çš„ææ–™
                retry_prompt = f"""
WICHTIG: Ihre vorherige Antwort hat folgende Materialien nicht bewertet:
{', '.join([f'Material {n}' for n in missing])}

Bitte bewerten Sie ALLE {total_materials} Materialien in Schritt 1 und erstellen Sie die Zusammenfassung erneut.

{prompt}
"""

                full_retry_prompt = f"{self.enhanced_prompts.SYSTEM_PROMPT_DE}\n\n{retry_prompt}"

                # é‡è¯•
                logger.info("[EnhancedSummarizeNode] ğŸ”„ é‡è¯•LLMè°ƒç”¨...")
                answer = self.llm.invoke(full_retry_prompt)

                # å†æ¬¡éªŒè¯
                is_complete_retry, missing_retry = self._verify_material_coverage(answer, total_materials)

                if not is_complete_retry:
                    logger.error(
                        f"âŒ é‡è¯•åä»æœ‰{len(missing_retry)}ä¸ªææ–™ç¼ºå¤±: {missing_retry}ï¼Œ"
                        f"ä½¿ç”¨ä¸å®Œæ•´ç­”æ¡ˆ"
                    )
                else:
                    logger.info("âœ… é‡è¯•æˆåŠŸï¼Œæ‰€æœ‰ææ–™å·²è¦†ç›–")

        # ã€éªŒè¯ã€‘æ£€æŸ¥å…³é”®æ”¿ç­–è¯æ˜¯å¦åœ¨æ€»ç»“éƒ¨åˆ†å‡ºç°ï¼ˆç”¨äºç¡®è®¤"äº‹å‰é¢„é˜²"æ•ˆæœï¼‰
        if self.enable_detail_citation and critical_keywords_found:
            summary_section = self._extract_summary_section(answer)

            # æ£€æŸ¥æ˜¯å¦åœ¨æ€»ç»“éƒ¨åˆ†å‡ºç°
            missing_in_summary = [d for d in critical_keywords_found if d.lower() not in summary_section.lower()]

            if missing_in_summary:
                # æ£€æµ‹å‡é˜³æ€§ï¼šåœ¨æ•´ä¸ªç­”æ¡ˆä¸­ä½†ä¸åœ¨æ€»ç»“éƒ¨åˆ†
                false_positives = [d for d in missing_in_summary if d.lower() in answer.lower()]
                if false_positives:
                    logger.warning(f"[EnhancedSummarizeNode] âš ï¸ å‡é˜³æ€§ï¼ˆä»…åœ¨Materialbewertungï¼‰: {false_positives}")

                logger.warning(f"[EnhancedSummarizeNode] âš ï¸ å…³é”®æ”¿ç­–è¯åœ¨æ€»ç»“éƒ¨åˆ†ç¼ºå¤±: {missing_in_summary}")
            else:
                logger.info(f"[EnhancedSummarizeNode] âœ… æ‰€æœ‰å…³é”®æ”¿ç­–è¯å·²åœ¨æ€»ç»“éƒ¨åˆ†ä¿ç•™: {critical_keywords_found}")

        return answer, None

    def _merge_retrieval_results(
        self,
        processing_results: List[Dict],
        question: str,
        max_chunks: int = 50
    ) -> Dict:
        """
        åˆå¹¶å¤šä¸ªæ£€ç´¢ç»“æœçš„chunksï¼ˆçŸ¥è¯†å›¾è°±æ‰©å±•åœºæ™¯ï¼‰

        åŠŸèƒ½ï¼š
        1. åˆå¹¶æ‰€æœ‰æ£€ç´¢ç»“æœçš„chunks
        2. åŸºäºtext_idå»é‡ï¼ˆä¿ç•™ç›¸ä¼¼åº¦æœ€é«˜çš„ç‰ˆæœ¬ï¼‰
        3. æŒ‰ç›¸ä¼¼åº¦é™åºæ’åº
        4. é™åˆ¶æœ€å¤§æ•°é‡é¿å…contextè¿‡é•¿

        Args:
            processing_results: å¤šä¸ªæ£€ç´¢ç»“æœ
            question: åŸå§‹é—®é¢˜
            max_chunks: æœ€å¤§chunksæ•°é‡

        Returns:
            åˆå¹¶åçš„æ£€ç´¢ç»“æœ
        """
        # æ”¶é›†æ‰€æœ‰chunksï¼Œç”¨text_idå»é‡
        seen_text_ids = {}  # text_id -> (chunk, score)
        seen_texts = {}     # text[:200] -> (chunk, score)  ç”¨äºå¤„ç†æ— text_idçš„æƒ…å†µ

        for result in processing_results:
            chunks = result.get("chunks", [])
            for chunk in chunks:
                text_id = chunk.get("metadata", {}).get("text_id", "")
                score = chunk.get("score", 0.0)
                text_preview = chunk.get("text", "")[:200]

                # ä¼˜å…ˆç”¨text_idå»é‡
                if text_id:
                    if text_id not in seen_text_ids or score > seen_text_ids[text_id][1]:
                        seen_text_ids[text_id] = (chunk, score)
                else:
                    # æ— text_idæ—¶ç”¨æ–‡æœ¬å‰200å­—ç¬¦å»é‡
                    if text_preview not in seen_texts or score > seen_texts[text_preview][1]:
                        seen_texts[text_preview] = (chunk, score)

        # åˆå¹¶å»é‡ç»“æœ
        all_chunks = [item[0] for item in seen_text_ids.values()]
        all_chunks.extend([item[0] for item in seen_texts.values()])

        # æŒ‰ç›¸ä¼¼åº¦é™åºæ’åº
        all_chunks.sort(key=lambda x: x.get("score", 0.0), reverse=True)

        # é™åˆ¶æ•°é‡
        final_chunks = all_chunks[:max_chunks]

        logger.info(
            f"[EnhancedSummarizeNode] åˆå¹¶æ£€ç´¢ç»“æœ: "
            f"åŸå§‹{sum(len(r.get('chunks', [])) for r in processing_results)}ä¸ª -> "
            f"å»é‡å{len(all_chunks)}ä¸ª -> æˆªå–{len(final_chunks)}ä¸ª"
        )

        return {
            "question": question,
            "chunks": final_chunks
        }

    def _multi_question_summarize(
        self,
        question: str,
        question_type: str,
        retrieval_results: List[Dict]
    ) -> Tuple[str, List[Dict]]:
        """
        å¤šé—®é¢˜åˆ†å±‚æ€»ç»“

        æµç¨‹:
        - ç”Ÿäº§æ¨¡å¼: è·³è¿‡å­ç­”æ¡ˆç”Ÿæˆï¼Œç›´æ¥ä»æ‰€æœ‰chunksç”Ÿæˆæœ€ç»ˆç­”æ¡ˆï¼ˆçœ26åˆ†é’Ÿï¼‰
        - æµ‹è¯•æ¨¡å¼: åŸå§‹æµç¨‹ï¼ˆç”Ÿæˆå­ç­”æ¡ˆ+æœ€ç»ˆç­”æ¡ˆï¼‰

        Args:
            question: åŸå§‹é—®é¢˜
            question_type: é—®é¢˜ç±»å‹
            retrieval_results: æ£€ç´¢ç»“æœåˆ—è¡¨

        Returns:
            (final_answer, sub_answers)
        """
        logger.info(f"[EnhancedSummarizeNode] å¤šé—®é¢˜åˆ†å±‚æ€»ç»“")
        logger.info(f"[EnhancedSummarizeNode] å­é—®é¢˜æ•°: {len(retrieval_results)}")
        logger.info(f"[EnhancedSummarizeNode] è¿è¡Œæ¨¡å¼: {'ç”Ÿäº§æ¨¡å¼' if self.production_mode else 'æµ‹è¯•æ¨¡å¼'}")

        # ç”Ÿäº§æ¨¡å¼ï¼šè·³è¿‡å­ç­”æ¡ˆç”Ÿæˆï¼Œç›´æ¥ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
        if self.production_mode:
            logger.info("[EnhancedSummarizeNode] ğŸš€ ç”Ÿäº§æ¨¡å¼ï¼šè·³è¿‡å­ç­”æ¡ˆç”Ÿæˆï¼Œç›´æ¥ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ")
            return self._production_mode_summarize(question, question_type, retrieval_results)

        # æµ‹è¯•æ¨¡å¼ï¼šåŸå§‹åˆ†å±‚æ€»ç»“æµç¨‹
        logger.info("[EnhancedSummarizeNode] ğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šç”Ÿæˆè¯¦ç»†å­ç­”æ¡ˆ")

        # Step 1: ä¸ºæ¯ä¸ªå­é—®é¢˜ç”Ÿæˆç­”æ¡ˆ
        sub_answers = []

        for i, result in enumerate(retrieval_results, 1):
            sub_question = result["question"]
            chunks = result.get("chunks", [])

            logger.info(f"[EnhancedSummarizeNode] å¤„ç†å­é—®é¢˜ {i}/{len(retrieval_results)}: {sub_question}")

            if chunks and len(chunks) > 0:
                # æ ¼å¼åŒ–ä¸Šä¸‹æ–‡
                context = self._format_context(chunks)

                # æ„å»ºPrompt
                prompt = self.prompts.SINGLE_QUESTION_MODULAR.format(
                    question=sub_question,
                    context=context
                )

                full_prompt = f"{self.prompts.SYSTEM_PROMPT_DE}\n\n{prompt}"

                # è°ƒç”¨LLM
                sub_answer = self.llm.invoke(full_prompt)

                # æå–æ¥æº
                sources = self._extract_sources(chunks)
            else:
                logger.warning(f"[EnhancedSummarizeNode] å­é—®é¢˜ {i} æ— ææ–™")
                sub_answer = "Keine relevanten Materialien gefunden."
                sources = []

            sub_answers.append({
                "question": sub_question,
                "answer": sub_answer,
                "sources": sources
            })

            logger.debug(f"[EnhancedSummarizeNode] å­ç­”æ¡ˆ {i} é•¿åº¦: {len(sub_answer)}")

        # Step 2: æ ¹æ®é—®é¢˜ç±»å‹é€‰æ‹©æ•´åˆæ¨¡æ¿
        summary_template = self.prompts.select_summary_template(question_type)

        logger.info(f"[EnhancedSummarizeNode] ä½¿ç”¨æ¨¡æ¿ç±»å‹: {question_type}")

        # Step 3: æ ¼å¼åŒ–å­é—®é¢˜ç­”æ¡ˆå¯¹
        sub_qa_text = self.prompts.format_sub_qa_pairs(sub_answers)

        # Step 4: æ„å»ºæœ€ç»ˆPrompt
        final_prompt = summary_template.format(
            original_question=question,
            sub_qa_pairs=sub_qa_text
        )

        full_final_prompt = f"{self.prompts.SYSTEM_PROMPT_DE}\n\n{final_prompt}"

        # Step 5: è°ƒç”¨LLMç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
        logger.info("[EnhancedSummarizeNode] ç”Ÿæˆæœ€ç»ˆæ•´åˆç­”æ¡ˆ...")
        final_answer = self.llm.invoke(full_final_prompt)

        logger.info(f"[EnhancedSummarizeNode] æœ€ç»ˆç­”æ¡ˆé•¿åº¦: {len(final_answer)}")

        return final_answer, sub_answers

    def _production_mode_summarize(
        self,
        question: str,
        question_type: str,
        retrieval_results: List[Dict]
    ) -> Tuple[str, Optional[List[Dict]]]:
        """
        ç”Ÿäº§æ¨¡å¼æ€»ç»“ï¼šè·³è¿‡å­ç­”æ¡ˆç”Ÿæˆï¼Œç›´æ¥ä»æ‰€æœ‰chunksç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ

        æ€§èƒ½ä¼˜åŒ–ï¼š
        - ä¸ç”Ÿæˆ40ä¸ªå­ç­”æ¡ˆï¼ˆçœ26åˆ†é’Ÿï¼‰
        - ç›´æ¥æ•´åˆæ‰€æœ‰retrieval_resultsçš„chunks
        - ä¸€æ¬¡LLMè°ƒç”¨ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ

        Args:
            question: åŸå§‹é—®é¢˜
            question_type: é—®é¢˜ç±»å‹
            retrieval_results: æ£€ç´¢ç»“æœåˆ—è¡¨

        Returns:
            (final_answer, None)
        """
        logger.info(f"[EnhancedSummarizeNode] ğŸš€ ç”Ÿäº§æ¨¡å¼ï¼šæ•´åˆæ‰€æœ‰æ£€ç´¢ç»“æœ")

        # Step 1: æ”¶é›†æ‰€æœ‰chunks
        all_chunks = []
        for result in retrieval_results:
            chunks = result.get("chunks", [])
            all_chunks.extend(chunks)

        logger.info(f"[EnhancedSummarizeNode] æ€»chunksæ•°: {len(all_chunks)}")

        # Step 2: å»é‡ï¼ˆåŸºäºidï¼‰
        unique_chunks = {}
        for chunk in all_chunks:
            # IDåœ¨é¡¶å±‚ï¼ˆä¼˜å…ˆï¼‰æˆ–metadataä¸­
            chunk_id = chunk.get("id") or chunk.get("metadata", {}).get("id", "")
            if chunk_id:
                # ä¿ç•™åˆ†æ•°æœ€é«˜çš„chunk
                if chunk_id not in unique_chunks or chunk.get("score", 0) > unique_chunks[chunk_id].get("score", 0):
                    unique_chunks[chunk_id] = chunk

        deduplicated_chunks = list(unique_chunks.values())
        logger.info(f"[EnhancedSummarizeNode] å»é‡åchunksæ•°: {len(deduplicated_chunks)}")

        # Step 3: æŒ‰åˆ†æ•°æ’åºï¼Œä¿ç•™Top-100
        sorted_chunks = sorted(deduplicated_chunks, key=lambda x: x.get("score", 0), reverse=True)
        top_chunks = sorted_chunks[:100]

        logger.info(f"[EnhancedSummarizeNode] ä½¿ç”¨Top-{len(top_chunks)}ä¸ªchunks")

        # Step 4: æ ¼å¼åŒ–ä¸Šä¸‹æ–‡
        context = self._format_context(top_chunks)

        # Step 5: ã€æ–¹æ¡ˆAæ ¸å¿ƒã€‘æå–å…³é”®ç»†èŠ‚ï¼Œç”¨äºå¼ºåˆ¶å¼•ç”¨
        key_details = []
        detail_requirement = ""
        if self.enable_detail_citation:
            key_details = self._extract_key_details(top_chunks)
            if key_details:
                # æ„å»ºå¼ºåˆ¶å¼•ç”¨è¦æ±‚ï¼ˆå…¨å¾·è¯­ï¼Œæ›´å¼ºè°ƒï¼‰
                detail_list = "\n".join([f"  â€¢ {detail}" for detail in key_details[:10]])
                detail_requirement = f"""
[âš ï¸ KRITISCHE ANFORDERUNG - Pflicht zur ErwÃ¤hnung folgender Details]

Die folgenden spezifischen Begriffe/Konzepte wurden in den Materialien gefunden und MÃœSSEN in Ihrer Antwort erwÃ¤hnt werden:

{detail_list}

WICHTIG:
1. Diese Details sind konkrete Projektnamen, PolitikmaÃŸnahmen, LÃ¤ndernamen oder spezifische VorschlÃ¤ge
2. Auch wenn ein Detail nur von einer Partei/einem Redner erwÃ¤hnt wird, muss es in der Antwort enthalten sein
3. FÃ¼r VorschlÃ¤ge wie "visumspflichtig machen" oder "Ausreisegewahrsam verlÃ¤ngern" - geben Sie den GENAUEN Wortlaut an
4. Ãœberspringen Sie ein Detail NUR wenn es wirklich keine Verbindung zur Frage hat (erklÃ¤ren Sie dann warum)
"""
                logger.info(f"[EnhancedSummarizeNode] ğŸ”¥ å¯ç”¨ç»†èŠ‚å¼ºåˆ¶å¼•ç”¨ï¼Œå…±{len(key_details)}ä¸ªç»†èŠ‚")

        # Step 6: æ ¹æ®é—®é¢˜ç±»å‹é€‰æ‹©æ¨¡æ¿
        summary_template = self.prompts.select_summary_template(question_type)

        # Step 7: æ„å»ºç›´æ¥ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆçš„Promptï¼ˆåŒ…å«å¼ºåˆ¶å¼•ç”¨è¦æ±‚ï¼‰
        # ã€æ ¸å¿ƒä¿®å¤ã€‘é’ˆå¯¹"å˜åŒ–ç±»"é—®é¢˜ä½¿ç”¨ä¸“é—¨çš„å†æ—¶å˜åŒ–æ ¼å¼æ¨¡æ¿
        if question_type == "å˜åŒ–ç±»":
            logger.info("[EnhancedSummarizeNode] ğŸ• æ£€æµ‹åˆ°å˜åŒ–ç±»é—®é¢˜ï¼Œä½¿ç”¨å†æ—¶å˜åŒ–ä¸“ç”¨æ ¼å¼")
            production_prompt = f"""Sie sind Experte fÃ¼r die Analyse von Bundestagsreden.

Bitte beantworten Sie die folgende Frage basierend auf den bereitgestellten Materialien.

[Frage]
{question}
{detail_requirement}
[Materialien]
{context}

[âš ï¸ KRITISCHE ANFORDERUNG - Zeitliche Strukturierung]

Dies ist eine Frage zur ZEITLICHEN ENTWICKLUNG. Sie MÃœSSEN die Antwort CHRONOLOGISCH strukturieren!

[Pflicht-Ausgabeformat]

**1. Ãœberblick**

[2-3 SÃ¤tze zur Gesamtentwicklung Ã¼ber den gesamten Zeitraum]

**2. Zeitliche Entwicklung**

Erstellen Sie fÃ¼r JEDES Jahr einen eigenen Abschnitt. Lassen Sie KEIN Jahr aus!

â€¢ **2015**
  - Kernposition: [Zusammenfassung der Position in diesem Jahr]
  - Konkrete MaÃŸnahmen/Forderungen: [Spezifische PolitikvorschlÃ¤ge]
  - ReprÃ¤sentatives Zitat: â€[Originalzitat]" ([Redner], [Datum])

â€¢ **2016**
  - Kernposition: [Zusammenfassung der Position in diesem Jahr]
  - Konkrete MaÃŸnahmen/Forderungen: [Spezifische PolitikvorschlÃ¤ge]
  - ReprÃ¤sentatives Zitat: â€[Originalzitat]" ([Redner], [Datum])

â€¢ **2017**
  - Kernposition: [...]
  - Konkrete MaÃŸnahmen/Forderungen: [...]
  - ReprÃ¤sentatives Zitat: â€[...]"

[... Fahren Sie fort fÃ¼r ALLE Jahre, fÃ¼r die Materialien vorliegen ...]

**3. HauptverÃ¤nderungen**

Identifizieren Sie die wichtigsten Wendepunkte und PositionsÃ¤nderungen:

1. **Von [Jahr X] zu [Jahr Y]**:
   - Was Ã¤nderte sich: [Konkrete Beschreibung der Ã„nderung]
   - Beispiel: â€[Vorher-Position]" â†’ â€[Nachher-Position]"

2. **Von [Jahr Y] zu [Jahr Z]**:
   - Was Ã¤nderte sich: [...]

**4. Zusammenfassung**

[AbschlieÃŸende Bewertung: Wie hat sich die Position insgesamt entwickelt? Was waren die Haupttreiber der VerÃ¤nderung?]

**Quellen**

- Material 1: [Redner] ([Partei]), [YYYY-MM-DD]
- Material 2: [Redner] ([Partei]), [YYYY-MM-DD]
- ...

[WICHTIGE REGELN]
1. JEDES Jahr mit verfÃ¼gbaren Materialien MUSS einen eigenen Abschnitt haben
2. Die Jahre MÃœSSEN in chronologischer Reihenfolge erscheinen (2015 â†’ 2016 â†’ 2017 â†’ ...)
3. Verwenden Sie fÃ¼r jedes Jahr mindestens ein konkretes Zitat mit Quellenangabe
4. Wenn fÃ¼r ein Jahr keine Materialien vorliegen, geben Sie dies explizit an: â€FÃ¼r [Jahr] liegen keine Materialien vor"
5. Vermeiden Sie es, Informationen aus verschiedenen Jahren zu vermischen!
"""
        else:
            # å…¶ä»–é—®é¢˜ç±»å‹ä½¿ç”¨é€šç”¨prompt
            production_prompt = f"""
ä½ æ˜¯å¾·å›½è®®ä¼šè®®äº‹å½•ä¸“å®¶ã€‚è¯·æ ¹æ®ä»¥ä¸‹æ£€ç´¢åˆ°çš„è®®ä¼šå‘è¨€ææ–™ï¼Œç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

ã€ç”¨æˆ·é—®é¢˜ã€‘
{question}
{detail_requirement}
ã€æ£€ç´¢ææ–™ã€‘
{context}

ã€è¦æ±‚ã€‘
1. ç›´æ¥å›ç­”é—®é¢˜ï¼Œç»“æ„æ¸…æ™°
2. å¼•ç”¨å…·ä½“å‘è¨€äººå’Œæ—¥æœŸ
3. ä½¿ç”¨å¾·è¯­å›ç­”
4. å¦‚æœæ˜¯å¯¹æ¯”ç±»é—®é¢˜ï¼Œæ¸…æ™°å¯¹æ¯”å„æ–¹è§‚ç‚¹
5. å¦‚æœæ˜¯æ€»ç»“ç±»é—®é¢˜ï¼Œæç‚¼æ ¸å¿ƒè§‚ç‚¹
6. **å¿…é¡»å¼•ç”¨ä¸Šè¿°"é‡è¦ç»†èŠ‚"ä¸­åˆ—å‡ºçš„æ‰€æœ‰å…·ä½“é¡¹ç›®ã€æ”¿ç­–ã€åœ°å**

ã€è¾“å‡ºæ ¼å¼ã€‘ï¼ˆå¿…é¡»åŒ…å«ä»¥ä¸‹æ‰€æœ‰éƒ¨åˆ†ï¼‰
1. Zusammenfassungï¼ˆæ€»ç»“ï¼‰
2. Wichtige Aussagenï¼ˆé‡è¦è§‚ç‚¹ï¼Œå¼•ç”¨å‘è¨€äººå’Œæ—¥æœŸï¼‰
3. Belege aus den Materialienï¼ˆææ–™è¯æ®ï¼Œ**å¿…é¡»åŒ…å«ä¸Šè¿°é‡è¦ç»†èŠ‚**ï¼‰
4. Quellenï¼ˆæ¥æºåˆ—è¡¨ï¼Œæ ¼å¼ï¼šMaterial 1: [å‘è¨€äºº] ([å…šæ´¾]), [æ—¥æœŸ]ï¼‰

æ³¨æ„ï¼šå¿…é¡»åœ¨æœ«å°¾ç”Ÿæˆå®Œæ•´çš„Quellenåˆ—è¡¨ï¼ŒæŒ‰Material 1, Material 2...çš„æ ¼å¼åˆ—å‡ºæ‰€æœ‰å¼•ç”¨çš„ææ–™ã€‚
"""

        full_prompt = f"{self.prompts.SYSTEM_PROMPT_DE}\n\n{production_prompt}"

        # Step 8: è°ƒç”¨LLMç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
        logger.info("[EnhancedSummarizeNode] ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ...")
        final_answer = self.llm.invoke(full_prompt)

        # Step 8.5: ã€æ–°å¢ã€‘æ£€æŸ¥å…³é”®è¯æ˜¯å¦å®Œå…¨è¢«é—æ¼ï¼ˆç¬¬ä¸€é˜¶æ®µé‡è¯•ï¼‰
        if self.enable_detail_citation and key_details:
            critical_patterns = ["Visum", "visumspflichtig", "Kultur baut", "Wiederaufbau", "Ausreisegewahrsam"]
            critical_keywords_in_chunks = [d for d in key_details if any(kw in d for kw in critical_patterns)]

            # æ£€æŸ¥è¿™äº›å…³é”®è¯æ˜¯å¦åœ¨æ•´ä¸ªç­”æ¡ˆä¸­å®Œå…¨ç¼ºå¤±
            completely_missing = [kw for kw in critical_keywords_in_chunks if kw.lower() not in final_answer.lower()]

            if completely_missing:
                logger.warning(f"[EnhancedSummarizeNode] âŒ å…³é”®è¯å®Œå…¨ç¼ºå¤±ï¼ˆè¿Materialbewertungéƒ½æ²¡æœ‰ï¼‰: {completely_missing}")

                # ä»chunksä¸­æå–è¯æ®
                evidence_for_missing = []
                for kw in completely_missing:
                    for chunk in top_chunks:
                        text = chunk.get("text", "")
                        if kw.lower() in text.lower():
                            kw_pos = text.lower().find(kw.lower())
                            start = max(0, kw_pos - 100)
                            end = min(len(text), kw_pos + len(kw) + 100)
                            excerpt = text[start:end].strip()
                            speaker = chunk.get("metadata", {}).get("speaker", "Unknown")
                            date = chunk.get("metadata", {}).get("date", "")
                            evidence_for_missing.append(f'å…³é”®è¯ "{kw}" å‡ºç°åœ¨: "{excerpt}..." (å‘è¨€äºº: {speaker}, {date})')
                            break

                if evidence_for_missing:
                    logger.info(f"[EnhancedSummarizeNode] ğŸ” æ‰¾åˆ° {len(evidence_for_missing)} ä¸ªç¼ºå¤±å…³é”®è¯çš„åŸå§‹è¯æ®")
                    for ev in evidence_for_missing:
                        logger.debug(f"  - {ev}")

                    # ç¬¬ä¸€é˜¶æ®µé‡è¯•ï¼šå¼ºåˆ¶åŒ…å«å®Œå…¨ç¼ºå¤±çš„å…³é”®è¯
                    force_include_prompt = f"""
{full_prompt}

[âŒ SCHWERWIEGENDER FEHLER - KRITISCHE DETAILS FEHLEN VOLLSTÃ„NDIG]

Ihre Antwort hat folgende wichtige Details ÃœBERHAUPT NICHT erwÃ¤hnt, obwohl sie IN DEN MATERIALIEN VORKOMMEN:

{chr(10).join([f'  â€¢ {d}' for d in completely_missing])}

DIREKTER BEWEIS aus den Materialien:
{chr(10).join([f'  {ev}' for ev in evidence_for_missing])}

Diese Details sind ENTSCHEIDEND fÃ¼r die VollstÃ¤ndigkeit der Antwort. Bitte wiederholen Sie die VOLLSTÃ„NDIGE Antwort und stellen Sie sicher, dass ALLE oben genannten Details sowohl in der Materialbewertung als auch in der Zusammenfassung erscheinen.
"""
                    logger.info(f"[EnhancedSummarizeNode] ğŸ”„ ç¬¬ä¸€é˜¶æ®µé‡è¯•: å¼ºåˆ¶åŒ…å«å®Œå…¨ç¼ºå¤±çš„å…³é”®è¯...")
                    final_answer = self.llm.invoke(force_include_prompt)

        # Step 9: ã€æ–¹æ¡ˆAéªŒè¯+é‡è¯•ã€‘æ£€æŸ¥å…³é”®ç»†èŠ‚æ˜¯å¦åœ¨"æ€»ç»“éƒ¨åˆ†"è¢«å¼•ç”¨ï¼ˆä¸ä»…ä»…æ˜¯ææ–™è¯„ä¼°éƒ¨åˆ†ï¼‰
        if self.enable_detail_citation and key_details:
            # æå–æ€»ç»“éƒ¨åˆ†ï¼ˆZusammenfassungå’ŒHauptpositionenä¹‹åçš„å†…å®¹ï¼‰
            summary_section = self._extract_summary_section(final_answer)

            # ã€ä¿®å¤ã€‘æ£€æŸ¥æ‰€æœ‰å…³é”®æ”¿ç­–è¯ï¼Œè€Œéä»…å‰10ä¸ªï¼ˆçŸ­å…³é”®è¯å¯èƒ½æ’åœ¨åé¢ï¼‰
            critical_patterns = ["Visum", "visumspflichtig", "Kultur baut", "Wiederaufbau", "Ausreisegewahrsam", "Voraussetzung"]
            critical_keywords = [d for d in key_details if any(
                kw in d for kw in critical_patterns
            )]
            logger.info(f"[EnhancedSummarizeNode] æ£€æµ‹åˆ°{len(critical_keywords)}ä¸ªå…³é”®æ”¿ç­–è¯: {critical_keywords}")

            # ã€æ ¸å¿ƒä¿®å¤ã€‘æ£€æŸ¥æ˜¯å¦åœ¨æ€»ç»“éƒ¨åˆ†å‡ºç°ï¼Œè€Œéæ•´ä¸ªç­”æ¡ˆ
            missing_in_summary = [d for d in critical_keywords if d.lower() not in summary_section.lower()]

            # å¦‚æœåœ¨æ•´ä¸ªç­”æ¡ˆä¸­å­˜åœ¨ä½†ä¸åœ¨æ€»ç»“éƒ¨åˆ†ï¼Œè¿™æ˜¯"å‡é˜³æ€§"
            false_positives = [d for d in missing_in_summary if d.lower() in final_answer.lower()]
            if false_positives:
                logger.warning(f"[EnhancedSummarizeNode] âš ï¸ æ£€æµ‹åˆ°å‡é˜³æ€§: {false_positives} ä»…åœ¨ææ–™è¯„ä¼°éƒ¨åˆ†å‡ºç°ï¼Œæœªåœ¨æ€»ç»“ä¸­ä½“ç°")

            if missing_in_summary:
                logger.warning(f"[EnhancedSummarizeNode] âš ï¸ å…³é”®æ”¿ç­–ç»†èŠ‚åœ¨æ€»ç»“éƒ¨åˆ†ç¼ºå¤±: {missing_in_summary}")

                # ã€å¢å¼ºã€‘ä»chunksä¸­æå–åŒ…å«ç¼ºå¤±å…³é”®è¯çš„åŸå§‹è¯æ®
                evidence_lines = []
                for kw in missing_in_summary:
                    for chunk in top_chunks:
                        text = chunk.get("text", "")
                        if kw.lower() in text.lower():
                            # æå–å…³é”®è¯å‘¨å›´çš„ä¸Šä¸‹æ–‡ï¼ˆ150å­—ç¬¦ï¼‰
                            kw_pos = text.lower().find(kw.lower())
                            start = max(0, kw_pos - 80)
                            end = min(len(text), kw_pos + len(kw) + 80)
                            excerpt = text[start:end].strip()
                            speaker = chunk.get("metadata", {}).get("speaker", "Unknown")
                            date = chunk.get("metadata", {}).get("date", "")
                            evidence_lines.append(f'  BEWEIS fÃ¼r "{kw}": "{excerpt}..." (Redner: {speaker}, {date})')
                            break  # æ¯ä¸ªå…³é”®è¯åªå–ä¸€ä¸ªè¯æ®

                evidence_section = ""
                if evidence_lines:
                    evidence_section = f"""

DIREKTER BEWEIS aus den Materialien:
{chr(10).join(evidence_lines)}

Die obigen Zitate zeigen, dass diese Details IN DEN MATERIALIEN VORKOMMEN. Sie MÃœSSEN sie in der Zusammenfassung erwÃ¤hnen!
"""

                # è§¦å‘æ›´ç²¾ç¡®çš„é‡è¯•ï¼ŒåŒ…å«åŸå§‹è¯æ®
                retry_prompt = f"""
{full_prompt}

[âš ï¸ KRITISCHER HINWEIS - Details fehlen in der Zusammenfassung]

Ihre vorherige Antwort hat folgende wichtige Details nicht ausreichend behandelt:

{chr(10).join([f'  â€¢ {d}' for d in missing_in_summary])}
{evidence_section}
WICHTIG: Diese spezifischen Begriffe MÃœSSEN im Abschnitt "Zusammenfassung" und/oder "Hauptpositionen" erscheinen, nicht nur in der Materialbewertung!

Beispiel: Wenn ein Material "Georgien visumspflichtig zu machen" fordert, muss in der Zusammenfassung explizit "Visumspflicht fÃ¼r Georgien" oder "Georgien visumspflichtig" stehen - NICHT nur "Druck ausÃ¼ben".

Bitte wiederholen Sie die vollstÃ¤ndige Antwort und stellen Sie sicher, dass diese konkreten PolitikmaÃŸnahmen im Haupttext (Zusammenfassung/Hauptpositionen) genannt werden.
"""
                logger.info(f"[EnhancedSummarizeNode] ğŸ”„ è§¦å‘ç²¾ç¡®é‡è¯•ï¼Œè¦æ±‚åœ¨æ€»ç»“éƒ¨åˆ†è¡¥å……ç¼ºå¤±ç»†èŠ‚...")
                final_answer = self.llm.invoke(retry_prompt)

                # å†æ¬¡æ£€æŸ¥æ€»ç»“éƒ¨åˆ†
                summary_section_retry = self._extract_summary_section(final_answer)
                still_missing = [d for d in missing_in_summary if d.lower() not in summary_section_retry.lower()]
                if still_missing:
                    logger.warning(f"[EnhancedSummarizeNode] âš ï¸ é‡è¯•åæ€»ç»“éƒ¨åˆ†ä»ç¼ºå¤±: {still_missing}")
                else:
                    logger.info(f"[EnhancedSummarizeNode] âœ… é‡è¯•æˆåŠŸï¼Œæ‰€æœ‰å…³é”®ç»†èŠ‚å·²åœ¨æ€»ç»“éƒ¨åˆ†å¼•ç”¨")
            else:
                logger.info(f"[EnhancedSummarizeNode] âœ… æ‰€æœ‰å…³é”®ç»†èŠ‚å·²åœ¨æ€»ç»“éƒ¨åˆ†è¢«å¼•ç”¨")

        logger.info(f"[EnhancedSummarizeNode] âœ… æœ€ç»ˆç­”æ¡ˆé•¿åº¦: {len(final_answer)}")

        # è¿”å›Noneä½œä¸ºsub_answersï¼ˆç”Ÿäº§æ¨¡å¼ä¸ç”Ÿæˆå­ç­”æ¡ˆï¼‰
        return final_answer, None
    
    # ä¸»æŒäººèŒä½åˆ—è¡¨ï¼ˆç”¨äºè¿‡æ»¤ï¼‰
    MODERATOR_TITLES = [
        "VizeprÃ¤sident",
        "VizeprÃ¤sidentin",
        "PrÃ¤sident",
        "PrÃ¤sidentin",
        "AltersprÃ¤sident",
        "AltersprÃ¤sidentin"
    ]

    def _is_moderator(self, speaker: str) -> bool:
        """
        æ£€æŸ¥speakeræ˜¯å¦æ˜¯ä¸»æŒäºº

        Args:
            speaker: å‘è¨€äººåç§°

        Returns:
            Trueå¦‚æœæ˜¯ä¸»æŒäººï¼ŒFalseå¦åˆ™
        """
        if not speaker:
            return True
        for title in self.MODERATOR_TITLES:
            if speaker.startswith(title):
                return True
        return False

    def _format_context(self, chunks: List[Dict]) -> str:
        """
        æ ¼å¼åŒ–æ£€ç´¢åˆ°çš„chunksä¸ºä¸Šä¸‹æ–‡

        æ³¨æ„ï¼šä¼šè¿‡æ»¤æ‰ä¸»æŒäººçš„å‘è¨€ï¼Œå› ä¸ºä»–ä»¬åªæ˜¯ä¸»æŒä¼šè®®ï¼Œ
        ä¸ä»£è¡¨ä»»ä½•æ”¿å…šç«‹åœº

        Args:
            chunks: æ£€ç´¢ç»“æœchunks

        Returns:
            æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        """
        context_parts = []
        material_index = 0

        for chunk in chunks:
            metadata = chunk.get("metadata", {})
            text = chunk.get("text", "")
            score = chunk.get("score", 0.0)

            # æå–å…ƒæ•°æ®
            speaker = metadata.get("speaker", "Unbekannt")

            # ã€å…³é”®ä¿®å¤ã€‘è¿‡æ»¤ä¸»æŒäººå‘è¨€
            if self._is_moderator(speaker):
                logger.debug(f"[EnhancedSummarizeNode] è¿‡æ»¤ä¸»æŒäººå‘è¨€: {speaker}")
                continue

            material_index += 1
            group = metadata.get("group", "Unbekannt")
            year = metadata.get("year", "")
            month = metadata.get("month", "")
            day = metadata.get("day", "")
            text_id = metadata.get("text_id", "")

            # æ ¼å¼åŒ–æ—¥æœŸ
            date = f"{year}-{month}-{day}" if year else "Unbekannt"

            # æ ¼å¼åŒ–å•ä¸ªchunk
            context_part = f"""
[Material {material_index}] (Relevanz: {score:.2f})
Redner: {speaker} ({group})
Datum: {date}
Quelle: {text_id}
Inhalt: {text}
"""
            context_parts.append(context_part)

        logger.info(f"[EnhancedSummarizeNode] æ ¼å¼åŒ–{material_index}ä¸ªæœ‰æ•ˆææ–™ï¼ˆè¿‡æ»¤ä¸»æŒäººåï¼‰")
        return "\n".join(context_parts)
    
    def _extract_sources(self, chunks: List[Dict]) -> List[Dict]:
        """
        ä»chunksä¸­æå–æ¥æºä¿¡æ¯

        æ³¨æ„ï¼šä¼šè¿‡æ»¤æ‰ä¸»æŒäººçš„å‘è¨€

        Args:
            chunks: æ£€ç´¢ç»“æœchunks

        Returns:
            æ¥æºä¿¡æ¯åˆ—è¡¨
        """
        sources = []

        for chunk in chunks:
            # åªä¿ç•™å‰5ä¸ªæœ‰æ•ˆæ¥æº
            if len(sources) >= 5:
                break

            metadata = chunk.get("metadata", {})
            speaker = metadata.get("speaker", "Unbekannt")

            # è¿‡æ»¤ä¸»æŒäºº
            if self._is_moderator(speaker):
                continue

            source = {
                "speaker": speaker,
                "group": metadata.get("group", "Unbekannt"),
                "date": f"{metadata.get('year', '')}-{metadata.get('month', '')}-{metadata.get('day', '')}",
                "text_id": metadata.get("text_id", ""),
                "score": chunk.get("score", 0.0)
            }

            sources.append(source)

        return sources

    def _extract_key_details(self, chunks: List[Dict]) -> List[str]:
        """
        ã€æ–¹æ¡ˆAæ ¸å¿ƒã€‘ä»æ£€ç´¢ç»“æœä¸­æå–æ½œåœ¨çš„å…³é”®ç»†èŠ‚

        æå–å†…å®¹ï¼š
        1. å¸¦å¼•å·çš„é¡¹ç›®å/æ”¿ç­–åï¼ˆå¦‚"Kultur baut BrÃ¼cken"ï¼‰
        2. é¢„å®šä¹‰çš„é‡è¦åœ°åï¼ˆå¦‚Syrien, Georgienï¼‰
        3. é¢„å®šä¹‰çš„é‡è¦æ”¿ç­–å…³é”®è¯

        Args:
            chunks: æ£€ç´¢ç»“æœchunks

        Returns:
            å…³é”®ç»†èŠ‚åˆ—è¡¨ï¼ˆæœ€å¤š15ä¸ªï¼‰
        """
        details = set()

        # æ­£åˆ™ï¼šæå–å¸¦å¼•å·çš„å†…å®¹ï¼ˆå¾·è¯­ç”¨â€"æˆ–""æˆ–ã€Œã€ï¼‰
        quote_patterns = [
            r'â€([^"]+)"',      # å¾·è¯­å¼•å· â€..."
            r'"([^"]+)"',      # æ™®é€šåŒå¼•å·
            r'\"([^\"]+)\"',   # è½¬ä¹‰åŒå¼•å·
        ]

        for chunk in chunks:
            text = chunk.get("text", "")

            # 1. æå–å¼•å·å†…çš„å†…å®¹
            for pattern in quote_patterns:
                matches = re.findall(pattern, text)
                for match in matches:
                    # è¿‡æ»¤ï¼šé•¿åº¦5-80å­—ç¬¦ï¼Œä¸”ä¸æ˜¯çº¯æ•°å­—
                    if 5 <= len(match) <= 80 and not match.isdigit():
                        details.add(match.strip())

            # 2. æ£€æŸ¥é¢„å®šä¹‰çš„é‡è¦åœ°å
            for loc in self.IMPORTANT_LOCATIONS:
                if loc in text:
                    details.add(loc)

            # 3. æ£€æŸ¥é¢„å®šä¹‰çš„é‡è¦æ”¿ç­–å…³é”®è¯
            for kw in self.IMPORTANT_POLICY_KEYWORDS:
                if kw in text:
                    details.add(kw)

        # æŒ‰é•¿åº¦æ’åºï¼Œä¼˜å…ˆä¿ç•™æ›´å…·ä½“çš„ç»†èŠ‚ï¼ˆé€šå¸¸æ›´é•¿ï¼‰
        sorted_details = sorted(details, key=len, reverse=True)

        logger.info(f"[EnhancedSummarizeNode] æå–åˆ°{len(sorted_details)}ä¸ªå…³é”®ç»†èŠ‚")
        if sorted_details:
            logger.debug(f"[EnhancedSummarizeNode] å…³é”®ç»†èŠ‚é¢„è§ˆ: {sorted_details[:5]}")

        return sorted_details[:15]  # æœ€å¤šè¿”å›15ä¸ª

    def _extract_summary_section(self, answer: str) -> str:
        """
        ä»ç­”æ¡ˆä¸­æå–"æ€»ç»“éƒ¨åˆ†"ï¼ˆZusammenfassung + Hauptpositionenï¼‰
        æ’é™¤"Materialbewertung"éƒ¨åˆ†

        ç”¨äºç²¾ç¡®éªŒè¯å…³é”®ç»†èŠ‚æ˜¯å¦åœ¨æœ€ç»ˆæ€»ç»“ä¸­å‡ºç°ï¼Œè€Œéä»…åœ¨ææ–™è¯„ä¼°ä¸­

        Args:
            answer: å®Œæ•´ç­”æ¡ˆ

        Returns:
            æ€»ç»“éƒ¨åˆ†çš„æ–‡æœ¬ï¼ˆä¸åŒ…å«ææ–™è¯„ä¼°ï¼‰
        """
        # å°è¯•å®šä½æ€»ç»“éƒ¨åˆ†çš„å¼€å§‹
        summary_markers = [
            "**Zusammenfassung**",
            "## Zusammenfassung",
            "### Zusammenfassung",
            "Zusammenfassung\n",
            "---\n\n**Zusammenfassung",
        ]

        # å°è¯•å®šä½ææ–™è¯„ä¼°éƒ¨åˆ†çš„ç»“æŸï¼ˆé€šå¸¸åœ¨ "---" åˆ†éš”ç¬¦åï¼‰
        material_end_markers = [
            "---\n\n**Zusammenfassung",
            "---\n\nZusammenfassung",
            "---\n\n###",
            "\n\n**Zusammenfassung",
            "\n\nZusammenfassung\n",
        ]

        summary_start = -1

        # æ–¹æ³•1ï¼šæ‰¾åˆ° "---" åçš„ Zusammenfassung
        for marker in material_end_markers:
            pos = answer.find(marker)
            if pos != -1:
                summary_start = pos
                break

        # æ–¹æ³•2ï¼šå¦‚æœæ²¡æ‰¾åˆ°ï¼Œç›´æ¥æ‰¾ Zusammenfassung
        if summary_start == -1:
            for marker in summary_markers:
                pos = answer.find(marker)
                if pos != -1:
                    summary_start = pos
                    break

        # æ–¹æ³•3ï¼šå¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ Hauptpositionen
        if summary_start == -1:
            hauptpos_markers = ["**Hauptpositionen", "## Hauptpositionen", "Hauptpositionen und VorschlÃ¤ge"]
            for marker in hauptpos_markers:
                pos = answer.find(marker)
                if pos != -1:
                    summary_start = pos
                    break

        if summary_start == -1:
            # å¦‚æœå®Œå…¨æ‰¾ä¸åˆ°ï¼Œè¿”å›æ•´ä¸ªç­”æ¡ˆï¼ˆé™çº§å¤„ç†ï¼‰
            logger.warning("[EnhancedSummarizeNode] æ— æ³•å®šä½æ€»ç»“éƒ¨åˆ†ï¼Œä½¿ç”¨æ•´ä¸ªç­”æ¡ˆè¿›è¡ŒéªŒè¯")
            return answer

        # æå–æ€»ç»“éƒ¨åˆ†ï¼ˆä»æ‰¾åˆ°çš„ä½ç½®åˆ°ç­”æ¡ˆæœ«å°¾ï¼‰
        summary_section = answer[summary_start:]

        logger.debug(f"[EnhancedSummarizeNode] æå–æ€»ç»“éƒ¨åˆ†: ä»ä½ç½®{summary_start}å¼€å§‹ï¼Œé•¿åº¦{len(summary_section)}å­—ç¬¦")

        return summary_section

    def _verify_material_coverage(self, answer: str, total_materials: int) -> Tuple[bool, List[int]]:
        """
        éªŒè¯ç­”æ¡ˆæ˜¯å¦è¦†ç›–äº†æ‰€æœ‰ææ–™ï¼ˆç»“æ„åŒ–éªŒè¯ï¼‰

        æ£€æµ‹æ–¹å¼ï¼š
        1. æ£€æŸ¥"Materialbewertung"éƒ¨åˆ†æ˜¯å¦å­˜åœ¨
        2. æå–æ‰€æœ‰Material Nçš„å¼•ç”¨
        3. å¯¹æ¯”æ˜¯å¦è¦†ç›–1~total_materials

        Args:
            answer: LLMç”Ÿæˆçš„ç­”æ¡ˆ
            total_materials: æ€»ææ–™æ•°

        Returns:
            (æ˜¯å¦å®Œæ•´è¦†ç›–, ç¼ºå¤±çš„Materialç¼–å·åˆ—è¡¨)
        """
        # æå–ç­”æ¡ˆä¸­å¼•ç”¨çš„Materialç¼–å·
        referenced_materials = set()

        # åŒ¹é… "Material N:" æˆ– "Material N" æ ¼å¼
        pattern = r'Material\s+(\d+)'
        matches = re.findall(pattern, answer)

        for match in matches:
            material_num = int(match)
            if 1 <= material_num <= total_materials:
                referenced_materials.add(material_num)

        # è®¡ç®—ç¼ºå¤±çš„ææ–™
        expected_materials = set(range(1, total_materials + 1))
        missing_materials = expected_materials - referenced_materials

        if missing_materials:
            logger.warning(
                f"âš ï¸ ææ–™è¦†ç›–ä¸å®Œæ•´ï¼"
                f"æ€»è®¡: {total_materials}, "
                f"å·²å¼•ç”¨: {len(referenced_materials)}, "
                f"ç¼ºå¤±: {sorted(missing_materials)}"
            )
            return False, sorted(missing_materials)

        logger.info(f"âœ… æ‰€æœ‰{total_materials}ä¸ªææ–™å‡å·²è¦†ç›–")
        return True, []


# ä¸ºäº†ä¿æŒå‘åå…¼å®¹ï¼Œåˆ›å»ºä¸€ä¸ªåˆ«å
SummarizeNode = EnhancedSummarizeNode


if __name__ == "__main__":
    # æµ‹è¯•å¢å¼ºç‰ˆæ€»ç»“èŠ‚ç‚¹
    from ..state import create_initial_state, update_state
    
    print("="*60)
    print("å¢å¼ºç‰ˆSummarizeNodeæµ‹è¯•")
    print("="*60)
    
    # æµ‹è¯•1: å•é—®é¢˜æ€»ç»“
    print("\nã€æµ‹è¯•1: å•é—®é¢˜æ€»ç»“ã€‘")
    question1 = "2019å¹´å¾·å›½è®®ä¼šè®¨è®ºäº†å“ªäº›ä¸»è¦è®®é¢˜ï¼Ÿ"
    
    # æ¨¡æ‹Ÿæ£€ç´¢ç»“æœ
    mock_result1 = {
        "question": question1,
        "chunks": [
            {
                "text": "Heute diskutieren wir Ã¼ber Klimaschutz, Digitalisierung und soziale Gerechtigkeit...",
                "metadata": {
                    "speaker": "Angela Merkel",
                    "group": "CDU/CSU",
                    "year": "2019",
                    "month": "03",
                    "day": "15",
                    "text_id": "pp_19_100_00001"
                },
                "score": 0.95
            },
            {
                "text": "Die digitale Transformation ist eine der grÃ¶ÃŸten Herausforderungen...",
                "metadata": {
                    "speaker": "Olaf Scholz",
                    "group": "SPD",
                    "year": "2019",
                    "month": "05",
                    "day": "20",
                    "text_id": "pp_19_110_00002"
                },
                "score": 0.88
            }
        ]
    }
    
    state1 = create_initial_state(question1)
    state1 = update_state(
        state1,
        retrieval_results=[mock_result1],
        is_decomposed=False
    )
    
    print(f"é—®é¢˜: {question1}")
    print(f"ææ–™æ•°: {len(mock_result1['chunks'])}")
    print("âœ… æ¨¡æ‹Ÿæ•°æ®å‡†å¤‡å®Œæˆï¼ˆå®é™…éœ€è¦LLMï¼‰")
    
    # æµ‹è¯•2: å¤šé—®é¢˜æ€»ç»“
    print("\nã€æµ‹è¯•2: å¤šé—®é¢˜æ€»ç»“ - å˜åŒ–ç±»ã€‘")
    question2 = "2015-2018å¹´ä¸åŒå…šæ´¾åœ¨éš¾æ°‘æ”¿ç­–ä¸Šçš„ç«‹åœºå˜åŒ–ï¼Ÿ"
    
    # æ¨¡æ‹Ÿå¤šä¸ªå­é—®é¢˜çš„æ£€ç´¢ç»“æœ
    mock_results2 = [
        {
            "question": "2015å¹´CDU/CSUåœ¨éš¾æ°‘æ”¿ç­–ä¸Šçš„ç«‹åœºï¼Ÿ",
            "chunks": [
                {
                    "text": "Wir schaffen das! Deutschland muss humanitÃ¤r handeln...",
                    "metadata": {
                        "speaker": "Angela Merkel",
                        "group": "CDU/CSU",
                        "year": "2015",
                        "month": "09",
                        "day": "01",
                        "text_id": "pp_18_120_00001"
                    },
                    "score": 0.92
                }
            ]
        },
        {
            "question": "2018å¹´CDU/CSUåœ¨éš¾æ°‘æ”¿ç­–ä¸Šçš„ç«‹åœºï¼Ÿ",
            "chunks": [
                {
                    "text": "Wir mÃ¼ssen die Zuwanderung besser steuern und kontrollieren...",
                    "metadata": {
                        "speaker": "Horst Seehofer",
                        "group": "CDU/CSU",
                        "year": "2018",
                        "month": "06",
                        "day": "15",
                        "text_id": "pp_19_045_00001"
                    },
                    "score": 0.89
                }
            ]
        }
    ]
    
    state2 = create_initial_state(question2)
    state2 = update_state(
        state2,
        question_type="å˜åŒ–ç±»",
        retrieval_results=mock_results2,
        sub_questions=["2015å¹´CDU/CSU...", "2018å¹´CDU/CSU..."],
        is_decomposed=True
    )
    
    print(f"é—®é¢˜: {question2}")
    print(f"é—®é¢˜ç±»å‹: å˜åŒ–ç±»")
    print(f"å­é—®é¢˜æ•°: {len(mock_results2)}")
    print("âœ… æ¨¡æ‹Ÿæ•°æ®å‡†å¤‡å®Œæˆï¼ˆå®é™…éœ€è¦LLMï¼‰")
    
    print("\n" + "="*60)
    print("æ³¨æ„: å®Œæ•´æµ‹è¯•éœ€è¦å¯åŠ¨LLMæœåŠ¡ï¼ˆGemini APIï¼‰")
    print("="*60)
    
    print("\nã€æ ¸å¿ƒåŠŸèƒ½ã€‘")
    print("âœ… å•é—®é¢˜æ¨¡å—åŒ–æ€»ç»“")
    print("âœ… å¤šé—®é¢˜åˆ†å±‚æ€»ç»“")
    print("âœ… æ ¹æ®é—®é¢˜ç±»å‹é€‰æ‹©Prompt")
    print("âœ… å¾·æ–‡ç»“æ„åŒ–è¾“å‡º")
    print("âœ… æ¥æºä¿¡æ¯æå–")

