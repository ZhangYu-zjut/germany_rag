"""
Pineconeæ£€ç´¢å™¨
ä¸ºLangGraphå·¥ä½œæµæä¾›Pineconeå‘é‡æ£€ç´¢èƒ½åŠ›
"""

import os
from typing import List, Dict, Optional, Any
from pinecone import Pinecone
from ..utils.logger import logger


class PineconeRetriever:
    """
    Pineconeæ£€ç´¢å™¨

    åŠŸèƒ½:
    1. å‘é‡ç›¸ä¼¼åº¦æ£€ç´¢
    2. å…ƒæ•°æ®è¿‡æ»¤(å¹´ä»½ã€å…šæ´¾ã€å‘è¨€äººç­‰)
    3. æ”¯æŒå¤šå¹´ä»½èŒƒå›´æŸ¥è¯¢
    4. è¿”å›ç»Ÿä¸€æ ¼å¼çš„æ£€ç´¢ç»“æœ
    """

    def __init__(
        self,
        index_name: str = "german-bge",
        namespace: str = "",
        default_limit: int = 50  # é»˜è®¤50ä¸ªç»“æœ,æ”¯æŒé•¿æ—¶é—´è·¨åº¦æŸ¥è¯¢
    ):
        """
        åˆå§‹åŒ–Pineconeæ£€ç´¢å™¨

        Args:
            index_name: ç´¢å¼•åç§°
            namespace: å‘½åç©ºé—´
            default_limit: é»˜è®¤è¿”å›ç»“æœæ•°
        """
        self.index_name = index_name
        self.namespace = namespace
        self.default_limit = default_limit

        # åˆå§‹åŒ–Pineconeå®¢æˆ·ç«¯
        api_key = os.getenv('PINECONE_VECTOR_DATABASE_API_KEY')
        if not api_key:
            raise ValueError("PINECONE_VECTOR_DATABASE_API_KEYæœªè®¾ç½®")

        self.pc = Pinecone(api_key=api_key)
        self.index = self.pc.Index(index_name)

        logger.info(f"[PineconeRetriever] åˆå§‹åŒ–å®Œæˆ: index={index_name}, default_limit={default_limit}")

    def search(
        self,
        query_vector: List[float],
        limit: Optional[int] = None,
        filters: Optional[Dict] = None,
        include_metadata: bool = True
    ) -> List[Dict[str, Any]]:
        """
        æ‰§è¡Œå‘é‡æœç´¢

        Args:
            query_vector: æŸ¥è¯¢å‘é‡
            limit: è¿”å›ç»“æœæ•°é‡
            filters: å…ƒæ•°æ®è¿‡æ»¤æ¡ä»¶
            include_metadata: æ˜¯å¦åŒ…å«å…ƒæ•°æ®

        Returns:
            æ£€ç´¢ç»“æœåˆ—è¡¨ï¼Œç»Ÿä¸€æ ¼å¼:
            [
                {
                    "id": "...",
                    "score": 0.95,
                    "text": "...",
                    "metadata": {...}
                }
            ]
        """
        limit = limit or self.default_limit

        # æ„å»ºæŸ¥è¯¢å‚æ•°
        query_args = {
            'vector': query_vector,
            'top_k': limit,
            'include_metadata': include_metadata
        }

        # æ·»åŠ è¿‡æ»¤å™¨
        if filters:
            pinecone_filter = self._convert_to_pinecone_filter(filters)
            if pinecone_filter:
                query_args['filter'] = pinecone_filter
                logger.debug(f"[PineconeRetriever] ä½¿ç”¨è¿‡æ»¤å™¨: {pinecone_filter}")

        # æ‰§è¡ŒæŸ¥è¯¢
        try:
            results = self.index.query(**query_args)
            logger.info(f"[PineconeRetriever] æ£€ç´¢æˆåŠŸï¼Œè¿”å›{len(results.matches)}ä¸ªç»“æœ")

            # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
            formatted_results = []
            for match in results.matches:
                formatted_results.append({
                    "id": match.id,
                    "score": match.score,
                    "text": match.metadata.get('text', '') if match.metadata else '',
                    "metadata": match.metadata or {}
                })

            return formatted_results

        except Exception as e:
            logger.error(f"[PineconeRetriever] æ£€ç´¢å¤±è´¥: {str(e)}")
            raise

    def search_multi_year(
        self,
        query_vector: List[float],
        years: List[str],
        limit_per_year: int = 5,
        other_filters: Optional[Dict] = None
    ) -> List[Dict[str, Any]]:
        """
        å¤šå¹´ä»½åˆ†å±‚æ£€ç´¢ï¼ˆç­–ç•¥ï¼šæ¯å¹´ç‹¬ç«‹æ£€ç´¢ï¼Œç„¶ååˆå¹¶ï¼‰

        é€‚ç”¨åœºæ™¯: "2015å¹´ä»¥æ¥"ã€"2015-2024"ç­‰é•¿æ—¶é—´è·¨åº¦æŸ¥è¯¢
        ä¿è¯æ¯å¹´éƒ½æœ‰ä»£è¡¨æ€§æ–‡æ¡£

        Args:
            query_vector: æŸ¥è¯¢å‘é‡
            years: å¹´ä»½åˆ—è¡¨ (e.g., ['2015', '2016', ..., '2024'])
            limit_per_year: æ¯å¹´è¿”å›çš„æ–‡æ¡£æ•°
            other_filters: å…¶ä»–è¿‡æ»¤æ¡ä»¶(å…šæ´¾ã€å‘è¨€äººç­‰)

        Returns:
            åˆå¹¶åçš„æ£€ç´¢ç»“æœï¼ŒæŒ‰ç›¸ä¼¼åº¦æ’åº
        """
        logger.info(f"[PineconeRetriever] å¤šå¹´ä»½æ£€ç´¢: {len(years)}å¹´, æ¯å¹´{limit_per_year}ä¸ªæ–‡æ¡£")

        all_results = []
        year_distribution = {}

        # é¢„å…ˆè½¬æ¢other_filtersä¸ºPineconeæ ¼å¼ï¼ˆé¿å…åŒé‡è½¬æ¢ï¼‰
        converted_other_filters = None
        if other_filters:
            converted_other_filters = self._convert_to_pinecone_filter(other_filters)
            logger.debug(f"[PineconeRetriever] å…¶ä»–è¿‡æ»¤æ¡ä»¶è½¬æ¢: {other_filters} -> {converted_other_filters}")

        for year in years:
            # æ„å»ºå½“å‰å¹´ä»½çš„è¿‡æ»¤å™¨(å·²ç»æ˜¯Pineconeæ ¼å¼)
            year_filter = {'year': {'$eq': str(year)}}

            # åˆå¹¶å…¶ä»–è¿‡æ»¤æ¡ä»¶(éƒ½æ˜¯Pineconeæ ¼å¼ï¼Œç›´æ¥åˆå¹¶)
            if converted_other_filters:
                # ä½¿ç”¨$andåˆå¹¶(éƒ½å·²ç»æ˜¯Pineconeæ ¼å¼)
                combined_filter = {'$and': [year_filter, converted_other_filters]}
            else:
                combined_filter = year_filter

            # æ£€ç´¢ï¼ˆæ³¨æ„ï¼šç›´æ¥ä¼ é€’Pineconeæ ¼å¼filteråˆ°index.queryï¼Œç»•è¿‡_convert_to_pinecone_filterï¼‰
            try:
                # ç›´æ¥è°ƒç”¨Pinecone index.queryï¼Œä¸ç»è¿‡search()æ–¹æ³•ï¼ˆé¿å…äºŒæ¬¡è½¬æ¢ï¼‰
                query_args = {
                    'vector': query_vector,
                    'top_k': limit_per_year,
                    'filter': combined_filter,
                    'include_metadata': True
                }

                results = self.index.query(**query_args)

                # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
                year_results = []
                for match in results.matches:
                    year_results.append({
                        "id": match.id,
                        "score": match.score,
                        "text": match.metadata.get('text', '') if match.metadata else '',
                        "metadata": match.metadata or {}
                    })

                year_distribution[year] = len(year_results)
                all_results.extend(year_results)

                logger.debug(f"[PineconeRetriever] {year}å¹´: {len(year_results)}ä¸ªæ–‡æ¡£")

            except Exception as e:
                logger.warning(f"[PineconeRetriever] {year}å¹´æ£€ç´¢å¤±è´¥: {str(e)}")
                year_distribution[year] = 0

        # æŒ‰ç›¸ä¼¼åº¦é‡æ–°æ’åº
        all_results.sort(key=lambda x: x['score'], reverse=True)

        logger.info(
            f"[PineconeRetriever] å¤šå¹´ä»½æ£€ç´¢å®Œæˆ: å…±{len(all_results)}ä¸ªæ–‡æ¡£, "
            f"å¹´ä»½åˆ†å¸ƒ={year_distribution}"
        )

        return all_results

    def search_multi_year_parallel(
        self,
        query_vector: List[float],
        years: List[str],
        limit_per_year: int = 5,
        other_filters: Optional[Dict] = None
    ) -> List[Dict[str, Any]]:
        """
        å¤šå¹´ä»½åˆ†å±‚æ£€ç´¢ï¼ˆå¹¶è¡Œä¼˜åŒ–ç‰ˆï¼‰

        ç›¸æ¯”ä¸²è¡Œç‰ˆæœ¬,ä½¿ç”¨ThreadPoolExecutorå¹¶è¡ŒæŸ¥è¯¢æ‰€æœ‰å¹´ä»½,å¤§å¹…æå‡æ€§èƒ½

        æ€§èƒ½å¯¹æ¯”:
        - ä¸²è¡Œç‰ˆæœ¬: 10å¹´ Ã— 8ç§’ = 80ç§’
        - å¹¶è¡Œç‰ˆæœ¬: max(8ç§’) = 8-10ç§’ (æå‡8-10å€)

        Args:
            query_vector: æŸ¥è¯¢å‘é‡
            years: å¹´ä»½åˆ—è¡¨ (e.g., ['2015', '2016', ..., '2024'])
            limit_per_year: æ¯å¹´è¿”å›çš„æ–‡æ¡£æ•°
            other_filters: å…¶ä»–è¿‡æ»¤æ¡ä»¶(å…šæ´¾ã€å‘è¨€äººç­‰)

        Returns:
            åˆå¹¶åçš„æ£€ç´¢ç»“æœï¼ŒæŒ‰ç›¸ä¼¼åº¦æ’åº
        """
        import concurrent.futures

        logger.info(f"[PineconeRetriever] ğŸš€ å¹¶è¡Œå¤šå¹´ä»½æ£€ç´¢: {len(years)}å¹´, æ¯å¹´{limit_per_year}ä¸ªæ–‡æ¡£")

        # é¢„å…ˆè½¬æ¢other_filtersä¸ºPineconeæ ¼å¼
        converted_other_filters = None
        if other_filters:
            converted_other_filters = self._convert_to_pinecone_filter(other_filters)
            logger.debug(f"[PineconeRetriever] å…¶ä»–è¿‡æ»¤æ¡ä»¶è½¬æ¢: {other_filters} -> {converted_other_filters}")

        def query_single_year(year: str) -> tuple:
            """
            æŸ¥è¯¢å•ä¸ªå¹´ä»½(çº¿ç¨‹å®‰å…¨)

            Returns:
                (year, results_list)
            """
            # æ„å»ºå¹´ä»½è¿‡æ»¤å™¨
            year_filter = {'year': {'$eq': str(year)}}

            # åˆå¹¶å…¶ä»–è¿‡æ»¤æ¡ä»¶
            if converted_other_filters:
                combined_filter = {'$and': [year_filter, converted_other_filters]}
            else:
                combined_filter = year_filter

            try:
                # PineconeæŸ¥è¯¢
                query_args = {
                    'vector': query_vector,
                    'top_k': limit_per_year,
                    'filter': combined_filter,
                    'include_metadata': True
                }

                results = self.index.query(**query_args)

                # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
                year_results = []
                for match in results.matches:
                    year_results.append({
                        "id": match.id,
                        "score": match.score,
                        "text": match.metadata.get('text', '') if match.metadata else '',
                        "metadata": match.metadata or {}
                    })

                logger.debug(f"[PineconeRetriever] âœ“ {year}å¹´: {len(year_results)}ä¸ªæ–‡æ¡£")
                return (year, year_results)

            except Exception as e:
                logger.warning(f"[PineconeRetriever] âœ— {year}å¹´æ£€ç´¢å¤±è´¥: {str(e)}")
                return (year, [])

        # å¹¶è¡ŒæŸ¥è¯¢æ‰€æœ‰å¹´ä»½
        max_workers = min(len(years), 20)  # é™åˆ¶æœ€å¤§å¹¶å‘æ•°ä¸º20
        all_results = []
        year_distribution = {}

        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_year = {executor.submit(query_single_year, year): year
                             for year in years}

            # æ”¶é›†ç»“æœ
            for future in concurrent.futures.as_completed(future_to_year):
                year = future_to_year[future]
                try:
                    returned_year, year_results = future.result()
                    year_distribution[returned_year] = len(year_results)
                    all_results.extend(year_results)
                except Exception as e:
                    logger.error(f"[PineconeRetriever] {year}å¹´æ£€ç´¢å¼‚å¸¸: {str(e)}")
                    year_distribution[year] = 0

        # æŒ‰ç›¸ä¼¼åº¦é‡æ–°æ’åº
        all_results.sort(key=lambda x: x['score'], reverse=True)

        logger.info(
            f"[PineconeRetriever] âœ… å¹¶è¡Œå¤šå¹´ä»½æ£€ç´¢å®Œæˆ: å…±{len(all_results)}ä¸ªæ–‡æ¡£, "
            f"å¹´ä»½åˆ†å¸ƒ={year_distribution}"
        )

        return all_results

    def _convert_to_pinecone_filter(self, filters: Dict) -> Dict:
        """
        è½¬æ¢è¿‡æ»¤å™¨æ ¼å¼ä¸ºPineconeæ ¼å¼

        è¾“å…¥æ ¼å¼:
        {
            "year": "2015" æˆ– ["2015", "2016"],
            "party": "CDU/CSU",
            "speaker": "Angela Merkel"
        }

        è¾“å‡ºæ ¼å¼(Pinecone):
        {
            "year": {"$eq": "2015"} æˆ– {"$in": ["2015", "2016"]},
            "group": {"$eq": "CDU/CSU"}
        }
        """
        if not filters:
            return {}

        pinecone_filter = {}

        # å¹´ä»½è¿‡æ»¤
        if 'year' in filters:
            year_value = filters['year']
            if isinstance(year_value, list):
                if len(year_value) == 1:
                    pinecone_filter['year'] = {'$eq': year_value[0]}
                else:
                    pinecone_filter['year'] = {'$in': year_value}
            else:
                pinecone_filter['year'] = {'$eq': year_value}

        # å…šæ´¾è¿‡æ»¤ (æ³¨æ„: Pineconeä¸­å­—æ®µæ˜¯'group')
        if 'party' in filters:
            party_value = filters['party']
            if isinstance(party_value, list):
                if len(party_value) == 1:
                    pinecone_filter['group'] = {'$eq': party_value[0]}
                else:
                    pinecone_filter['group'] = {'$in': party_value}
            else:
                pinecone_filter['group'] = {'$eq': party_value}

        # å‘è¨€äººè¿‡æ»¤
        if 'speaker' in filters:
            pinecone_filter['speaker'] = {'$eq': filters['speaker']}

        # ä¸»é¢˜è¿‡æ»¤ (å¦‚æœæœ‰çš„è¯)
        if 'topic' in filters:
            # Pineconeå¯èƒ½éœ€è¦å…¨æ–‡åŒ¹é…æˆ–è€…ä½¿ç”¨contains
            pinecone_filter['topic'] = {'$eq': filters['topic']}

        return pinecone_filter

    def get_stats(self) -> Dict:
        """
        è·å–ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        stats = self.index.describe_index_stats()
        return {
            'total_vectors': stats.get('total_vector_count', 0),
            'dimension': stats.get('dimension', 0),
            'index_fullness': stats.get('index_fullness', 0)
        }


def create_pinecone_retriever(
    index_name: str = "german-bge",
    default_limit: int = 50
) -> PineconeRetriever:
    """
    åˆ›å»ºPineconeæ£€ç´¢å™¨çš„å·¥å‚å‡½æ•°

    Args:
        index_name: ç´¢å¼•åç§°
        default_limit: é»˜è®¤æ£€ç´¢æ•°é‡

    Returns:
        PineconeRetrieverå®ä¾‹
    """
    return PineconeRetriever(
        index_name=index_name,
        default_limit=default_limit
    )


if __name__ == "__main__":
    # æµ‹è¯•Pineconeæ£€ç´¢å™¨
    print("=== Pineconeæ£€ç´¢å™¨æµ‹è¯• ===")

    try:
        retriever = create_pinecone_retriever()
        print(f"âœ… æ£€ç´¢å™¨åˆ›å»ºæˆåŠŸ")

        stats = retriever.get_stats()
        print(f"âœ… ç´¢å¼•ç»Ÿè®¡: {stats}")

        print("\nå¦‚éœ€å®Œæ•´æµ‹è¯•ï¼Œè¯·:")
        print("1. ç¡®ä¿PINECONE_VECTOR_DATABASE_API_KEYå·²è®¾ç½®")
        print("2. ç¡®ä¿ç´¢å¼•german-bgeå­˜åœ¨ä¸”æœ‰æ•°æ®")
        print("3. æä¾›æŸ¥è¯¢å‘é‡è¿›è¡Œå®é™…æ£€ç´¢")

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
