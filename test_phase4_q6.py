"""
Phase 4æµ‹è¯•ï¼šQueryæ‰©å±•æ–¹æ¡ˆéªŒè¯
ä¸“é—¨æµ‹è¯•Q6é—®é¢˜ï¼ŒéªŒè¯"Zwang durchsetzen"æ˜¯å¦èƒ½è¢«æˆåŠŸå¬å›
"""

import os
import sys
from datetime import datetime

# æ·»åŠ srcåˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from src.graph.workflow import create_graph
from src.utils.logger import logger


def test_q6_phase4():
    """æµ‹è¯•Q6é—®é¢˜ï¼ˆPhase 4: Queryæ‰©å±•ï¼‰"""

    print("=" * 80)
    print("ğŸ§ª Phase 4æµ‹è¯•ï¼šQueryæ‰©å±•æ–¹æ¡ˆ")
    print("=" * 80)
    print()

    # Q6é—®é¢˜
    question = "Wie haben sich die Positionen der CDU/CSU zur Migrationspolitik zwischen 2017 und 2019 im Vergleich verÃ¤ndert?"

    print(f"ğŸ“ æµ‹è¯•é—®é¢˜: {question}")
    print()
    print("ğŸ¯ éªŒè¯ç›®æ ‡:")
    print("   1. Queryæ‰©å±•æ˜¯å¦ç”Ÿæ•ˆï¼ˆåº”ç”Ÿæˆ3ä¸ªæŸ¥è¯¢å˜ä½“ï¼‰")
    print("   2. å…³é”®æ–‡æ¡£text_id 2017_1762423575_2922æ˜¯å¦è¢«å¬å›")
    print("   3. æŠ¥å‘Šä¸­æ˜¯å¦å‡ºç°'Zwang durchsetzen'çŸ­è¯­")
    print()
    print("-" * 80)
    print()

    try:
        # åˆ›å»ºworkflow
        graph = create_graph()

        # è¿è¡Œ
        logger.info(f"å¼€å§‹æµ‹è¯•Q6...")
        result = graph.invoke({"question": question})

        # æå–æŠ¥å‘Š
        final_answer = result.get("final_answer", "")
        retrieval_thinking = result.get("retrieval_thinking", "")
        retrieval_results = result.get("retrieval_results", [])

        print("\n" + "=" * 80)
        print("ğŸ“Š æ£€ç´¢é˜¶æ®µåˆ†æ")
        print("=" * 80)

        # æ£€æŸ¥1: Queryæ‰©å±•æ˜¯å¦ç”Ÿæ•ˆ
        print("\nã€æ£€æŸ¥1ã€‘Queryæ‰©å±•ç”Ÿæ•ˆæƒ…å†µ:")
        if "Queryæ‰©å±•" in retrieval_thinking:
            print("   âœ… Queryæ‰©å±•å·²å¯ç”¨")
            # æå–å˜ä½“ä¿¡æ¯
            lines = retrieval_thinking.split('\n')
            for line in lines:
                if 'å˜ä½“' in line:
                    print(f"   {line}")
        else:
            print("   âŒ Queryæ‰©å±•æœªå¯ç”¨ï¼ˆå¯èƒ½ä»£ç æœªç”Ÿæ•ˆï¼‰")

        # æ£€æŸ¥2: å…³é”®æ–‡æ¡£æ˜¯å¦è¢«å¬å›
        print("\nã€æ£€æŸ¥2ã€‘å…³é”®æ–‡æ¡£å¬å›æƒ…å†µ:")
        target_text_id = "2017_1762423575_2922"
        found_target = False

        for sub_result in retrieval_results:
            chunks = sub_result.get("chunks", [])
            for i, chunk in enumerate(chunks):
                chunk_id = chunk.get("id", "")
                if target_text_id in chunk_id:
                    found_target = True
                    score = chunk.get("score", 0)
                    text_preview = chunk.get("text", "")[:150]
                    print(f"   âœ… æ‰¾åˆ°ç›®æ ‡æ–‡æ¡£ï¼")
                    print(f"      - æ–‡æ¡£ID: {chunk_id}")
                    print(f"      - ç›¸ä¼¼åº¦: {score:.4f}")
                    print(f"      - æ’å: Top-{i+1}")
                    print(f"      - å†…å®¹é¢„è§ˆ: {text_preview}...")
                    break
            if found_target:
                break

        if not found_target:
            print(f"   âŒ æœªæ‰¾åˆ°ç›®æ ‡æ–‡æ¡£ {target_text_id}")

        # æ£€æŸ¥3: æŠ¥å‘Šä¸­æ˜¯å¦åŒ…å«å…³é”®çŸ­è¯­
        print("\nã€æ£€æŸ¥3ã€‘æŠ¥å‘Šå†…å®¹æ£€æŸ¥:")
        key_phrases = [
            "Zwang durchsetzen",
            "å¼ºåˆ¶æ‰§è¡Œ",
            "Ausreisepflicht",
            "é£è¿”ä¹‰åŠ¡"
        ]

        found_phrases = []
        for phrase in key_phrases:
            if phrase in final_answer:
                found_phrases.append(phrase)

        if found_phrases:
            print(f"   âœ… æŠ¥å‘Šä¸­åŒ…å«å…³é”®çŸ­è¯­: {', '.join(found_phrases)}")
        else:
            print(f"   âŒ æŠ¥å‘Šä¸­æœªåŒ…å«ä»»ä½•å…³é”®çŸ­è¯­")

        # ç»Ÿè®¡æ€»å¬å›æ–‡æ¡£æ•°
        total_docs = sum(len(r.get("chunks", [])) for r in retrieval_results)
        print(f"\nã€ç»Ÿè®¡ã€‘æ€»å¬å›æ–‡æ¡£æ•°: {total_docs}")

        # ä¿å­˜æŠ¥å‘Š
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = f"outputs/Q6_Phase4_{timestamp}"
        os.makedirs(output_dir, exist_ok=True)

        report_path = os.path.join(output_dir, "Q6_full_report.md")
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(final_answer)

        thinking_path = os.path.join(output_dir, "retrieval_thinking.txt")
        with open(thinking_path, 'w', encoding='utf-8') as f:
            f.write(retrieval_thinking)

        print(f"\nğŸ“ æŠ¥å‘Šå·²ä¿å­˜:")
        print(f"   - å®Œæ•´æŠ¥å‘Š: {report_path}")
        print(f"   - æ£€ç´¢æ€è€ƒ: {thinking_path}")

        # æœ€ç»ˆåˆ¤æ–­
        print("\n" + "=" * 80)
        print("ğŸ¯ Phase 4æ•ˆæœè¯„ä¼°")
        print("=" * 80)

        if found_target and found_phrases:
            print("âœ…âœ…âœ… Phase 4æˆåŠŸï¼å…³é”®æ–‡æ¡£å·²å¬å›ä¸”æŠ¥å‘ŠåŒ…å«å…³é”®çŸ­è¯­")
            return True
        elif found_target:
            print("âš ï¸ Phase 4éƒ¨åˆ†æˆåŠŸï¼šæ–‡æ¡£å·²å¬å›ï¼Œä½†æŠ¥å‘Šä¸­ç¼ºå¤±å…³é”®çŸ­è¯­ï¼ˆå¯èƒ½æ˜¯æ€»ç»“é—®é¢˜ï¼‰")
            return False
        else:
            print("âŒ Phase 4å¤±è´¥ï¼šå…³é”®æ–‡æ¡£æœªè¢«å¬å›ï¼ˆéœ€è¦è€ƒè™‘æ–¹æ¡ˆAæˆ–BM25ï¼‰")
            return False

    except Exception as e:
        logger.error(f"æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = test_q6_phase4()
    sys.exit(0 if success else 1)
