#!/usr/bin/env python3
"""
æ‰¹é‡å¤„ç†æ€§èƒ½ä¼˜åŒ–æµ‹è¯•
æµ‹è¯•ä¸åŒå‚æ•°ä¸‹çš„å®é™…å¤„ç†é€Ÿåº¦
"""

import os
import sys
import time
import random
from pathlib import Path
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).resolve().parent
sys.path.append(str(project_root))

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(project_root / ".env", override=True)

from src.utils.logger import setup_logger

logger = setup_logger()

def test_batch_embedding_performance():
    """æµ‹è¯•æ‰¹é‡embeddingæ€§èƒ½"""
    logger.info("ğŸ§  æµ‹è¯•BGE-M3æ‰¹é‡embeddingæ€§èƒ½")
    
    try:
        from src.llm.embeddings import GeminiEmbeddingClient
        
        embedding_client = GeminiEmbeddingClient(
            embedding_mode="local",
            model_name="BAAI/bge-m3", 
            dimensions=1024
        )
        
        # ç”Ÿæˆæµ‹è¯•æ–‡æœ¬
        test_texts = []
        for i in range(100):  # æµ‹è¯•100ä¸ªæ–‡æœ¬
            text = f"è¿™æ˜¯ç¬¬{i+1}ä¸ªæµ‹è¯•æ–‡æœ¬ï¼Œç”¨äºéªŒè¯BGE-M3æ‰¹é‡embeddingçš„æ€§èƒ½ã€‚å†…å®¹åŒ…æ‹¬å¾·å›½è”é‚¦è®®é™¢çš„ç›¸å…³è®¨è®ºå’Œæ”¿æ²»åˆ†æï¼Œç¡®ä¿æ–‡æœ¬é•¿åº¦å’Œå¤æ‚åº¦ç¬¦åˆå®é™…æ•°æ®ç‰¹å¾ã€‚"
            test_texts.append(text)
        
        # æµ‹è¯•ä¸åŒæ‰¹æ¬¡å¤§å°
        batch_sizes = [16, 32, 64, 128]
        
        results = []
        
        for batch_size in batch_sizes:
            logger.info(f"ğŸ§ª æµ‹è¯•æ‰¹æ¬¡å¤§å°: {batch_size}")
            
            start_time = time.time()
            vectors = embedding_client.embed_batch(
                test_texts,
                batch_size=batch_size,
                max_workers=4  # ä¿å®ˆå¹¶å‘æ•°
            )
            embedding_time = time.time() - start_time
            
            speed = len(test_texts) / embedding_time
            results.append({
                'batch_size': batch_size,
                'time': embedding_time,
                'speed': speed,
                'vectors': len(vectors)
            })
            
            logger.info(f"   è€—æ—¶: {embedding_time:.2f}ç§’")
            logger.info(f"   é€Ÿåº¦: {speed:.1f}æ¡/ç§’")
            
            # æ¸…ç†GPUå†…å­˜
            import torch
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
        
        # æ˜¾ç¤ºç»“æœ
        logger.info("ğŸ“Š æ‰¹é‡embeddingæ€§èƒ½å¯¹æ¯”:")
        logger.info("æ‰¹æ¬¡å¤§å°  |  è€—æ—¶(ç§’)  |  é€Ÿåº¦(æ¡/ç§’)")
        logger.info("-" * 40)
        for result in results:
            logger.info(f"   {result['batch_size']:3d}    |   {result['time']:6.2f}   |    {result['speed']:6.1f}")
        
        # æ¨èæœ€ä½³é…ç½®
        best_result = max(results, key=lambda x: x['speed'])
        logger.info(f"ğŸ¯ æ¨èé…ç½®: æ‰¹æ¬¡å¤§å° {best_result['batch_size']} (é€Ÿåº¦: {best_result['speed']:.1f}æ¡/ç§’)")
        
        return best_result
        
    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡embeddingæµ‹è¯•å¤±è´¥: {str(e)}")
        return None

def test_batch_pinecone_performance(embedding_result):
    """æµ‹è¯•æ‰¹é‡Pineconeå­˜å‚¨æ€§èƒ½"""
    logger.info("ğŸ“¤ æµ‹è¯•Pineconeæ‰¹é‡å­˜å‚¨æ€§èƒ½")
    
    try:
        from pinecone import Pinecone
        from src.llm.embeddings import GeminiEmbeddingClient
        
        # åˆå§‹åŒ–
        api_key = os.getenv("PINECONE_VECTOR_DATABASE_API_KEY")
        pc = Pinecone(api_key=api_key)
        index = pc.Index("german-bge")
        
        embedding_client = GeminiEmbeddingClient(
            embedding_mode="local",
            model_name="BAAI/bge-m3",
            dimensions=1024
        )
        
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        test_texts = [
            f"Pineconeå­˜å‚¨æµ‹è¯•æ–‡æœ¬{i+1}ï¼šå¾·å›½è”é‚¦è®®é™¢çš„æ”¿æ²»è®¨è®ºå’Œæ³•å¾‹åˆ¶å®šè¿‡ç¨‹åˆ†æã€‚"
            for i in range(50)  # æµ‹è¯•50ä¸ªå‘é‡
        ]
        
        # ç”Ÿæˆembeddings
        logger.info("ğŸ§  ç”Ÿæˆæµ‹è¯•embeddings")
        vectors = embedding_client.embed_batch(test_texts, batch_size=embedding_result['batch_size'])
        
        # å‡†å¤‡å‘é‡æ•°æ®
        vector_data = []
        timestamp = int(time.time())
        for i, (text, vector) in enumerate(zip(test_texts, vectors)):
            vector_data.append({
                "id": f"perf_test_{timestamp}_{i}",
                "values": vector,
                "metadata": {
                    "text": text,
                    "test_type": "performance_batch",
                    "batch_id": timestamp
                }
            })
        
        # æµ‹è¯•ä¸åŒæ‰¹é‡å­˜å‚¨å¤§å°
        upsert_batch_sizes = [10, 25, 50, 100]
        
        results = []
        
        for upsert_batch_size in upsert_batch_sizes:
            if upsert_batch_size > len(vector_data):
                continue
                
            logger.info(f"ğŸ“¦ æµ‹è¯•å­˜å‚¨æ‰¹æ¬¡å¤§å°: {upsert_batch_size}")
            
            # å–å‰Nä¸ªå‘é‡æµ‹è¯•
            test_vectors = vector_data[:upsert_batch_size]
            
            start_time = time.time()
            upsert_response = index.upsert(vectors=test_vectors)
            upsert_time = time.time() - start_time
            
            speed = len(test_vectors) / upsert_time if upsert_time > 0 else 0
            results.append({
                'batch_size': upsert_batch_size,
                'time': upsert_time, 
                'speed': speed,
                'response': upsert_response
            })
            
            logger.info(f"   è€—æ—¶: {upsert_time:.2f}ç§’")
            logger.info(f"   é€Ÿåº¦: {speed:.1f}æ¡/ç§’")
            logger.info(f"   ç»“æœ: {upsert_response}")
            
            # çŸ­æš‚ç­‰å¾…é¿å…APIé™åˆ¶
            time.sleep(1)
        
        # æ˜¾ç¤ºç»“æœ
        logger.info("ğŸ“Š æ‰¹é‡å­˜å‚¨æ€§èƒ½å¯¹æ¯”:")
        logger.info("æ‰¹æ¬¡å¤§å°  |  è€—æ—¶(ç§’)  |  é€Ÿåº¦(æ¡/ç§’)")
        logger.info("-" * 40)
        for result in results:
            logger.info(f"   {result['batch_size']:3d}    |   {result['time']:6.2f}   |    {result['speed']:6.1f}")
        
        # æ¨èæœ€ä½³é…ç½®
        best_result = max(results, key=lambda x: x['speed'])
        logger.info(f"ğŸ¯ æ¨èå­˜å‚¨é…ç½®: æ‰¹æ¬¡å¤§å° {best_result['batch_size']} (é€Ÿåº¦: {best_result['speed']:.1f}æ¡/ç§’)")
        
        # æ¸…ç†æµ‹è¯•æ•°æ®
        logger.info("ğŸ§¹ æ¸…ç†æµ‹è¯•å‘é‡")
        test_ids = [v["id"] for v in vector_data]
        index.delete(ids=test_ids)
        
        return best_result
        
    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡å­˜å‚¨æµ‹è¯•å¤±è´¥: {str(e)}")
        return None

def calculate_optimized_migration_time(embedding_result, storage_result):
    """è®¡ç®—ä¼˜åŒ–åçš„è¿ç§»æ—¶é—´"""
    logger.info("â° è®¡ç®—ä¼˜åŒ–åçš„è¿ç§»æ—¶é—´")
    
    # é¢„ä¼°æ•°æ®é‡
    estimated_vectors = 79824 * 6  # 2015å¹´ Ã— 6å¹´
    
    # ç»¼åˆæ€§èƒ½ï¼ˆè€ƒè™‘embeddingå’Œå­˜å‚¨çš„å¹³è¡¡ï¼‰
    embedding_speed = embedding_result['speed'] if embedding_result else 30
    storage_speed = storage_result['speed'] if storage_result else 20
    
    # ç“¶é¢ˆé€Ÿåº¦ï¼ˆå–è¾ƒå°å€¼ï¼‰
    bottleneck_speed = min(embedding_speed, storage_speed)
    
    # åŠ ä¸Šæ•°æ®å¤„ç†å¼€é”€ï¼ˆé¢„ä¼°20%ï¼‰
    effective_speed = bottleneck_speed * 0.8
    
    # è®¡ç®—æ—¶é—´
    total_seconds = estimated_vectors / effective_speed
    total_hours = total_seconds / 3600
    
    logger.info("ğŸ¯ ä¼˜åŒ–åæ—¶é—´é¢„ä¼°:")
    logger.info(f"   é¢„è®¡å‘é‡æ•°: {estimated_vectors:,}")
    logger.info(f"   Embeddingé€Ÿåº¦: {embedding_speed:.1f}æ¡/ç§’")  
    logger.info(f"   å­˜å‚¨é€Ÿåº¦: {storage_speed:.1f}æ¡/ç§’")
    logger.info(f"   ç“¶é¢ˆé€Ÿåº¦: {bottleneck_speed:.1f}æ¡/ç§’")
    logger.info(f"   æœ‰æ•ˆé€Ÿåº¦: {effective_speed:.1f}æ¡/ç§’ (å«å¤„ç†å¼€é”€)")
    logger.info(f"   é¢„è®¡æ€»æ—¶é—´: {total_hours:.1f}å°æ—¶ ({total_seconds/60:.0f}åˆ†é’Ÿ)")
    
    # æä¾›ä¸åŒåœºæ™¯
    scenarios = [
        ("ä¿å®ˆä¼°è®¡", effective_speed * 0.7, "å«ç½‘ç»œå»¶è¿Ÿå’Œé‡è¯•"),
        ("ä¹è§‚ä¼°è®¡", effective_speed * 1.2, "æœ€ä½³ç½‘ç»œæ¡ä»¶"),
        ("å®é™…é¢„æœŸ", effective_speed, "ç»¼åˆè€ƒè™‘å„ç§å› ç´ ")
    ]
    
    logger.info("ğŸ“Š ä¸åŒåœºæ™¯é¢„ä¼°:")
    for name, speed, desc in scenarios:
        hours = estimated_vectors / speed / 3600
        logger.info(f"   {name}: {hours:.1f}å°æ—¶ ({desc})")
    
    return total_hours

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†æ€§èƒ½ä¼˜åŒ–æµ‹è¯•")
    logger.info("=" * 60)
    
    # æµ‹è¯•1: æ‰¹é‡embeddingæ€§èƒ½
    embedding_result = test_batch_embedding_performance()
    
    if not embedding_result:
        logger.error("âŒ Embeddingæµ‹è¯•å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
        return 1
    
    logger.info("-" * 40)
    
    # æµ‹è¯•2: æ‰¹é‡å­˜å‚¨æ€§èƒ½  
    storage_result = test_batch_pinecone_performance(embedding_result)
    
    if not storage_result:
        logger.error("âŒ å­˜å‚¨æµ‹è¯•å¤±è´¥")
        return 1
    
    logger.info("-" * 40)
    
    # æµ‹è¯•3: è®¡ç®—ä¼˜åŒ–æ—¶é—´
    optimized_hours = calculate_optimized_migration_time(embedding_result, storage_result)
    
    logger.info("=" * 60)
    logger.info("ğŸ‰ æ€§èƒ½ä¼˜åŒ–æµ‹è¯•å®Œæˆï¼")
    logger.info(f"ğŸ“ˆ é¢„è®¡è¿ç§»æ—¶é—´å¯ç¼©çŸ­è‡³: {optimized_hours:.1f}å°æ—¶")
    
    return 0

if __name__ == "__main__":
    exit(main())
